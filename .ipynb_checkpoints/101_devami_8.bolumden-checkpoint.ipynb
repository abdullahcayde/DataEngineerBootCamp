{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a654d321-c9db-4bd9-a83d-8570c097a223",
   "metadata": {},
   "source": [
    " NumPy for Data Science\n",
    "Operations on Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a022b1-fd55-4b00-91c6-a3e89c53125d",
   "metadata": {},
   "source": [
    "# Operations on Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d119db-17ed-4898-bb4b-a7cf3d199906",
   "metadata": {},
   "source": [
    "## Arithmetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ea4c6-ac29-4980-ad4f-302fed0fa0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Arithmetic operators\n",
    "\n",
    "    Numpy allows you to perform mathematical operations on arrays in an optimized way.\n",
    "\n",
    "            Applying one of the basic arithmetic operations (/, *, -,+,**) between an array and a value will apply the operation to each of the elements of the array.\n",
    "\n",
    "            It is also possible to perform an arithmetic operation between two arrays. This will apply the operation between each pair of elements.\n",
    "\n",
    "        # Creation of two arrays with 2 values\n",
    "        a = np.array([4, 10])\n",
    "        b = np.array([6, 7])\n",
    "\n",
    "        # Multiplication between two arrays\n",
    "        print(a * b)\n",
    "        >>> [24, 70]\n",
    "\n",
    "    (a) Import the package numpy under the name np.\n",
    "\n",
    "    (b) Create an array of dimensions 10x4 filled with ones.\n",
    "\n",
    "    (c) Using a for loop and the enumerate function, multiply each row by its index. In order to modify the matrix,\n",
    "    it must be accessed through indexing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b699c5-f06e-4721-b3e1-4b0597634f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1. 1.]\n",
      "1 [1. 1.]\n",
      "2 [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.ones((3,2))\n",
    "\n",
    "for n, arr in enumerate(X):\n",
    "    print(n, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf2d6424-d1dd-4baa-86bc-453e96e2055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 2. 3.]\n",
      " [0. 1. 2. 3.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the array of the value is bigger than 1 then compute 2 powers of value \n",
    "X = np.ones((10,4))\n",
    "X = X * [i for i in range(4)]\n",
    "print(X[:2])\n",
    "\n",
    "for i, row in enumerate(X):\n",
    "    for j in row:\n",
    "        if j > 1:\n",
    "            X[i,int(j)] **= 2\n",
    "            \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c90c141-1b12-4be3-ada6-e7a8379f6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[1. 1. 1. 1.]\n",
      "[2. 2. 2. 2.]\n",
      "[3. 3. 3. 3.]\n",
      "[4. 4. 4. 4.]\n",
      "[5. 5. 5. 5.]\n",
      "[6. 6. 6. 6.]\n",
      "[7. 7. 7. 7.]\n",
      "[8. 8. 8. 8.]\n",
      "[9. 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "import numpy as np\n",
    "\n",
    "X = np.ones((10,4))\n",
    "\n",
    "for n, arr in enumerate(X):\n",
    "    print(n * arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8178ca0f-6630-49e4-9cb9-2fd9a8d7e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 2. 2. 2.]\n",
      " [3. 3. 3. 3.]\n",
      " [4. 4. 4. 4.]\n",
      " [5. 5. 5. 5.]\n",
      " [6. 6. 6. 6.]\n",
      " [7. 7. 7. 7.]\n",
      " [8. 8. 8. 8.]\n",
      " [9. 9. 9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "#original cozum \n",
    "import numpy as np\n",
    "\n",
    "M = np.ones((10, 4))\n",
    "\n",
    "# For each row of the matrix M\n",
    "for i, row in enumerate(M):\n",
    "    # We multiply the row by its index\n",
    "    M[i,:] = row*i\n",
    "    # Alternatively M[i,:]* = i\n",
    "    \n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a153d4-c423-4e0a-9e12-7f9566ab73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "As explained above, the * operator allows you to compute an element-wise product between arrays.\n",
    "\n",
    "For example:\n",
    "\n",
    "(5310)âˆ—(2048)=(10040)\n",
    "\n",
    "The matrix product, in the mathematical sense of the term, can be performed using the dot method of a numpy array:\n",
    "\n",
    "# Creation of two arrays of size 2x2\n",
    "M = np.array([[5, 1],\n",
    "              [3, 0]])\n",
    "\n",
    "N = np.array([[2, 4],\n",
    "              [0, 8]])\n",
    "\n",
    "# Matrix product between the two arrays\n",
    "print(M.dot(N))\n",
    ">>> [[10, 28]\n",
    ">>>  [6, 12]]\n",
    "\n",
    "Indeed, if we recall the matrix product:\n",
    "\n",
    "ğ‘€=([5, 1],\n",
    "    [3, 0]),\n",
    "ğ‘=([2, 4],\n",
    "    [0, 8])\n",
    "\n",
    "ğ‘€ğ‘=(5310)(2048)=((5âˆ—2)+(1âˆ—0)(3âˆ—2)+(0âˆ—0)(5âˆ—4)+(1âˆ—8)(3âˆ—4)+(0âˆ—8))=[[10, 28],\n",
    "                                                                 [ 6, 12]])\n",
    "Let's consider the following matrix:\n",
    "\n",
    "ğ´=(1âˆ’1âˆ’11)\n",
    "\n",
    "    (d) Define a function named powerA taking as argument an integer n greater than 1. This function must compute and return ğ´^ğ‘›\n",
    "\n",
    "    (according to matrix product).\n",
    "\n",
    "    (e) Calculate and display ğ´^2, ğ´^3 and ğ´^4. Can you guess a general formula for ğ´^ğ‘›?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4367ecc1-2671-4d44-b904-541cb747ece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10, 28],\n",
       "        [ 6, 12]]),\n",
       " array([[10, 28],\n",
       "        [ 6, 12]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[5, 1],\n",
    "              [3, 0]])\n",
    "\n",
    "\n",
    "N = np.array([[2, 4],\n",
    "              [0, 8]])\n",
    "\n",
    "\n",
    "\n",
    "def powerA(n, A, B):\n",
    "\n",
    "    for i in range(n):\n",
    "        at = A @ B\n",
    "        A = A.dot(B)\n",
    "    return A, at         \n",
    "\n",
    "\n",
    "powerA(1, M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ecebc8e-e6f1-42c8-9529-b1190e7e1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A**2: \n",
      " [[ 2 -2]\n",
      " [-2  2]] \n",
      "\n",
      "A**3: \n",
      " [[ 4 -4]\n",
      " [-4  4]] \n",
      "\n",
      "A**4: \n",
      " [[ 8 -8]\n",
      " [-8  8]] \n",
      "\n",
      "A general formula of A**n is given by:\n",
      "[2**(n-1), -2**(n-1)]\n",
      "[-2**(n-1), 2**(n-1)]\n"
     ]
    }
   ],
   "source": [
    "# original cozum\n",
    "def powerA(n):\n",
    "    # A is initialized to the identity matrix\n",
    "    A = np.array([[1, 0],\n",
    "                  [0, 1]])\n",
    "    \n",
    "    # This matrix B will be used to calculate the powers of A\n",
    "    B = np.array([[1, -1],\n",
    "                  [-1, 1]])\n",
    "    \n",
    "    # We multiply A by B n times to get A**n\n",
    "    for i in range(n):\n",
    "        A = A.dot(B)\n",
    "        \n",
    "    return A\n",
    "\n",
    "print (\"A**2: \\n\", powerA(2), \"\\n\")\n",
    "print (\"A**3: \\n\", powerA(3), \"\\n\")\n",
    "print (\"A**4: \\n\", powerA(4), \"\\n\")\n",
    "\n",
    "print (\"A general formula of A**n is given by:\")\n",
    "print (\"[2**(n-1), -2**(n-1)]\")\n",
    "print (\"[-2**(n-1), 2**(n-1)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669a8a1-f32b-4aa3-9cad-2f74e52d28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a two-dimensional plane, rotations around the origin are represented by the matrices of the form:\n",
    "\n",
    "ğ´(ğœƒ)=(cos(ğœƒ) âˆ’sin(ğœƒ)\n",
    "     sin(ğœƒ)  cos(ğœƒ))\n",
    "where ğœƒ defines the angle of the rotation in radians. Thus, the rotation of a point with coordinates ğ‘¥=(ğ‘¥1ğ‘¥2) is calculated thanks to the formula ğ‘¥Ìƒ =ğ´(ğœƒ)ğ‘¥\n",
    "\n",
    "    (f) Define a function named rotation_matrix taking as argument a number ğœƒ\n",
    "\n",
    "(theta) and returning the associated ğ´(ğœƒ) matrix. You can calculate the cos and sin\n",
    "\n",
    "    functions using the np.cos andnp.sin functions of numpy.\n",
    "\n",
    "    (g) Let ğ‘¥=(1\n",
    "                1)\n",
    "\n",
    "be a point. Calculate and display ğ´(ğœ‹)ğ‘¥, which is equivalent to rotating 180Âº around the origin. You have access to the constant ğœ‹\n",
    "\n",
    "    with the np.pi instruction.\n",
    "\n",
    "    (h) Show that ğ´(ğœ‹4)ğ´(3ğœ‹4)ğ‘¥=ğ´(ğœ‹)ğ‘¥\n",
    "\n",
    "    .\n",
    "\n",
    "    (i) Generally speaking, for any angle, ğ´(ğœƒ1)ğ´(ğœƒ2)ğ‘¥=ğ´(ğœƒ1+ğœƒ2)ğ‘¥\n",
    "\n",
    ". Why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f08656b-67e4-4245-ba64-14bf2f9b5c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [-1. -1.]\n",
      "0.0 [-1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def rotation_matrix(theta, X):\n",
    "    Y = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "    return Y.dot(X)\n",
    "\n",
    "#g)\n",
    "x = np.array([1,1])\n",
    "\n",
    "x_pi = rotation_matrix(np.pi, x)\n",
    "\n",
    "print(x, x_pi )\n",
    "\n",
    "#h)\n",
    "a_pi_4 = rotation_matrix(np.pi/4, x)\n",
    "a_3pi_4 = rotation_matrix(3*np.pi/4, x)\n",
    "\n",
    "print(a_pi_4.dot(a_3pi_4), x_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d63605dc-6bfb-49ad-90f0-6d6d617df23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [-1. -1.]\n",
      "[1 1] [-1. -1.] \n",
      "\n",
      "a_theta1 \n",
      "\n",
      " [[ 1.00000000e+00 -1.96438672e-15]\n",
      " [ 1.96438672e-15  1.00000000e+00]] \n",
      " a_theta2 \n",
      "\n",
      " [[ 1.00000000e+00 -3.92877345e-15]\n",
      " [ 3.92877345e-15  1.00000000e+00]] \n",
      " a_sum \n",
      "\n",
      " [[ 1.00000000e+00  5.09502587e-14]\n",
      " [-5.09502587e-14  1.00000000e+00]] \n",
      "\n",
      "[1. 1.]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    Y = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "    return Y\n",
    "\n",
    "#g)\n",
    "x = np.array([1,1])\n",
    "\n",
    "x_pi = rotation_matrix(np.pi)\n",
    "\n",
    "print(x, x_pi.dot(x))\n",
    "\n",
    "#h)\n",
    "x = np.array([1,1])\n",
    "a_pi_4 = rotation_matrix(np.pi/4)\n",
    "a_3pi_4 = rotation_matrix(3*np.pi/4)\n",
    "\n",
    "print(x, a_pi_4.dot(a_3pi_4.dot(x)), \"\\n\")\n",
    "\n",
    "#i)\n",
    "pi = 100*np.pi\n",
    "pi_2 = 200*np.pi\n",
    "\n",
    "a_theta1 = rotation_matrix(pi)\n",
    "a_theta2 = rotation_matrix(pi_2)\n",
    "a_sum = rotation_matrix(pi + pi_2)\n",
    "\n",
    "print(\"a_theta1 \\n\\n\",a_theta1, \"\\n a_theta2 \\n\\n\", a_theta2, \"\\n a_sum \\n\\n\", a_sum, \"\\n\")\n",
    "print(a_theta1.dot(a_theta2.dot(x)))\n",
    "print(a_sum.dot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab3211a5-6eff-46de-812f-d0c0e452ee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [1 1]\n",
      "A(pi)x = [-1. -1.]\n",
      "A(pi/4) A(3pi/4) x = [-1. -1.]\n",
      "\n",
      "\n",
      "Intuitively, A(theta_1) A(theta_2) = A(theta_1 + theta_2) because applying a rotation of angle theta_1 then\n",
      "applying another rotation of angle theta_2 is exactly the same as applying a rotation whose angle is the sum of the two.\n"
     ]
    }
   ],
   "source": [
    "#original cozum\n",
    "#????????\n",
    "\n",
    "# First question\n",
    "def rotation_matrix(theta):\n",
    "    A = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "    \n",
    "    return A\n",
    "\n",
    "# Second question\n",
    "x = np.array([1, 1])\n",
    "A_pi = rotation_matrix(np.pi)\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"A(pi)x =\", A_pi.dot(x))\n",
    "\n",
    "# Third question\n",
    "A_pi_4 = rotation_matrix(np.pi/4)\n",
    "A_3pi_4 = rotation_matrix(3*np.pi/4)\n",
    "\n",
    "print(\"A(pi/4) A(3pi/4) x =\", A_pi_4.dot(A_3pi_4.dot(x)))\n",
    "\n",
    "# Fourth question\n",
    "print(\"\\n\")\n",
    "print(\"Intuitively, A(theta_1) A(theta_2) = A(theta_1 + theta_2) because applying a rotation of angle theta_1 then\" )\n",
    "print(\"applying another rotation of angle theta_2 is exactly the same as applying a rotation whose angle is the sum of the two.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2fd1f-ac1d-4c5e-86b8-84f60635efe1",
   "metadata": {},
   "source": [
    "## Broadcasting between a matrix and a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc864bc8-bec5-4524-b7f0-198c64c63b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Broadcasting between a matrix and a value\n",
    "\n",
    "    When performing an operation between elements of different dimensions, Numpy performs what is called Broadcasting to understand the operation and execute it.\n",
    "\n",
    "    The term broadcasting is used because one of the arrays is \"broadcasted\" into an array of larger dimensions so that the two arrays have compatible dimensions. This definition will be illustrated below.\n",
    "\n",
    "    In this section, we will try to understand numpy's broadcasting rules in the following cases:\n",
    "\n",
    "        Operation between a matrix and a constant\n",
    "        Operation between a matrix and a vector\n",
    "\n",
    "    An arithmetic operation such as the sum between a matrix and a constant does not make mathematical sense. With Numpy, the broadcasting rule in this case is to sum the constant to each term of the matrix.\n",
    "\n",
    "    ğ‘€=(3âˆ’21125),ğ‘=10\n",
    "\n",
    "ğ‘€+ğ‘=(3+10âˆ’2+101+101+102+105+10)=(13811111215)\n",
    "\n",
    "What really happens is that the constant ğ‘\n",
    "is broadcasted into a matrix ğ¶ with the same dimensions as ğ‘€\n",
    "\n",
    ":\n",
    "\n",
    "ğ‘âŸ¶broadcastingğ¶=(ğ‘ğ‘ğ‘ğ‘ğ‘ğ‘)\n",
    "\n",
    "Thus, ğ‘€+ğ¶\n",
    "\n",
    "    is mathematically well defined and can be computed with basic operations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82660abe-29ea-4939-925b-d869fbbee8aa",
   "metadata": {},
   "source": [
    "## Broadcasting between a matrix and a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1e8d6f-0084-400e-ae9b-6bbc4c94f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Broadcasting between a matrix and a vector\n",
    "\n",
    "    Similarly, numpy allows us to perform arithmetic operations between a matrix and a vector. However, there are some constraints which determine whether the vector can be broadcasted into a matrix with compatible dimensions.\n",
    "\n",
    "    In order to determine if the dimensions of the vector and the matrix are compatible, numpy will compare each dimension of the two arrays and determine if:\n",
    "\n",
    "        the dimensions are equal.\n",
    "        one of the dimensions is equal to 1.\n",
    "\n",
    "    If for each dimension, one of these conditions is verified, then the dimensions are compatible and the operation has been understood. Otherwise, a ValueError: operands could not be broadcast together error will be displayed.\n",
    "\n",
    "    Let us consider the following objects :\n",
    "\n",
    "    ğ‘€=(3âˆ’21125),ğ‘£=(25)\n",
    "\n",
    "Do ğ‘€\n",
    "and ğ‘£\n",
    "\n",
    "have compatible dimensions for broadcasting?\n",
    "\n",
    "ğ‘€\n",
    "is a 2x3 dimensional matrix. ğ‘£ is a vector with 2 elements, but numpy will instead see ğ‘£\n",
    "\n",
    "as a matrix of dimensions 2x1, that is, a matrix with two rows and one column.\n",
    "\n",
    "The first dimension of ğ‘€\n",
    "and ğ‘£ is equal to 2\n",
    "\n",
    ". They are equal so the compatibility condition is verified for this dimension.\n",
    "\n",
    "The second dimension of ğ‘€\n",
    "is equal to 3 and that of ğ‘£\n",
    "\n",
    "is equal to 1. The compatibility condition is still verified because one of the dimensions is equal to 1.\n",
    "\n",
    "Therefore ğ‘€\n",
    "and ğ‘£\n",
    "\n",
    "have compatible dimensions for broadcasting.\n",
    "\n",
    "The vector ğ‘£\n",
    "will then be broadcasted along the axis where the dimension of ğ‘£ is equal to 1. In our case, it is the axis of the columns. The broadcasting of ğ‘£\n",
    "\n",
    "will therefore be given by:\n",
    "\n",
    "ğ‘£=(25)âŸ¶broadcastingğ‘‰=[ğ‘£ğ‘£ğ‘£]=(252525)\n",
    "\n",
    "The result of ğ‘€âˆ—ğ‘£\n",
    "\n",
    "will then be given by:\n",
    "\n",
    "ğ‘€âˆ—ğ‘£âŸ¶broadcastingğ‘€âˆ—ğ‘‰=(3âˆ—2âˆ’2âˆ—51âˆ—21âˆ—52âˆ—25âˆ—5)=(6âˆ’1025425)\n",
    "\n",
    "Now suppose we have a line vector ğ‘¢=(34)\n",
    "\n",
    ".\n",
    "\n",
    "For numpy, this vector has dimensions 1x2 (one row and 2 columns). The vectors ğ‘¢\n",
    "and ğ‘£\n",
    "\n",
    "are compatible for broadcasting because on each axis one of the vectors has a dimension equal to 1.\n",
    "\n",
    "How and on which object is the broadcasting carried out in this case?\n",
    "\n",
    "The broadcasting will be carried out on the two vectors and the resulting matrix of the broadcasting will have the largest dimension between the two vectors:\n",
    "\n",
    "ğ‘£=(25)âŸ¶broadcastingğ‘‰=(2525)\n",
    "\n",
    "and\n",
    "\n",
    "ğ‘¢=(34)âŸ¶broadcastingğ‘ˆ=(3344)\n",
    "\n",
    "Thus, the result of ğ‘£+ğ‘¢\n",
    "\n",
    "is given by:\n",
    "\n",
    "ğ‘£+ğ‘¢âŸ¶broadcasting=(25)+(34)ğ‘‰+ğ‘ˆ=(2525)+(3344)=(5869)\n",
    "\n",
    "    These rules allow us to understand and predict the result of an operation between two arrays which do not have the same shape. They will be useful for the following exercise:\n",
    "\n",
    "    Min-Max normalization is a method that is used to rescale the variables of a database to the interval [0,1]\n",
    "\n",
    ".\n",
    "\n",
    "Assume our database contains 3 individuals and 2 variables:\n",
    "\n",
    "        Jacques: 24 years old, height of 1.88m.\n",
    "\n",
    "        Mathilde: 18 years old, height of 1.68m.\n",
    "\n",
    "        Alban: 14 years old, height of 1.65m.\n",
    "\n",
    "This data can be represented by the matrix:\n",
    "\n",
    "ğ‘‹=î€‚î€€î€î€2418141.881.681.65î€…î€ƒî€„î€„\n",
    "\n",
    "Each row corresponds to an individual, and each column corresponds to a variable. This format is the standard format for databases.\n",
    "\n",
    "We want to compare the age differences with the height differences between individuals. However, the variables in this database do not have the same scale. We have to use Min-Max normalization so that the variables have the same scale.\n",
    "\n",
    "We denote by ğ‘‹ğ‘–,ğ‘—\n",
    "the value of the variable ğ‘— for the individual ğ‘– and ğ‘‹:,ğ‘— the column of the variable ğ‘—\n",
    "\n",
    ".\n",
    "\n",
    "Min-Max normalization will produce a new matrix ğ‘‹Ìƒ \n",
    "such that for each entry of the ğ‘‹\n",
    "\n",
    "matrix:\n",
    "\n",
    "ğ‘‹Ìƒ ğ‘–,ğ‘—=ğ‘‹ğ‘–,ğ‘—âˆ’min(ğ‘‹:,ğ‘—)max(ğ‘‹:,ğ‘—)âˆ’min(ğ‘‹:,ğ‘—)\n",
    "\n",
    "Thus, to implement Min-Max normalization :\n",
    "\n",
    "        For each ğ‘‹:,ğ‘—\n",
    "\n",
    "column, compute min(ğ‘‹:,ğ‘—) and max(ğ‘‹:,ğ‘—)\n",
    "\n",
    "    .\n",
    "\n",
    "    For each element ğ‘‹ğ‘–,ğ‘—\n",
    "\n",
    "in the column, compute ğ‘‹Ìƒ ğ‘–,ğ‘—\n",
    "\n",
    "        .\n",
    "\n",
    "By default, a for loop on ğ‘‹ will cycle through the lines of ğ‘‹. \n",
    "In order to browse the columns of ğ‘‹, you can browse the rows of the transposed matrix of ğ‘‹, which we denote by ğ‘‹ğ‘‡\n",
    "\n",
    ".\n",
    "\n",
    "ğ‘‹ğ‘‡=(241.88181.68141.65)\n",
    "\n",
    "The transposition of an array is obtained with its T attribute: ğ‘‹ğ‘‡\n",
    "\n",
    "    =X.T.\n",
    "\n",
    "    (a) Define a function named normalization_min_max taking as argument a matrix ğ‘‹ and which will return ğ‘‹Ìƒ \n",
    "\n",
    "    (b) Apply Min-Max normalization on ğ‘‹ . You should get the matrix to two decimal places:\n",
    "\n",
    "X = np.array([[1, 0.4, 0],\n",
    "              [1, 0.13, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddfb2387-16a8-4810-9a5e-03eb3cedfc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 1.  ],\n",
       "       [0.4 , 0.13],\n",
       "       [0.  , 0.  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def normalization_min_max(X):\n",
    "    if X.ndim == 1:\n",
    "        l2 = []\n",
    "        for i in X:\n",
    "            new_i = (i - min(X)) / (max(X) - min(X))\n",
    "            l2.append(round(new_i, 2))\n",
    "        return l2\n",
    "    else:\n",
    "        X = X.T\n",
    "        for i, row in enumerate(X):\n",
    "            mi = min(row)\n",
    "            ma = max(row)\n",
    "            for j, value in enumerate(row):\n",
    "                new_value = (value - mi) / (ma - mi)\n",
    "                X[i,j] = round(new_value, 2)\n",
    "\n",
    "        return X.T\n",
    "\n",
    "l = np.array([1,2,3,4])\n",
    "\n",
    "X = np.array([[1, 0.4, 0],\n",
    "              [1, 0.13, 0]])\n",
    "\n",
    "y = np.array([[24, 1.88],\n",
    "              [18, 1.68],\n",
    "              [14, 1.65]])\n",
    "normalization_min_max(l)\n",
    "normalization_min_max(y)\n",
    "#normalization_min_max(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93fb9efe-218f-4d03-b689-77e2b29937ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.        ]\n",
      " [0.4        0.13043478]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# original cozum\n",
    "def normalization_min_max(X):\n",
    "    # Initialization of X_tilde\n",
    "    X_tilde = np.zeros(shape = X.shape)\n",
    "    \n",
    "    # For each column of X\n",
    "    for j, column in enumerate(X.T):\n",
    "        # Initialization of the minimum and maximum of the column\n",
    "        min_Xj = column[0]\n",
    "        max_Xj = column[0]\n",
    "        \n",
    "        # For each value in the column\n",
    "        for value in column:\n",
    "            # If the value is SMALLER than the min\n",
    "            if value < min_Xj:\n",
    "                # We overwrite the min with this value\n",
    "                min_Xj = value\n",
    "            \n",
    "            # If the value is GREATER than the max\n",
    "            if value > max_Xj:\n",
    "                # We overwrite the max with this value\n",
    "                max_Xj = value\n",
    "                \n",
    "        # We can now calculate X_tilde for this column\n",
    "        # Broadcasting allows us to do this without a for loop\n",
    "        X_tilde[:, j] = (X[:, j] - min_Xj)/(max_Xj - min_Xj)\n",
    "            \n",
    "    return X_tilde\n",
    "        \n",
    "\n",
    "X = np.array([[24, 1.88],\n",
    "              [18, 1.68],\n",
    "              [14, 1.65]])\n",
    "\n",
    "X_tilde = normalization_min_max(X)\n",
    "\n",
    "print(X_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee034a9-0859-4f29-92b7-95695a3c8470",
   "metadata": {},
   "source": [
    "## Statistical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc8b50-4611-4b50-a083-a26371e150c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Statistical methods\n",
    "\n",
    "    In addition to common math operations, numpy arrays also have several methods for more complex operations on arrays.\n",
    "\n",
    "    One of the most used operations is the computation of an average using the mean method of an array:\n",
    "\n",
    "    A = np.array([[1, 1, 10],\n",
    "                  [3, 5, 2]])\n",
    "\n",
    "    # Computation of the mean over ALL the values of X\n",
    "    print(A.mean())\n",
    "    >>> 3.67\n",
    "\n",
    "    # Computation of the mean of each COLUMN of X\n",
    "    print(A.mean(axis = 0))\n",
    "    >>> [2, 3, 6]\n",
    "\n",
    "    # Computation of the mean of each ROW of X\n",
    "    print(A.mean(axis = 1))\n",
    "    >>> [4, 3.33]\n",
    "\n",
    "    The argument axis determines which dimension will be scanned to compute the mean:\n",
    "\n",
    "            axis = 0 means that the dimension scanned will be that of rows, which means that the result will be the average of each column.\n",
    "\n",
    "            axis = 1 means that the dimension scanned will be that of columns, which means that the result will be the average of each row.\n",
    "\n",
    "    The axis argument is very often used for operations on matrices, and not only for Numpy. It is very important to understand its effect.\n",
    "\n",
    "    There are other statistical methods that behave like the mean method, such as:\n",
    "\n",
    "            sum: Computes the sum of the elements of an array.\n",
    "\n",
    "            std: Computes the standard deviation.\n",
    "\n",
    "            min: Finds the minimum value among the elements of an array.\n",
    "\n",
    "            max: Finds the maximum value among the elements of an array.\n",
    "\n",
    "            argmin: Returns the index of the minimum value.\n",
    "\n",
    "            argmax: Returns the index of the maximum value.\n",
    "\n",
    "    These methods are useless for databases if you do not provide a value for the axis argument.\n",
    "\n",
    "    In general, we will use the value axis = 0 to get the result for each column, that is, for each variable in the database.\n",
    "\n",
    "    Thus, we can calculate the Min-Max normalization very quickly using the min and max methods along with broadcasting:\n",
    "\n",
    "    X_tilde = (X - X.min(axis = 0))/(X.max(axis = 0) - X.min(axis = 0))\n",
    "\n",
    "    print (X_tilde)\n",
    "    >>> [[1, 1]\n",
    "    >>>  [0.4, 0.13043478]\n",
    "    >>>  [0, 0]]\n",
    "\n",
    "The Mean Squared Error is a metric to quantify the prediction error obtained by a regression model. This notion will be seen in more detail later in your training.\n",
    "\n",
    "The formula for the mean squared error, abbreviated by MSE\n",
    "\n",
    ", is calculated with the following formula:\n",
    "\n",
    "MSE=1ğ‘›âˆ‘ğ‘–=1ğ‘›(ğ‘¦Ì‚ ğ‘–âˆ’ğ‘¦ğ‘–)2\n",
    "\n",
    "where:\n",
    "\n",
    "        ğ‘¦Ì‚ \n",
    "\n",
    "and ğ‘¦ are vectors with length ğ‘›\n",
    "\n",
    "    .\n",
    "\n",
    "    ğ‘¦Ì‚ \n",
    "\n",
    "is given by the matrix product between a ğ‘‹ matrix and a regression vector ğ›½, ie:\n",
    "ğ‘¦Ì‚ =ğ‘‹ğ›½\n",
    "\n",
    "In the case of linear regression, the goal of the mean squared error is to find the regression vector ğ›½\n",
    "\n",
    "which minimizes this error.\n",
    "\n",
    "    (a) Define a function named mean_squared_error taking as argument a matrix X\n",
    "    , a vector beta and a vector y and which, without a for loop, returns the associated mean squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e5ad477-ab27-4e50-876d-98c7a33b90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original cozum\n",
    "def mean_squared_error(X, beta, y):\n",
    "    # Computation of ^y\n",
    "    y_hat = X.dot(beta)\n",
    "    \n",
    "    # Computation of (^y_i - y_i)**2\n",
    "    mse = (y_hat - y)**2\n",
    "    \n",
    "    # MSE\n",
    "    mse = mse.mean()\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab3b08-b414-4e42-bca8-2cd0e6faad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Our database contained 3 individuals and 2 variables:\n",
    "\n",
    "        Jacques: 24 years old, height 1.88m.\n",
    "\n",
    "        Mathilde: 18 years old, height 1.68m.\n",
    "\n",
    "        Alban: 14 years old, height 1.65m.\n",
    "\n",
    "We will try to find a model able to predict the height of an individual based on his age. Thus, we define:\n",
    "ğ‘‹=î€‚î€€î€î€241814î€…î€ƒî€„î€„\n",
    "\n",
    "ğ‘¦=î€‚î€€î€î€1.881.681.65î€…î€ƒî€„î€„\n",
    "\n",
    "Our goal will be to find an optimal ğ›½âˆ—\n",
    "such that:\n",
    "ğ‘¦â‰ˆğ‘‹ğ›½âˆ—\n",
    "\n",
    "    (b) For beta taking the values 0.01, 0.02, ..., 0.13, 0.14 and 0.15, compute the associated MSE\n",
    "\n",
    "    using the previously defined mean_squared_error function. Store the values in a list.\n",
    "\n",
    "    To create the list [0.01, 0.02, ..., 0.13, 0.14, 0.15], you can use the np.linspace function which has a signature similar to the range function:\n",
    "\n",
    "    print(np.linspace(start = 0.01, stop = 0.15, num = 15))\n",
    "    >>> [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15]\n",
    "\n",
    "    The num argument allows you to define the desired number of elements between start and stop. It is not the step between two consecutive values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd81b475-9d91-48d9-9b5f-82a01bc98ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininmun MSE and Optimal Beta : [0.07803333333333334, 0.08999999999999998]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([24,\n",
    "              18,\n",
    "              14])\n",
    "\n",
    "y = np.array([1.88,\n",
    "              1.68,\n",
    "              1.65])\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "\n",
    "lst = np.linspace(0.01, 0.15, 15)\n",
    "result = []\n",
    "for beta in  lst:\n",
    "    result.append([mean_squared_error(X, beta, y), beta])\n",
    "\n",
    "#print(result)\n",
    "print(\"Mininmun MSE and Optimal Beta :\",min(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34253aab-9dda-4c8c-922e-2404cba67168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original cozum\n",
    "X = np.array([24,\n",
    "              18,\n",
    "              14])\n",
    "\n",
    "y = np.array([1.88,\n",
    "              1.68,\n",
    "              1.65])\n",
    "\n",
    "# List containing the mse\n",
    "errors = []\n",
    "\n",
    "# List containing the betas to be tested\n",
    "betas = np.linspace(start = 0.01, stop = 0.15, num = 15)\n",
    "\n",
    "# For all the values of beta\n",
    "for beta in betas:\n",
    "    # Compute the associated MSE\n",
    "    errors.append(mean_squared_error(X, beta, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4750e2-f8ad-41f8-a241-c20c57c73318",
   "metadata": {},
   "outputs": [],
   "source": [
    "(c) Convert the list containing the MSE\n",
    "\n",
    "    's to a numpy array.\n",
    "\n",
    "    (d) Determine the ğ›½âˆ—\n",
    "\n",
    "that minimizes the MSE using the argmin method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a75d18cb-0d66-4436-a3b2-be1c2de6b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of MSE : \n",
      " [2.40656667 1.85976667 1.38603333 0.98536667 0.65776667 0.40323333\n",
      " 0.22176667 0.11336667 0.07803333 0.11576667 0.22656667 0.41043333\n",
      " 0.66736667 0.99736667 1.40043333] \n",
      "\n",
      "Min MSE index : 8 \n",
      "\n",
      "Minimum MSE =  0.07803333333333334 \n",
      "\n",
      "Optimal Beta =  0.08999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "errs_arr = np.array(errors)\n",
    "print(\"Array of MSE : \\n\", errs_arr, \"\\n\")\n",
    "\n",
    "min_err_index = errs_arr.argmin()\n",
    "print(\"Min MSE index :\", min_err_index, \"\\n\")\n",
    "\n",
    "print(\"Minimum MSE = \",errs_arr[min_err_index], \"\\n\")\n",
    "print(\"Optimal Beta = \", betas[min_err_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fcd03f1-46b2-45ac-bf3b-370954b690d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal beta is: 0.08999999999999998\n"
     ]
    }
   ],
   "source": [
    "# original cozum\n",
    "# Array containing the MSE for each beta\n",
    "errors = np.array(errors)\n",
    "\n",
    "# List containing the betas that have been tested\n",
    "betas = np.linspace(start = 0.01, stop = 0.15, num = 15)\n",
    "\n",
    "# Index of the beta that minimizes the MSE \n",
    "index_beta_optimal = errors.argmin()\n",
    "\n",
    "# Optimal beta \n",
    "beta_optimal = betas[index_beta_optimal]\n",
    "\n",
    "print(\"The optimal beta is:\", beta_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5156ace6-8a1d-43a9-badc-9a9f10af3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "e) What are the heights predicted by this optimal ğ›½âˆ—? The heights predicted by the model are given by the vector ğ‘¦Ì‚ =ğ‘‹ğ›½âˆ—\n",
    "\n",
    "    .\n",
    "\n",
    "(f) Compare the predicted heights to the actual heights of the individuals. \n",
    "For example, you can compute the average absolute difference between the predicted and true values using the absolute value (np.abs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "597b0666-7aa7-4e4d-b79c-2977407df38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted heights :  [2.16 1.62 1.26]\n",
      "Real heights      :  [1.88 1.68 1.65]\n",
      "Erros             :  [0.28 0.06 0.39]\n",
      "Average of errors :  0.2433333333333334\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "y_predict = X.dot(beta_optimal)\n",
    "print(\"Predicted heights : \",y_predict)\n",
    "\n",
    "\n",
    "print(\"Real heights      : \", y)\n",
    "\n",
    "errors_ = np.abs(y - y_predict)\n",
    "\n",
    "print(\"Erros             : \", errors_)\n",
    "\n",
    "print(\"Average of errors : \", errors_.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fc243a7-cee4-45cd-ae1d-fba7d41c7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted heights: \n",
      " [2.16 1.62 1.26]\n",
      "\n",
      " Real heights: \n",
      " [1.88 1.68 1.65]\n",
      "\n",
      " The model makes an average mistake of 0.2433333333333334 metres.\n"
     ]
    }
   ],
   "source": [
    "y_hat = X.dot(beta_optimal)\n",
    "print(\"Predicted heights: \\n\", y_hat)\n",
    "\n",
    "print(\"\\n Real heights: \\n\", y)\n",
    "\n",
    "print(\"\\n The model makes an average mistake of\", np.abs(y - y_hat).mean(), \"metres.\")\n",
    "\n",
    "# The predicted heights are incorrect but approximately very close to the real sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1a1d9-c745-411a-a0ce-2ddad14b8b4f",
   "metadata": {},
   "source": [
    "# Introduction to DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f6e66-9086-413d-bb39-9ac94b3d171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Introduction\n",
    "\n",
    "    The pandas module has been developed to provide Python with the tools necessary to manipulate and analyze large volumes of data.\n",
    "\n",
    "    Pandas introduces the DataFrame class, an array-like data structure that offers more advanced data manipulation and exploration than NumPy arrays.\n",
    "\n",
    "    The main features of pandas are:\n",
    "\n",
    "            data recovery from files (CSV, Excel tables, etc.)\n",
    "\n",
    "            handling this data (deletion / addition, modification, statistical visualization, etc.).\n",
    "\n",
    "    This notebook aims at:\n",
    "\n",
    "            Understanding the format of a DataFrame.\n",
    "\n",
    "            Creating a first Dataframe.\n",
    "\n",
    "            Carrying out a first exploration of a dataset using the DataFrame class.\n",
    "\n",
    "    (a) Import the pandas module under the name pd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aceceba-444c-448d-a5f8-dc7ff2f680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac49d-b23c-4f2e-8985-e018021076ed",
   "metadata": {},
   "source": [
    "## Format of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be53471-b41b-46b6-a130-fe158f45df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Format of a DataFrame\n",
    "\n",
    "    A DataFrame is in the form of a matrix whose rows and columns each have an index. Typically, columns are indexed by name and rows by unique identifiers.\n",
    "\n",
    "    A DataFrame is used to store a database. The different entries in the database (individuals, animals, objects, etc.) are the different lines and their features are the different columns:\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    0 \tRobert \tM \t174 \t23\n",
    "    1 \tMark \tM \t182 \t40\n",
    "    2 \tAline \tF \t169 \t56\n",
    "\n",
    "            The DataFrame above groups together information on 3 individuals: the DataFrame therefore has 3 lines.\n",
    "\n",
    "            For each of these individuals, there are 4 variables (name, gender, height and age) : therefore, the DataFrame has 4 columns.\n",
    "\n",
    "    The column containing the numbering of the lines is called the index and is not managed in the same way as other columns of the DataFrame.\n",
    "\n",
    "    The index can be set by default (will follow the row numbering), defined with one (or several) of the columns of the DataFrame or even defined with a list that we specify.\n",
    "\n",
    "    Example: Default indexing (line numbering), you don't have to specify anything :\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    0 \tRobert \tM \t174 \t23\n",
    "    1 \tMark \tM \t182 \t40\n",
    "    2 \tAline \tF \t169 \t56\n",
    "\n",
    "    Example: Indexing by the column 'Name':\n",
    "    \tGender \tHeight \tAge\n",
    "    Robert \tM \t174 \t23\n",
    "    Mark \tM \t182 \t40\n",
    "    Aline \tF \t169 \t56\n",
    "\n",
    "    Example: Indexing by the list ['person_1', 'person_2', 'person_3']:\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    person_1 \tRobert \tM \t174 \t23\n",
    "    person_2 \tMark \tM \t182 \t40\n",
    "    person_3 \tAline \tF \t169 \t56\n",
    "\n",
    "    We will detail later how to define the index when creating a DataFrame.\n",
    "\n",
    "    The DataFrame class has several advantages over aNumpy array:\n",
    "\n",
    "            Visually, a DataFrame is much more readable thanks to more explicit column and row indexing.\n",
    "\n",
    "            Within the same column the elements are of the same type but from one column to another, the type of the elements may vary, which is not the case of Numpy arrays which only support data of the same type.\n",
    "\n",
    "            The DataFrame class contains more methods for handling and preprocessing databases, while NumPy specializes instead in optimized computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14cd18-7069-478b-8dd2-453997e22272",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f19e82-c37a-4d24-8c0e-22fbe833545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Creation of a DataFrame: from a NumPy array\n",
    "\n",
    "    It is possible to directly create a DataFrame from a NumPy array using the DataFrame() constructor. The disadvantage of this method is that it is not very practical and the data type is necessarily the same for all the columns.\n",
    "\n",
    "    Let's take a closer look at the header of this constructor.\n",
    "\n",
    "    pd.DataFrame(data, index, columns, ...)\n",
    "\n",
    "            The data parameter contains the data to be formatted (NumPy array, list, dictionary or another DataFrame).\n",
    "\n",
    "            The index parameter, if specified, must be a list containing the indices of the entries.\n",
    "\n",
    "            The columns parameter, if specified, must be a list containing the name of the columns.\n",
    "\n",
    "    For other parameters, you can consult the Python documentation.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # Creation of a NumPy array with 3 rows and 4 columns\n",
    "    array = np.array ([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8],\n",
    "                       [9, 10, 11, 12]])\n",
    "\n",
    "    # Instantiation of a DataFrame\n",
    "    df = pd.DataFrame (data = array, # The data to format\n",
    "                       index = ['i_1', 'i_2', 'i_3'], # The indices of each entry\n",
    "                       columns = ['A', 'B', 'C', 'D']) # The name of the columns\n",
    "\n",
    "    This produces the following DataFrame:\n",
    "    \tA \tB \tC \tD\n",
    "    i_1 \t1 \t2 \t3 \t4\n",
    "    i_2 \t5 \t6 \t7 \t8\n",
    "    i_3 \t9 \t10 \t11 \t12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584ee0d-65a2-4538-97ae-ef12f54a1e14",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd9a97-cf59-421b-9c24-aed6c1a6ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Creation of a DataFrame: from a dictionary\n",
    "\n",
    "    Another way to create a DataFrame is to use a dictionary. Thanks to this technique, the columns can be of different type and their names are already given when creating the DataFrame.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # Creation of a dictionary\n",
    "    dictionary = {'A': [1, 5, 9],\n",
    "                  'B': [2, 6, 10],\n",
    "                  'C': [3, 7, 11],\n",
    "                  'D': [4, 8, 12]}\n",
    "\n",
    "    # Instantiation of a DataFrame\n",
    "    df = pd.DataFrame (data = dictionary,\n",
    "                       index = ['i_1', 'i_2', 'i_3'])\n",
    "\n",
    "    This produces the same DataFrame as before:\n",
    "    \tA \tB \tC \tD\n",
    "    i_1 \t1 \t2 \t3 \t4\n",
    "    i_2 \t5 \t6 \t7 \t8\n",
    "    i_3 \t9 \t10 \t11 \t12\n",
    "\n",
    "The manager of a grocery store has the following stock of food products:\n",
    "\n",
    "    100 jars of honey with an expiration date of 08/10/2025 and worth â‚¬2 each.\n",
    "\n",
    "    55 packets of flour expiring on 09/25/2024 each costing â‚¬ 3.\n",
    "\n",
    "    1800 bottles of wine costing â‚¬ 10 per unit and expiring on 10/15/2023.\n",
    "\n",
    "    (a) From a dictionary, create and display a DataFrame df that contains for each product:\n",
    "\n",
    "            Its name.\n",
    "            Its expiration date.\n",
    "            Its quantity.\n",
    "            Its price per unit.\n",
    "\n",
    "You will choose relevant column names and the index will be the default one (in this case we do not specify the index parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b09c8dfa-50e4-4078-ae09-eb8aa5c5da58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Expiration date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price per unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honey</td>\n",
       "      <td>10/08/2025</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flour</td>\n",
       "      <td>25/09/2024</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine</td>\n",
       "      <td>15/10/2023</td>\n",
       "      <td>1800</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Expiration date  Quantity  Price per unit\n",
       "0   honey      10/08/2025       100               2\n",
       "1   flour      25/09/2024        55               3\n",
       "2    wine      15/10/2023      1800              10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your Code\n",
    "\n",
    "dictionary = {\"Product\"          : ['honey', 'flour', 'wine'],\n",
    "              \"Expiration date\"  : ['10/08/2025', '25/09/2024', '15/10/2023'],\n",
    "              \"Quantity\"         : [100, 55, 1800], \n",
    "              \"Price per unit\"   : [2, 3, 10]}\n",
    "\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74731371-de11-4edb-ab26-d923820f088e",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e0d47-d614-48ad-bda0-207ca0f70beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Creation of a DataFrame: from a data file\n",
    "\n",
    "    Most often a DataFrame is created directly from a file containing the data of interest. The file's format can be a CSV, Excel, txt, etc.\n",
    "\n",
    "    The most common format is the CSV format, which stands for Comma-Separated Values and denotes a spreadsheet-like file whose values are separated by commas.\n",
    "\n",
    "    Here is an example:\n",
    "\n",
    "    A, B, C, D,\n",
    "    1, 2, 3, 4,\n",
    "    5, 6, 7, 8,\n",
    "    9, 10, 11, 12\n",
    "\n",
    "    In this format:\n",
    "\n",
    "            The first line contains the name of the columns, but sometimes the name of the columns is not filled in.\n",
    "\n",
    "            Each line corresponds to an entry in the database.\n",
    "\n",
    "            The values are separated by a separator character. In this example, it is ',' but it could be a ';'.\n",
    "\n",
    "    To import the data into a DataFrame, we need to use the read_csv function of pandas whose header is as follows:\n",
    "\n",
    "    pd.read_csv(filepath_or_buffer, sep = ',', header = 0, index_col = 0 ...)\n",
    "\n",
    "    The essential arguments of the pd.read_csv function to know are:\n",
    "\n",
    "            filepath_or_buffer: The path of the .csv file relative to the execution environment.\n",
    "                If the file is in the same folder as the Python environment, just fill in the name of the file.\n",
    "                This path must be entered in the form of character string.\n",
    "\n",
    "            sep: The character used in the .csv file to to separate the different columns.\n",
    "                This argument must be specified as character.\n",
    "\n",
    "            header: The number of the row that contains the names of the columns.\n",
    "                If for example the column names are entered in the first line of the .csv file, then we must specify header = 0.\n",
    "                If the names are not included, we will put header = None.\n",
    "\n",
    "            index_col: The name or number of the column containing the indices of the database.\n",
    "                If the database entries are indexed by the first column, you will need to fill in index_col = 0.\n",
    "                Alternatively, if the entries are indexed by a column which bears the name \"Id\", we can specify index_col = \"Id\".\n",
    "\n",
    "    This function will return an object of type DataFrame which contains all the data of the file.\n",
    "\n",
    "    (a) Load the data contained in the file transactions.csv into aDataFrame named transactions:\n",
    "\n",
    "            The file is located in the same folder as the environment of this notebook.\n",
    "            Columns are separated by commas.\n",
    "            The names of the columns are in the first line of the file.\n",
    "            The rows of the database are indexed by the \"transaction_id\" column which is also the first column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b3425-52d0-4993-b3c4-90c7b9d3dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# You can directly specify the name of the column containing the indices\n",
    "\n",
    "transactions = pd.read_csv(filepath_or_buffer = 'transactions.csv', # file path\n",
    "                           sep = ',',                               # character separating values\n",
    "                           header = 0,                              # number of the row containing column names\n",
    "                           index_col = 'transaction_id')            # name of the column that indexes the entries\n",
    "\n",
    "\n",
    "# You can also directly enter the number of the column that indexes the entries\n",
    "\n",
    "transactions = pd.read_csv(filepath_or_buffer = 'transactions.csv',\n",
    "                           sep = ',',\n",
    "                           header = 0,\n",
    "                           index_col = 0) # number of the column that indexes the entries\n",
    "\n",
    "# We loaded the transactions.csv file in theDataFrame transactions which gathers a history of transactions carried out between 2011 and 2014. \n",
    "#In the next section, we will study this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506e9cf-2b48-465b-8748-1a720974c5ec",
   "metadata": {},
   "source": [
    "## First exploration of a dataset using the DataFrame class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cde126-fb58-4743-b1f6-718a3591a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. First exploration of a dataset using the DataFrame class\n",
    "\n",
    "    The rest of this notebook briefly presents the main methods of the DataFrame class which will allow us to do a quick analysis of our data set, that is:\n",
    "\n",
    "            Having a brief overview of the data (head method,columns and shape attributes).\n",
    "\n",
    "            Selecting values in the DataFrame (loc and iloc methods).\n",
    "\n",
    "            Carrying out a quick statistical study of our data (describe and value _counts methods)\n",
    "\n",
    "    As a reminder, to apply a method to an object in Python (such as a DataFrame for example), you must add the method as a suffix of the object. Example: my_object.my_method()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5764ad-c505-4224-ab2a-79cf30635a73",
   "metadata": {},
   "source": [
    "## Visualization of a DataFrame: head method, columns and shape attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384dad2-969a-4c11-b6a5-b8dc406c7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Visualization of a DataFrame: head method, columns and shape attributes\n",
    "\n",
    "        It is possible to have a preview of a dataset by displaying only the first lines of the DataFrame.\n",
    "\n",
    "    For that, we must use the head() method, specifying as an argument the number of lines that we want to display (by default 5).\n",
    "\n",
    "    It is also possible to preview the last lines using the tail() method which is applied in the same way:\n",
    "\n",
    "    # Display of the first 10 lines of my_dataframe\n",
    "    my_dataframe.head(10)\n",
    "\n",
    "    (a) Display the first 20 lines of the transactions DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f4645-75e9-4027-9a08-e79ac61c3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b3c4-aecb-439b-93fa-f4dd4b52f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Display the last 10 lines of the transactions DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4349a8-0ef4-4632-8491-ff8b9818fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e01940-a6d8-496d-aab7-6f4b5ba55112",
   "metadata": {},
   "outputs": [],
   "source": [
    "     \tA \tB \tC \tD\n",
    "    i_ 1 \t1 \t2 \t3 \t4\n",
    "    i _2 \t5 \t6 \t7 \t8\n",
    "    i_ 3 \t9 \t10 \t11 \t12\n",
    "\n",
    "    # Display of df DataFrame columns\n",
    "    print(df.columns)\n",
    "    >>> ['A', 'B', 'C', 'D']\n",
    "\n",
    "    The list of the column names can be used to iterate over the columns of a DataFrame within a loop.\n",
    "\n",
    "    It can be interesting to know how many transactions (rows) and how many features (columns) the dataset contains.\n",
    "\n",
    "    For this we will use the shape attribute of the DataFrame class which displays the dimensions of our DataFrame in the form of a tuple (number of rows, number of columns):\n",
    "\n",
    "    # Display the dimensions of df\n",
    "    print (df.shape)\n",
    "    >>> (3,4)\n",
    "\n",
    "    (c) Display the dimensions of the DataFrame transactions as well as the name of the 5th column. Remember that in Python the indices start from 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977eca5f-fb8e-4fa1-adcd-4547fe48c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "print(transactions.shape)\n",
    "\n",
    "transactions.columns[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad1b8e-26ef-475c-a814-c4c9b7d71519",
   "metadata": {},
   "source": [
    "## Selecting columns from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d405d9b-56ac-49d5-a196-a7a9dec5176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Selecting columns from a DataFrame\n",
    "\n",
    "    Extracting columns from a DataFrame is almost identical to extracting data from a dictionary.\n",
    "\n",
    "    To extract a column from a DataFrame, all we have to do is enter between brackets the name of the column to extract. To extract several columns, we must enter between brackets the list of the names of the columns to extract:\n",
    "\n",
    "    # Display of the 'cust_id' column\n",
    "    print(transactions['cust_id'])\n",
    "\n",
    "    # Extraction of 'cust_id' and 'Qty' columns from transactions\n",
    "    cust_id_qty = transactions[[\"cust_id\", \"Qty\"]]\n",
    "\n",
    "    cust_id_qty is a new DataFrame containing only the 'cust_id' and 'Qty' columns.\n",
    "\n",
    "    The display of the first 3 lines of cust_id_qty yields:\n",
    "\n",
    "\n",
    "\n",
    "    transactions_id \tcust_id \tQty\n",
    "    80712190438 \t270351 \t-5\n",
    "    29258453508 \t270384 \t-5\n",
    "    51750724947 \t273420 \t-2\n",
    "\n",
    "    When we prepare a dataset for later use, it is better to separate the categorical variables from the quantitative variables:\n",
    "\n",
    "            A categorical variable is a variable that takes only a finite number of modalities.\n",
    "\n",
    "            The categorical variables of the DataFrame transactions are: ['cust_id', 'tran_date', 'prod_subcat_code', 'prod_cat_code', 'Store_type'].\n",
    "\n",
    "            A quantitative variable is a variable that measures a quantity that can take an infinite number of values.\n",
    "\n",
    "            The quantitative variables of transactions are: ['Qty', 'Rate', 'Tax', 'total_amt'].\n",
    "\n",
    "    This distinction is made because some basic operations like calculating an average only make sense for quantitative variables.\n",
    "\n",
    "    (a) In a DataFrame named cat_vars, store the categorical variables of transactions.\n",
    "\n",
    "    (b) In a DataFrame named num_vars, store the quantitative variables of transactions.\n",
    "\n",
    "    (c) Display the first 5 lines of each DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a03c3-86c3-4613-9859-f6ca982d0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# Extraction of categorical variables\n",
    "cat_var_names = ['cust_id', 'tran_date', 'prod_subcat_code', 'prod_cat_code' , 'Store_type']\n",
    "cat_vars = transactions[cat_var_names]\n",
    "\n",
    "# Extraction of quantitative variables\n",
    "num_var_names = ['Qty', 'Rate', 'Tax', 'total_amt']\n",
    "num_vars = transactions[num_var_names]\n",
    "\n",
    "# Display of the first 5 lines of each DataFrame\n",
    "print (\"Categorical variables: \\n\")\n",
    "print (cat_vars.head(), \"\\n \\n\")\n",
    "\n",
    "print (\"Quantitative variables: \\n\")\n",
    "print (num_vars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c5095-e2fc-4d01-9b39-0a5ecf0b6da8",
   "metadata": {},
   "source": [
    "## Selecting rows of a DataFrame: loc and iloc methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cd06a-65a0-4d45-bd0a-ef13608965c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Selecting rows of a DataFrame: loc and iloc methods\n",
    "\n",
    "    To extract one or more rows from a DataFrame, we use the loc method. loc is a very special type of method because the arguments are filled in between square brackets and not between parentheses. Using this method is very similar to indexing lists.\n",
    "\n",
    "    In order to retrieve the line of index i of a DataFrame, all we have to do is enter i as an argument of the loc method:\n",
    "\n",
    "    # We retrieve the line of index 80712190438 of the num_vars DataFrame\n",
    "    print(num_vars.loc[80712190438])\n",
    "\n",
    "    >>                 Rate    Tax  total_amt\n",
    "    >> transaction_id                         \n",
    "    >> 80712190438    -772.0  405.3    -4265.3\n",
    "    >> 80712190438     772.0  405.3     4265.3\n",
    "\n",
    "    In order to retrieve several rows, we can either:\n",
    "\n",
    "            Enter a list of indices.\n",
    "\n",
    "            Enter a slice by specifying the start and end indices of the slice. To use slicing with loc, the indices must be unique, which is not the case for transactions.\n",
    "\n",
    "    # We retrieve the rows at indices 80712190438, 29258453508 and 51750724947 from the transactions DataFrame\n",
    "    transactions.loc[[80712190438, 29258453508, 51750724947]]\n",
    "\n",
    "    loc can also take a column or list of columns as an argument in order to refine the data extraction:\n",
    "\n",
    "    # We extract the columns 'Tax' and 'total_amt' from the rows at index 80712190438 and 29258453508\n",
    "    transactions.loc[[80712190438, 29258453508], ['Tax', 'total_amt']]\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    transaction_id \tTax \ttotal_amt\n",
    "    80712190438 \t405.300 \t-4265.300\n",
    "    80712190438 \t405.300 \t4265.300\n",
    "    29258453508 \t785.925 \t-8270.925\n",
    "    29258453508 \t785.925 \t8270.925\n",
    "\n",
    "    The iloc method is used to index a DataFrame exactly like a numpy array, that is to say by only filling in the numeric indices of the rows and columns. This allows the use of slicing without constraint:\n",
    "\n",
    "    # Extraction of the first 4 rows and the first 3 columns of transactions\n",
    "    transactions.iloc[0:4, 0:3]\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    transaction_id \tcust_id \ttran_date \tprod_subcat_code\n",
    "    80712190438 \t270351 \t28-02-2014 \t1.0\n",
    "    29258453508 \t270384 \t27-02-2014 \t5.0\n",
    "    51750724947 \t273420 \t24-02-2014 \t6.0\n",
    "    93274880719 \t271509 \t24-02-2014 \t11.0\n",
    "\n",
    "    If the row indexing is the one by default (row numbering), the loc and iloc methods are equivalent.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83c629-6615-4a5a-93a8-4722f262494b",
   "metadata": {},
   "source": [
    "## Conditional indexing of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2eb568-f61d-4637-b60a-eb0ccefcaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Conditional indexing of a DataFrame\n",
    "\n",
    "    As with Numpy arrays, we can use conditional indexing to extract rows from a Dataframe that meet a given condition.\n",
    "\n",
    "    In the following illustration, we select the rows of the DataFrame df for which the column col 2 is equal to 3.\n",
    "\n",
    "\n",
    "    There are two syntaxes for conditionally indexing a DataFrame:\n",
    "\n",
    "\n",
    "    # We select the rows of the DataFrame df for which the column 'col 2' is equal to 3.\n",
    "    df[df['col 2'] == 3]\n",
    "\n",
    "    df.loc[df['col 2'] == 3]\n",
    "\n",
    "    If we want to assign a new value to these entries, we must absolutely use the loc method.\n",
    "\n",
    "    Indeed, indexing with the syntax df[df['col 2'] == 3] only returns a copy of these entries and does not provide access the memory location where the data is located.\n",
    "\n",
    "The manager of the transactions listed in the transactions DataFrame wishes to have access to the identifiers of customers who have made an online purchase (i.e. in a \"e-Shop\") as well as the date of the corresponding transaction.\n",
    "\n",
    "We have the following information about the columns of transactions:\n",
    "Column name \tDescription\n",
    "'cust_id' \tThe identifier of the customer\n",
    "'Store_type' \tThe type of store where the transaction took place\n",
    "'tran_date' \tThe date of the transaction\n",
    "\n",
    "    (a) In a DataFrame named transactions_eshop, store the transactions that took place in an \"e-Shop\" type store.\n",
    "\n",
    "    (b) In another DataFrame named transactions_id_date, store the customer identifiers and the transaction date of the transactions_eshop DataFrame.\n",
    "\n",
    "    (c) Display the first 5 rows of transactions_id_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc8cd2-67f9-4d93-a76b-da33e30be988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# Creation of transactions_eshop by conditional indexing\n",
    "transactions_eshop = transactions.loc[transactions['Store_type'] == 'e-Shop']\n",
    "\n",
    "# Extraction of the 'cust_ id' and 'tran _date' columns\n",
    "transactions_id_date = transactions_eshop[['cust_id', 'tran_date']]\n",
    "\n",
    "# Display of the first 5 lines of transactions_id_date\n",
    "transactions_id_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32d2a7-a0e1-4cb7-a73d-077d25755f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, the manager would like to have access to the transactions carried out by the client whose identifier is 268819.\n",
    "\n",
    "    (d) In a DataFrame named transactions_client_268819, store all transactions with client identifier 268819.\n",
    "\n",
    "    (e) A column in a DataFrame can be iterated over with a loop exactly like a list (for value in df['column']:). Using a for loop on the 'total_amt' column, compute and display the total transaction amount for the client with identifier 268819.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ad531-d02a-4189-8b02-fd0d651e778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# Extraction of the transactions ofthe customer which identifier is 268819\n",
    "transactions_client_268819 = transactions[transactions['cust_id'] == 268819]\n",
    "\n",
    "\n",
    "# Computation of the total amount of transactions\n",
    "total = 0\n",
    "\n",
    "# For each amount in the column 'total_amt'\n",
    "for amount in transactions_client_268819['total_amt']:\n",
    "    # We sum the amounts\n",
    "    total += amount\n",
    "    \n",
    "print(total)\n",
    "\n",
    "# Second Way\n",
    "transactions.loc[transactions.cust_id == 268819]['total_amt'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd9401-1f16-4894-8563-81bd24739fad",
   "metadata": {},
   "source": [
    "## Quick statistical study of the data in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf4ace-48c7-4656-9e63-9b55fd35b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Quick statistical study of the data in a DataFrame.\n",
    "\n",
    "    The describe method of a DataFrame returns a summary of the descriptive statistics (min, max, mean, quantiles,...) of its quantitative variables. It is therefore a very useful tool for a first visualisation of the type and distribution of these variables.\n",
    "\n",
    "    To analyse the categorical variables, it is recommended to start by using the value_counts method which returns the number of occurrences for each modality of these variables. The value_counts method cannot be used directly on a DataFrame but only on the columns of the DataFrame which are objects of the pd.Series class.\n",
    "\n",
    "    (a) Use the describe method of the DataFrame transactions.\n",
    "\n",
    "    (b) The quantitative variables of transactions are 'Qty', 'Rate', 'Tax' and total_amt'. By default, are the statistics produced by the describe method only computed on the quantitative variables?\n",
    "\n",
    "    (c) Display the number of occurrences of each modality of the Store_type column using the value_counts method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987b0a5-7c14-4c56-a396-35867eb76e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "transactions.describe()\n",
    "\n",
    "transactions['Store_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbb9de-6372-4b7d-acc4-87782b2cbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The describe method computed statistics on the variables cust_id, prod_subcat_code and prod_cat_code while these are categorical variables.\n",
    "\n",
    "    Of course, these statistics make no sense. The describe method has treated these variables as quantitative because the modalities they take are of numerical type.\n",
    "\n",
    "    This is why it is necessary to pay attention to the results returned by the describe method and always take a step back to remember what the variables are reflecting.\n",
    "\n",
    "    The manager wishes to make a quick report on the characteristics of the transactions DataFrame: in particular, he wants to know the average amount spent as well as the maximum quantity purchased.\n",
    "\n",
    "    (d) What is the average total amount spent? We are interested in the 'total_amt' column of transactions.\n",
    "\n",
    "    (e) What is the maximum quantity purchased? We will look at the 'Qty' column of transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a4f91-cec0-4937-8791-1c07fddf2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "print('average total amount spent :', transactions['total_amt'].mean())\n",
    "print('maximum quantity purchased :', transactions['Qty'].max())\n",
    "\n",
    "transactions.describe()\n",
    "\n",
    "# Applying the describe method to the transactions DataFrame\n",
    "transactions.describe()\n",
    "\n",
    "# The average total amount spent is â‚¬2109.\n",
    "# The maximum quantity purchased is 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0e072-0760-44cd-90ce-017657bcedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some transactions have negative amounts.\n",
    "\n",
    "These are transactions that have been cancelled and refunded to the client. These amounts will disrupt the distribution of the amounts which gives us bad estimates of the mean and quantiles of the variable total_amt.\n",
    "\n",
    "    (f) What is the average amount of transactions with positive amounts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad9db6-7c1f-4aa4-ac8f-5b8c3548edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "\n",
    "transactions[transactions['total_amt'] > 0].describe()\n",
    "\n",
    "# the average amount of transactions with positive amounts is worth â‚¬2608 which is\n",
    "# â‚¬500 more than we had before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8634bb-9c81-4454-ae13-2a734d96c7a1",
   "metadata": {},
   "source": [
    "## Conclusion and recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40401943-1bc8-4a85-83e5-c02229c7c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Conclusion and recap\n",
    "\n",
    "    The DataFrame class of the pandas module will be your favorite data structure when exploring, analysing and processing datasets and databases.\n",
    "\n",
    "    In this brief introduction, you have learned to:\n",
    "\n",
    "            Create a DataFrame from a numpy array and a dictionary using the pd.DataFrame constructor.\n",
    "\n",
    "            Create a DataFrame from a .csv file using the pd.read_csv function.\n",
    "\n",
    "            Display the first and last lines of a DataFrame using the head and tail methods.\n",
    "\n",
    "            Select one or more columns of a DataFrame by entering their names in square brackets as in a dictionary.\n",
    "\n",
    "            Select one or more lines of a DataFrame by filling in their index using the loc and iloc methods.\n",
    "\n",
    "            Select the lines of a DataFrame that meet a specific condition using conditional indexing.\n",
    "\n",
    "            Perform a quick statistical study of the quantitative variables of a DataFrame using the describe method.\n",
    "\n",
    "    The dataset transactions we used is very clean. The variables are cleanly filled in and do not contain any missing value. In practice, this is rarely the case. This is why in the following notebook we will see how to clean datasets with pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95760230-9927-4cc7-92e3-5e34e4da1d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#e)\n",
    "df_first = df.drop_duplicates(keep = 'first')\n",
    "df_repStore = df_first.replace(['e-Shop', 'TeleShop', 'MBR', 'Flagship store', np.nan], [1, 2, 3, 4, 0])\n",
    "df_repStore.head().dtypes\n",
    "\n",
    "#f)\n",
    "dict1 = {'Store_type' : 'int',\n",
    "        'prod_subcat_code' : 'int'}\n",
    "\n",
    "df_repStore.astype(dict1).dtypes\n",
    "df_repStore.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53f840-7c28-4c97-b757-da527ebd905c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d8fcb14-b45a-4e69-ba9b-f238091c552a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brown</td>\n",
       "      <td>Aus</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Duch</td>\n",
       "      <td>Fra</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hana</td>\n",
       "      <td>De</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brown</td>\n",
       "      <td>Aus</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name country  age\n",
       "0  Brown     Aus   33\n",
       "1   Duch     Fra   25\n",
       "2   Hana      De   38\n",
       "3  Brown     Aus   33"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1 = {'name' : ['Brown', 'Duch', 'Hana', 'Brown'],\n",
    "         'country' : ['Aus', 'Fra', 'De', 'Aus'],\n",
    "         'age' : [33, 25, 38, 33]}\n",
    "\n",
    "df = pd.DataFrame(dict1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efed4027-3353-4c96-aba3-cd23bbdf483f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name       object\n",
       "country    object\n",
       "age         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first = df.drop_duplicates()\n",
    "df_first\n",
    "df_first.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "117ab14a-d496-402e-ac83-acde4714dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name       object\n",
      "country    object\n",
      "age         int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "name       object\n",
       "country    object\n",
       "age        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_first.dtypes)\n",
    "\n",
    "dict1 = {'age' :'object'}\n",
    "\n",
    "df_first.astype(dict1).dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f42e41d2-d886-4cb5-951a-01ca9c96f336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name       object\n",
       "country    object\n",
       "age         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_first.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab510d-1c70-4ed6-ab9d-4aef7a4a6120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scpraing_portfolio_deneme",
   "language": "python",
   "name": "web_scpraing_portfolio_deneme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

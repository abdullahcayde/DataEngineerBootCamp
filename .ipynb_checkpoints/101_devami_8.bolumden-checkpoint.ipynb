{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a654d321-c9db-4bd9-a83d-8570c097a223",
   "metadata": {},
   "source": [
    " NumPy for Data Science\n",
    "Operations on Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a022b1-fd55-4b00-91c6-a3e89c53125d",
   "metadata": {},
   "source": [
    "# Operations on Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d119db-17ed-4898-bb4b-a7cf3d199906",
   "metadata": {},
   "source": [
    "## Arithmetic operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ea4c6-ac29-4980-ad4f-302fed0fa0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Arithmetic operators\n",
    "\n",
    "    Numpy allows you to perform mathematical operations on arrays in an optimized way.\n",
    "\n",
    "            Applying one of the basic arithmetic operations (/, *, -,+,**) between an array and a value will apply the operation to each of the elements of the array.\n",
    "\n",
    "            It is also possible to perform an arithmetic operation between two arrays. This will apply the operation between each pair of elements.\n",
    "\n",
    "        # Creation of two arrays with 2 values\n",
    "        a = np.array([4, 10])\n",
    "        b = np.array([6, 7])\n",
    "\n",
    "        # Multiplication between two arrays\n",
    "        print(a * b)\n",
    "        >>> [24, 70]\n",
    "\n",
    "    (a) Import the package numpy under the name np.\n",
    "\n",
    "    (b) Create an array of dimensions 10x4 filled with ones.\n",
    "\n",
    "    (c) Using a for loop and the enumerate function, multiply each row by its index. In order to modify the matrix,\n",
    "    it must be accessed through indexing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b699c5-f06e-4721-b3e1-4b0597634f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [1. 1.]\n",
      "1 [1. 1.]\n",
      "2 [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.ones((3,2))\n",
    "\n",
    "for n, arr in enumerate(X):\n",
    "    print(n, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf2d6424-d1dd-4baa-86bc-453e96e2055d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 2. 3.]\n",
      " [0. 1. 2. 3.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.],\n",
       "       [0., 1., 4., 9.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If the array of the value is bigger than 1 then compute 2 powers of value \n",
    "X = np.ones((10,4))\n",
    "X = X * [i for i in range(4)]\n",
    "print(X[:2])\n",
    "\n",
    "for i, row in enumerate(X):\n",
    "    for j in row:\n",
    "        if j > 1:\n",
    "            X[i,int(j)] **= 2\n",
    "            \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c90c141-1b12-4be3-ada6-e7a8379f6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.]\n",
      "[1. 1. 1. 1.]\n",
      "[2. 2. 2. 2.]\n",
      "[3. 3. 3. 3.]\n",
      "[4. 4. 4. 4.]\n",
      "[5. 5. 5. 5.]\n",
      "[6. 6. 6. 6.]\n",
      "[7. 7. 7. 7.]\n",
      "[8. 8. 8. 8.]\n",
      "[9. 9. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "import numpy as np\n",
    "\n",
    "X = np.ones((10,4))\n",
    "\n",
    "for n, arr in enumerate(X):\n",
    "    print(n * arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8178ca0f-6630-49e4-9cb9-2fd9a8d7e1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 2. 2. 2.]\n",
      " [3. 3. 3. 3.]\n",
      " [4. 4. 4. 4.]\n",
      " [5. 5. 5. 5.]\n",
      " [6. 6. 6. 6.]\n",
      " [7. 7. 7. 7.]\n",
      " [8. 8. 8. 8.]\n",
      " [9. 9. 9. 9.]]\n"
     ]
    }
   ],
   "source": [
    "#original cozum \n",
    "import numpy as np\n",
    "\n",
    "M = np.ones((10, 4))\n",
    "\n",
    "# For each row of the matrix M\n",
    "for i, row in enumerate(M):\n",
    "    # We multiply the row by its index\n",
    "    M[i,:] = row*i\n",
    "    # Alternatively M[i,:]* = i\n",
    "    \n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a153d4-c423-4e0a-9e12-7f9566ab73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "As explained above, the * operator allows you to compute an element-wise product between arrays.\n",
    "\n",
    "For example:\n",
    "\n",
    "(5310)∗(2048)=(10040)\n",
    "\n",
    "The matrix product, in the mathematical sense of the term, can be performed using the dot method of a numpy array:\n",
    "\n",
    "# Creation of two arrays of size 2x2\n",
    "M = np.array([[5, 1],\n",
    "              [3, 0]])\n",
    "\n",
    "N = np.array([[2, 4],\n",
    "              [0, 8]])\n",
    "\n",
    "# Matrix product between the two arrays\n",
    "print(M.dot(N))\n",
    ">>> [[10, 28]\n",
    ">>>  [6, 12]]\n",
    "\n",
    "Indeed, if we recall the matrix product:\n",
    "\n",
    "𝑀=([5, 1],\n",
    "    [3, 0]),\n",
    "𝑁=([2, 4],\n",
    "    [0, 8])\n",
    "\n",
    "𝑀𝑁=(5310)(2048)=((5∗2)+(1∗0)(3∗2)+(0∗0)(5∗4)+(1∗8)(3∗4)+(0∗8))=[[10, 28],\n",
    "                                                                 [ 6, 12]])\n",
    "Let's consider the following matrix:\n",
    "\n",
    "𝐴=(1−1−11)\n",
    "\n",
    "    (d) Define a function named powerA taking as argument an integer n greater than 1. This function must compute and return 𝐴^𝑛\n",
    "\n",
    "    (according to matrix product).\n",
    "\n",
    "    (e) Calculate and display 𝐴^2, 𝐴^3 and 𝐴^4. Can you guess a general formula for 𝐴^𝑛?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4367ecc1-2671-4d44-b904-541cb747ece7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[10, 28],\n",
       "        [ 6, 12]]),\n",
       " array([[10, 28],\n",
       "        [ 6, 12]]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = np.array([[5, 1],\n",
    "              [3, 0]])\n",
    "\n",
    "\n",
    "N = np.array([[2, 4],\n",
    "              [0, 8]])\n",
    "\n",
    "\n",
    "\n",
    "def powerA(n, A, B):\n",
    "\n",
    "    for i in range(n):\n",
    "        at = A @ B\n",
    "        A = A.dot(B)\n",
    "    return A, at         \n",
    "\n",
    "\n",
    "powerA(1, M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ecebc8e-e6f1-42c8-9529-b1190e7e1e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A**2: \n",
      " [[ 2 -2]\n",
      " [-2  2]] \n",
      "\n",
      "A**3: \n",
      " [[ 4 -4]\n",
      " [-4  4]] \n",
      "\n",
      "A**4: \n",
      " [[ 8 -8]\n",
      " [-8  8]] \n",
      "\n",
      "A general formula of A**n is given by:\n",
      "[2**(n-1), -2**(n-1)]\n",
      "[-2**(n-1), 2**(n-1)]\n"
     ]
    }
   ],
   "source": [
    "# original cozum\n",
    "def powerA(n):\n",
    "    # A is initialized to the identity matrix\n",
    "    A = np.array([[1, 0],\n",
    "                  [0, 1]])\n",
    "    \n",
    "    # This matrix B will be used to calculate the powers of A\n",
    "    B = np.array([[1, -1],\n",
    "                  [-1, 1]])\n",
    "    \n",
    "    # We multiply A by B n times to get A**n\n",
    "    for i in range(n):\n",
    "        A = A.dot(B)\n",
    "        \n",
    "    return A\n",
    "\n",
    "print (\"A**2: \\n\", powerA(2), \"\\n\")\n",
    "print (\"A**3: \\n\", powerA(3), \"\\n\")\n",
    "print (\"A**4: \\n\", powerA(4), \"\\n\")\n",
    "\n",
    "print (\"A general formula of A**n is given by:\")\n",
    "print (\"[2**(n-1), -2**(n-1)]\")\n",
    "print (\"[-2**(n-1), 2**(n-1)]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b669a8a1-f32b-4aa3-9cad-2f74e52d28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "In a two-dimensional plane, rotations around the origin are represented by the matrices of the form:\n",
    "\n",
    "𝐴(𝜃)=(cos(𝜃) −sin(𝜃)\n",
    "     sin(𝜃)  cos(𝜃))\n",
    "where 𝜃 defines the angle of the rotation in radians. Thus, the rotation of a point with coordinates 𝑥=(𝑥1𝑥2) is calculated thanks to the formula 𝑥̃ =𝐴(𝜃)𝑥\n",
    "\n",
    "    (f) Define a function named rotation_matrix taking as argument a number 𝜃\n",
    "\n",
    "(theta) and returning the associated 𝐴(𝜃) matrix. You can calculate the cos and sin\n",
    "\n",
    "    functions using the np.cos andnp.sin functions of numpy.\n",
    "\n",
    "    (g) Let 𝑥=(1\n",
    "                1)\n",
    "\n",
    "be a point. Calculate and display 𝐴(𝜋)𝑥, which is equivalent to rotating 180º around the origin. You have access to the constant 𝜋\n",
    "\n",
    "    with the np.pi instruction.\n",
    "\n",
    "    (h) Show that 𝐴(𝜋4)𝐴(3𝜋4)𝑥=𝐴(𝜋)𝑥\n",
    "\n",
    "    .\n",
    "\n",
    "    (i) Generally speaking, for any angle, 𝐴(𝜃1)𝐴(𝜃2)𝑥=𝐴(𝜃1+𝜃2)𝑥\n",
    "\n",
    ". Why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f08656b-67e4-4245-ba64-14bf2f9b5c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [-1. -1.]\n",
      "0.0 [-1. -1.]\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def rotation_matrix(theta, X):\n",
    "    Y = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "    return Y.dot(X)\n",
    "\n",
    "#g)\n",
    "x = np.array([1,1])\n",
    "\n",
    "x_pi = rotation_matrix(np.pi, x)\n",
    "\n",
    "print(x, x_pi )\n",
    "\n",
    "#h)\n",
    "a_pi_4 = rotation_matrix(np.pi/4, x)\n",
    "a_3pi_4 = rotation_matrix(3*np.pi/4, x)\n",
    "\n",
    "print(a_pi_4.dot(a_3pi_4), x_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d63605dc-6bfb-49ad-90f0-6d6d617df23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1] [-1. -1.]\n",
      "[1 1] [-1. -1.] \n",
      "\n",
      "a_theta1 \n",
      "\n",
      " [[ 1.00000000e+00 -1.96438672e-15]\n",
      " [ 1.96438672e-15  1.00000000e+00]] \n",
      " a_theta2 \n",
      "\n",
      " [[ 1.00000000e+00 -3.92877345e-15]\n",
      " [ 3.92877345e-15  1.00000000e+00]] \n",
      " a_sum \n",
      "\n",
      " [[ 1.00000000e+00  5.09502587e-14]\n",
      " [-5.09502587e-14  1.00000000e+00]] \n",
      "\n",
      "[1. 1.]\n",
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    Y = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "    return Y\n",
    "\n",
    "#g)\n",
    "x = np.array([1,1])\n",
    "\n",
    "x_pi = rotation_matrix(np.pi)\n",
    "\n",
    "print(x, x_pi.dot(x))\n",
    "\n",
    "#h)\n",
    "x = np.array([1,1])\n",
    "a_pi_4 = rotation_matrix(np.pi/4)\n",
    "a_3pi_4 = rotation_matrix(3*np.pi/4)\n",
    "\n",
    "print(x, a_pi_4.dot(a_3pi_4.dot(x)), \"\\n\")\n",
    "\n",
    "#i)\n",
    "pi = 100*np.pi\n",
    "pi_2 = 200*np.pi\n",
    "\n",
    "a_theta1 = rotation_matrix(pi)\n",
    "a_theta2 = rotation_matrix(pi_2)\n",
    "a_sum = rotation_matrix(pi + pi_2)\n",
    "\n",
    "print(\"a_theta1 \\n\\n\",a_theta1, \"\\n a_theta2 \\n\\n\", a_theta2, \"\\n a_sum \\n\\n\", a_sum, \"\\n\")\n",
    "print(a_theta1.dot(a_theta2.dot(x)))\n",
    "print(a_sum.dot(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab3211a5-6eff-46de-812f-d0c0e452ee13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = [1 1]\n",
      "A(pi)x = [-1. -1.]\n",
      "A(pi/4) A(3pi/4) x = [-1. -1.]\n",
      "\n",
      "\n",
      "Intuitively, A(theta_1) A(theta_2) = A(theta_1 + theta_2) because applying a rotation of angle theta_1 then\n",
      "applying another rotation of angle theta_2 is exactly the same as applying a rotation whose angle is the sum of the two.\n"
     ]
    }
   ],
   "source": [
    "#original cozum\n",
    "#????????\n",
    "\n",
    "# First question\n",
    "def rotation_matrix(theta):\n",
    "    A = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta), np.cos(theta)]])\n",
    "    \n",
    "    return A\n",
    "\n",
    "# Second question\n",
    "x = np.array([1, 1])\n",
    "A_pi = rotation_matrix(np.pi)\n",
    "\n",
    "print(\"x =\", x)\n",
    "print(\"A(pi)x =\", A_pi.dot(x))\n",
    "\n",
    "# Third question\n",
    "A_pi_4 = rotation_matrix(np.pi/4)\n",
    "A_3pi_4 = rotation_matrix(3*np.pi/4)\n",
    "\n",
    "print(\"A(pi/4) A(3pi/4) x =\", A_pi_4.dot(A_3pi_4.dot(x)))\n",
    "\n",
    "# Fourth question\n",
    "print(\"\\n\")\n",
    "print(\"Intuitively, A(theta_1) A(theta_2) = A(theta_1 + theta_2) because applying a rotation of angle theta_1 then\" )\n",
    "print(\"applying another rotation of angle theta_2 is exactly the same as applying a rotation whose angle is the sum of the two.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a2fd1f-ac1d-4c5e-86b8-84f60635efe1",
   "metadata": {},
   "source": [
    "## Broadcasting between a matrix and a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc864bc8-bec5-4524-b7f0-198c64c63b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Broadcasting between a matrix and a value\n",
    "\n",
    "    When performing an operation between elements of different dimensions, Numpy performs what is called Broadcasting to understand the operation and execute it.\n",
    "\n",
    "    The term broadcasting is used because one of the arrays is \"broadcasted\" into an array of larger dimensions so that the two arrays have compatible dimensions. This definition will be illustrated below.\n",
    "\n",
    "    In this section, we will try to understand numpy's broadcasting rules in the following cases:\n",
    "\n",
    "        Operation between a matrix and a constant\n",
    "        Operation between a matrix and a vector\n",
    "\n",
    "    An arithmetic operation such as the sum between a matrix and a constant does not make mathematical sense. With Numpy, the broadcasting rule in this case is to sum the constant to each term of the matrix.\n",
    "\n",
    "    𝑀=(3−21125),𝑐=10\n",
    "\n",
    "𝑀+𝑐=(3+10−2+101+101+102+105+10)=(13811111215)\n",
    "\n",
    "What really happens is that the constant 𝑐\n",
    "is broadcasted into a matrix 𝐶 with the same dimensions as 𝑀\n",
    "\n",
    ":\n",
    "\n",
    "𝑐⟶broadcasting𝐶=(𝑐𝑐𝑐𝑐𝑐𝑐)\n",
    "\n",
    "Thus, 𝑀+𝐶\n",
    "\n",
    "    is mathematically well defined and can be computed with basic operations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82660abe-29ea-4939-925b-d869fbbee8aa",
   "metadata": {},
   "source": [
    "## Broadcasting between a matrix and a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a1e8d6f-0084-400e-ae9b-6bbc4c94f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Broadcasting between a matrix and a vector\n",
    "\n",
    "    Similarly, numpy allows us to perform arithmetic operations between a matrix and a vector. However, there are some constraints which determine whether the vector can be broadcasted into a matrix with compatible dimensions.\n",
    "\n",
    "    In order to determine if the dimensions of the vector and the matrix are compatible, numpy will compare each dimension of the two arrays and determine if:\n",
    "\n",
    "        the dimensions are equal.\n",
    "        one of the dimensions is equal to 1.\n",
    "\n",
    "    If for each dimension, one of these conditions is verified, then the dimensions are compatible and the operation has been understood. Otherwise, a ValueError: operands could not be broadcast together error will be displayed.\n",
    "\n",
    "    Let us consider the following objects :\n",
    "\n",
    "    𝑀=(3−21125),𝑣=(25)\n",
    "\n",
    "Do 𝑀\n",
    "and 𝑣\n",
    "\n",
    "have compatible dimensions for broadcasting?\n",
    "\n",
    "𝑀\n",
    "is a 2x3 dimensional matrix. 𝑣 is a vector with 2 elements, but numpy will instead see 𝑣\n",
    "\n",
    "as a matrix of dimensions 2x1, that is, a matrix with two rows and one column.\n",
    "\n",
    "The first dimension of 𝑀\n",
    "and 𝑣 is equal to 2\n",
    "\n",
    ". They are equal so the compatibility condition is verified for this dimension.\n",
    "\n",
    "The second dimension of 𝑀\n",
    "is equal to 3 and that of 𝑣\n",
    "\n",
    "is equal to 1. The compatibility condition is still verified because one of the dimensions is equal to 1.\n",
    "\n",
    "Therefore 𝑀\n",
    "and 𝑣\n",
    "\n",
    "have compatible dimensions for broadcasting.\n",
    "\n",
    "The vector 𝑣\n",
    "will then be broadcasted along the axis where the dimension of 𝑣 is equal to 1. In our case, it is the axis of the columns. The broadcasting of 𝑣\n",
    "\n",
    "will therefore be given by:\n",
    "\n",
    "𝑣=(25)⟶broadcasting𝑉=[𝑣𝑣𝑣]=(252525)\n",
    "\n",
    "The result of 𝑀∗𝑣\n",
    "\n",
    "will then be given by:\n",
    "\n",
    "𝑀∗𝑣⟶broadcasting𝑀∗𝑉=(3∗2−2∗51∗21∗52∗25∗5)=(6−1025425)\n",
    "\n",
    "Now suppose we have a line vector 𝑢=(34)\n",
    "\n",
    ".\n",
    "\n",
    "For numpy, this vector has dimensions 1x2 (one row and 2 columns). The vectors 𝑢\n",
    "and 𝑣\n",
    "\n",
    "are compatible for broadcasting because on each axis one of the vectors has a dimension equal to 1.\n",
    "\n",
    "How and on which object is the broadcasting carried out in this case?\n",
    "\n",
    "The broadcasting will be carried out on the two vectors and the resulting matrix of the broadcasting will have the largest dimension between the two vectors:\n",
    "\n",
    "𝑣=(25)⟶broadcasting𝑉=(2525)\n",
    "\n",
    "and\n",
    "\n",
    "𝑢=(34)⟶broadcasting𝑈=(3344)\n",
    "\n",
    "Thus, the result of 𝑣+𝑢\n",
    "\n",
    "is given by:\n",
    "\n",
    "𝑣+𝑢⟶broadcasting=(25)+(34)𝑉+𝑈=(2525)+(3344)=(5869)\n",
    "\n",
    "    These rules allow us to understand and predict the result of an operation between two arrays which do not have the same shape. They will be useful for the following exercise:\n",
    "\n",
    "    Min-Max normalization is a method that is used to rescale the variables of a database to the interval [0,1]\n",
    "\n",
    ".\n",
    "\n",
    "Assume our database contains 3 individuals and 2 variables:\n",
    "\n",
    "        Jacques: 24 years old, height of 1.88m.\n",
    "\n",
    "        Mathilde: 18 years old, height of 1.68m.\n",
    "\n",
    "        Alban: 14 years old, height of 1.65m.\n",
    "\n",
    "This data can be represented by the matrix:\n",
    "\n",
    "𝑋=2418141.881.681.65\n",
    "\n",
    "Each row corresponds to an individual, and each column corresponds to a variable. This format is the standard format for databases.\n",
    "\n",
    "We want to compare the age differences with the height differences between individuals. However, the variables in this database do not have the same scale. We have to use Min-Max normalization so that the variables have the same scale.\n",
    "\n",
    "We denote by 𝑋𝑖,𝑗\n",
    "the value of the variable 𝑗 for the individual 𝑖 and 𝑋:,𝑗 the column of the variable 𝑗\n",
    "\n",
    ".\n",
    "\n",
    "Min-Max normalization will produce a new matrix 𝑋̃ \n",
    "such that for each entry of the 𝑋\n",
    "\n",
    "matrix:\n",
    "\n",
    "𝑋̃ 𝑖,𝑗=𝑋𝑖,𝑗−min(𝑋:,𝑗)max(𝑋:,𝑗)−min(𝑋:,𝑗)\n",
    "\n",
    "Thus, to implement Min-Max normalization :\n",
    "\n",
    "        For each 𝑋:,𝑗\n",
    "\n",
    "column, compute min(𝑋:,𝑗) and max(𝑋:,𝑗)\n",
    "\n",
    "    .\n",
    "\n",
    "    For each element 𝑋𝑖,𝑗\n",
    "\n",
    "in the column, compute 𝑋̃ 𝑖,𝑗\n",
    "\n",
    "        .\n",
    "\n",
    "By default, a for loop on 𝑋 will cycle through the lines of 𝑋. \n",
    "In order to browse the columns of 𝑋, you can browse the rows of the transposed matrix of 𝑋, which we denote by 𝑋𝑇\n",
    "\n",
    ".\n",
    "\n",
    "𝑋𝑇=(241.88181.68141.65)\n",
    "\n",
    "The transposition of an array is obtained with its T attribute: 𝑋𝑇\n",
    "\n",
    "    =X.T.\n",
    "\n",
    "    (a) Define a function named normalization_min_max taking as argument a matrix 𝑋 and which will return 𝑋̃ \n",
    "\n",
    "    (b) Apply Min-Max normalization on 𝑋 . You should get the matrix to two decimal places:\n",
    "\n",
    "X = np.array([[1, 0.4, 0],\n",
    "              [1, 0.13, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddfb2387-16a8-4810-9a5e-03eb3cedfc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.  , 1.  ],\n",
       "       [0.4 , 0.13],\n",
       "       [0.  , 0.  ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "def normalization_min_max(X):\n",
    "    if X.ndim == 1:\n",
    "        l2 = []\n",
    "        for i in X:\n",
    "            new_i = (i - min(X)) / (max(X) - min(X))\n",
    "            l2.append(round(new_i, 2))\n",
    "        return l2\n",
    "    else:\n",
    "        X = X.T\n",
    "        for i, row in enumerate(X):\n",
    "            mi = min(row)\n",
    "            ma = max(row)\n",
    "            for j, value in enumerate(row):\n",
    "                new_value = (value - mi) / (ma - mi)\n",
    "                X[i,j] = round(new_value, 2)\n",
    "\n",
    "        return X.T\n",
    "\n",
    "l = np.array([1,2,3,4])\n",
    "\n",
    "X = np.array([[1, 0.4, 0],\n",
    "              [1, 0.13, 0]])\n",
    "\n",
    "y = np.array([[24, 1.88],\n",
    "              [18, 1.68],\n",
    "              [14, 1.65]])\n",
    "normalization_min_max(l)\n",
    "normalization_min_max(y)\n",
    "#normalization_min_max(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93fb9efe-218f-4d03-b689-77e2b29937ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.        ]\n",
      " [0.4        0.13043478]\n",
      " [0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# original cozum\n",
    "def normalization_min_max(X):\n",
    "    # Initialization of X_tilde\n",
    "    X_tilde = np.zeros(shape = X.shape)\n",
    "    \n",
    "    # For each column of X\n",
    "    for j, column in enumerate(X.T):\n",
    "        # Initialization of the minimum and maximum of the column\n",
    "        min_Xj = column[0]\n",
    "        max_Xj = column[0]\n",
    "        \n",
    "        # For each value in the column\n",
    "        for value in column:\n",
    "            # If the value is SMALLER than the min\n",
    "            if value < min_Xj:\n",
    "                # We overwrite the min with this value\n",
    "                min_Xj = value\n",
    "            \n",
    "            # If the value is GREATER than the max\n",
    "            if value > max_Xj:\n",
    "                # We overwrite the max with this value\n",
    "                max_Xj = value\n",
    "                \n",
    "        # We can now calculate X_tilde for this column\n",
    "        # Broadcasting allows us to do this without a for loop\n",
    "        X_tilde[:, j] = (X[:, j] - min_Xj)/(max_Xj - min_Xj)\n",
    "            \n",
    "    return X_tilde\n",
    "        \n",
    "\n",
    "X = np.array([[24, 1.88],\n",
    "              [18, 1.68],\n",
    "              [14, 1.65]])\n",
    "\n",
    "X_tilde = normalization_min_max(X)\n",
    "\n",
    "print(X_tilde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee034a9-0859-4f29-92b7-95695a3c8470",
   "metadata": {},
   "source": [
    "## Statistical methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdc8b50-4611-4b50-a083-a26371e150c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Statistical methods\n",
    "\n",
    "    In addition to common math operations, numpy arrays also have several methods for more complex operations on arrays.\n",
    "\n",
    "    One of the most used operations is the computation of an average using the mean method of an array:\n",
    "\n",
    "    A = np.array([[1, 1, 10],\n",
    "                  [3, 5, 2]])\n",
    "\n",
    "    # Computation of the mean over ALL the values of X\n",
    "    print(A.mean())\n",
    "    >>> 3.67\n",
    "\n",
    "    # Computation of the mean of each COLUMN of X\n",
    "    print(A.mean(axis = 0))\n",
    "    >>> [2, 3, 6]\n",
    "\n",
    "    # Computation of the mean of each ROW of X\n",
    "    print(A.mean(axis = 1))\n",
    "    >>> [4, 3.33]\n",
    "\n",
    "    The argument axis determines which dimension will be scanned to compute the mean:\n",
    "\n",
    "            axis = 0 means that the dimension scanned will be that of rows, which means that the result will be the average of each column.\n",
    "\n",
    "            axis = 1 means that the dimension scanned will be that of columns, which means that the result will be the average of each row.\n",
    "\n",
    "    The axis argument is very often used for operations on matrices, and not only for Numpy. It is very important to understand its effect.\n",
    "\n",
    "    There are other statistical methods that behave like the mean method, such as:\n",
    "\n",
    "            sum: Computes the sum of the elements of an array.\n",
    "\n",
    "            std: Computes the standard deviation.\n",
    "\n",
    "            min: Finds the minimum value among the elements of an array.\n",
    "\n",
    "            max: Finds the maximum value among the elements of an array.\n",
    "\n",
    "            argmin: Returns the index of the minimum value.\n",
    "\n",
    "            argmax: Returns the index of the maximum value.\n",
    "\n",
    "    These methods are useless for databases if you do not provide a value for the axis argument.\n",
    "\n",
    "    In general, we will use the value axis = 0 to get the result for each column, that is, for each variable in the database.\n",
    "\n",
    "    Thus, we can calculate the Min-Max normalization very quickly using the min and max methods along with broadcasting:\n",
    "\n",
    "    X_tilde = (X - X.min(axis = 0))/(X.max(axis = 0) - X.min(axis = 0))\n",
    "\n",
    "    print (X_tilde)\n",
    "    >>> [[1, 1]\n",
    "    >>>  [0.4, 0.13043478]\n",
    "    >>>  [0, 0]]\n",
    "\n",
    "The Mean Squared Error is a metric to quantify the prediction error obtained by a regression model. This notion will be seen in more detail later in your training.\n",
    "\n",
    "The formula for the mean squared error, abbreviated by MSE\n",
    "\n",
    ", is calculated with the following formula:\n",
    "\n",
    "MSE=1𝑛∑𝑖=1𝑛(𝑦̂ 𝑖−𝑦𝑖)2\n",
    "\n",
    "where:\n",
    "\n",
    "        𝑦̂ \n",
    "\n",
    "and 𝑦 are vectors with length 𝑛\n",
    "\n",
    "    .\n",
    "\n",
    "    𝑦̂ \n",
    "\n",
    "is given by the matrix product between a 𝑋 matrix and a regression vector 𝛽, ie:\n",
    "𝑦̂ =𝑋𝛽\n",
    "\n",
    "In the case of linear regression, the goal of the mean squared error is to find the regression vector 𝛽\n",
    "\n",
    "which minimizes this error.\n",
    "\n",
    "    (a) Define a function named mean_squared_error taking as argument a matrix X\n",
    "    , a vector beta and a vector y and which, without a for loop, returns the associated mean squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e5ad477-ab27-4e50-876d-98c7a33b90dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original cozum\n",
    "def mean_squared_error(X, beta, y):\n",
    "    # Computation of ^y\n",
    "    y_hat = X.dot(beta)\n",
    "    \n",
    "    # Computation of (^y_i - y_i)**2\n",
    "    mse = (y_hat - y)**2\n",
    "    \n",
    "    # MSE\n",
    "    mse = mse.mean()\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdab3b08-b414-4e42-bca8-2cd0e6faad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Our database contained 3 individuals and 2 variables:\n",
    "\n",
    "        Jacques: 24 years old, height 1.88m.\n",
    "\n",
    "        Mathilde: 18 years old, height 1.68m.\n",
    "\n",
    "        Alban: 14 years old, height 1.65m.\n",
    "\n",
    "We will try to find a model able to predict the height of an individual based on his age. Thus, we define:\n",
    "𝑋=241814\n",
    "\n",
    "𝑦=1.881.681.65\n",
    "\n",
    "Our goal will be to find an optimal 𝛽∗\n",
    "such that:\n",
    "𝑦≈𝑋𝛽∗\n",
    "\n",
    "    (b) For beta taking the values 0.01, 0.02, ..., 0.13, 0.14 and 0.15, compute the associated MSE\n",
    "\n",
    "    using the previously defined mean_squared_error function. Store the values in a list.\n",
    "\n",
    "    To create the list [0.01, 0.02, ..., 0.13, 0.14, 0.15], you can use the np.linspace function which has a signature similar to the range function:\n",
    "\n",
    "    print(np.linspace(start = 0.01, stop = 0.15, num = 15))\n",
    "    >>> [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15]\n",
    "\n",
    "    The num argument allows you to define the desired number of elements between start and stop. It is not the step between two consecutive values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd81b475-9d91-48d9-9b5f-82a01bc98ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininmun MSE and Optimal Beta : [0.07803333333333334, 0.08999999999999998]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([24,\n",
    "              18,\n",
    "              14])\n",
    "\n",
    "y = np.array([1.88,\n",
    "              1.68,\n",
    "              1.65])\n",
    "\n",
    "# Insert your code here\n",
    "\n",
    "\n",
    "lst = np.linspace(0.01, 0.15, 15)\n",
    "result = []\n",
    "for beta in  lst:\n",
    "    result.append([mean_squared_error(X, beta, y), beta])\n",
    "\n",
    "#print(result)\n",
    "print(\"Mininmun MSE and Optimal Beta :\",min(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34253aab-9dda-4c8c-922e-2404cba67168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original cozum\n",
    "X = np.array([24,\n",
    "              18,\n",
    "              14])\n",
    "\n",
    "y = np.array([1.88,\n",
    "              1.68,\n",
    "              1.65])\n",
    "\n",
    "# List containing the mse\n",
    "errors = []\n",
    "\n",
    "# List containing the betas to be tested\n",
    "betas = np.linspace(start = 0.01, stop = 0.15, num = 15)\n",
    "\n",
    "# For all the values of beta\n",
    "for beta in betas:\n",
    "    # Compute the associated MSE\n",
    "    errors.append(mean_squared_error(X, beta, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4750e2-f8ad-41f8-a241-c20c57c73318",
   "metadata": {},
   "outputs": [],
   "source": [
    "(c) Convert the list containing the MSE\n",
    "\n",
    "    's to a numpy array.\n",
    "\n",
    "    (d) Determine the 𝛽∗\n",
    "\n",
    "that minimizes the MSE using the argmin method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a75d18cb-0d66-4436-a3b2-be1c2de6b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array of MSE : \n",
      " [2.40656667 1.85976667 1.38603333 0.98536667 0.65776667 0.40323333\n",
      " 0.22176667 0.11336667 0.07803333 0.11576667 0.22656667 0.41043333\n",
      " 0.66736667 0.99736667 1.40043333] \n",
      "\n",
      "Min MSE index : 8 \n",
      "\n",
      "Minimum MSE =  0.07803333333333334 \n",
      "\n",
      "Optimal Beta =  0.08999999999999998\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "errs_arr = np.array(errors)\n",
    "print(\"Array of MSE : \\n\", errs_arr, \"\\n\")\n",
    "\n",
    "min_err_index = errs_arr.argmin()\n",
    "print(\"Min MSE index :\", min_err_index, \"\\n\")\n",
    "\n",
    "print(\"Minimum MSE = \",errs_arr[min_err_index], \"\\n\")\n",
    "print(\"Optimal Beta = \", betas[min_err_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fcd03f1-46b2-45ac-bf3b-370954b690d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal beta is: 0.08999999999999998\n"
     ]
    }
   ],
   "source": [
    "# original cozum\n",
    "# Array containing the MSE for each beta\n",
    "errors = np.array(errors)\n",
    "\n",
    "# List containing the betas that have been tested\n",
    "betas = np.linspace(start = 0.01, stop = 0.15, num = 15)\n",
    "\n",
    "# Index of the beta that minimizes the MSE \n",
    "index_beta_optimal = errors.argmin()\n",
    "\n",
    "# Optimal beta \n",
    "beta_optimal = betas[index_beta_optimal]\n",
    "\n",
    "print(\"The optimal beta is:\", beta_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5156ace6-8a1d-43a9-badc-9a9f10af3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "e) What are the heights predicted by this optimal 𝛽∗? The heights predicted by the model are given by the vector 𝑦̂ =𝑋𝛽∗\n",
    "\n",
    "    .\n",
    "\n",
    "(f) Compare the predicted heights to the actual heights of the individuals. \n",
    "For example, you can compute the average absolute difference between the predicted and true values using the absolute value (np.abs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "597b0666-7aa7-4e4d-b79c-2977407df38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted heights :  [2.16 1.62 1.26]\n",
      "Real heights      :  [1.88 1.68 1.65]\n",
      "Erros             :  [0.28 0.06 0.39]\n",
      "Average of errors :  0.2433333333333334\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here\n",
    "\n",
    "y_predict = X.dot(beta_optimal)\n",
    "print(\"Predicted heights : \",y_predict)\n",
    "\n",
    "\n",
    "print(\"Real heights      : \", y)\n",
    "\n",
    "errors_ = np.abs(y - y_predict)\n",
    "\n",
    "print(\"Erros             : \", errors_)\n",
    "\n",
    "print(\"Average of errors : \", errors_.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0fc243a7-cee4-45cd-ae1d-fba7d41c7ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted heights: \n",
      " [2.16 1.62 1.26]\n",
      "\n",
      " Real heights: \n",
      " [1.88 1.68 1.65]\n",
      "\n",
      " The model makes an average mistake of 0.2433333333333334 metres.\n"
     ]
    }
   ],
   "source": [
    "y_hat = X.dot(beta_optimal)\n",
    "print(\"Predicted heights: \\n\", y_hat)\n",
    "\n",
    "print(\"\\n Real heights: \\n\", y)\n",
    "\n",
    "print(\"\\n The model makes an average mistake of\", np.abs(y - y_hat).mean(), \"metres.\")\n",
    "\n",
    "# The predicted heights are incorrect but approximately very close to the real sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1a1d9-c745-411a-a0ce-2ddad14b8b4f",
   "metadata": {},
   "source": [
    "# Introduction to DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f6e66-9086-413d-bb39-9ac94b3d171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Introduction\n",
    "\n",
    "    The pandas module has been developed to provide Python with the tools necessary to manipulate and analyze large volumes of data.\n",
    "\n",
    "    Pandas introduces the DataFrame class, an array-like data structure that offers more advanced data manipulation and exploration than NumPy arrays.\n",
    "\n",
    "    The main features of pandas are:\n",
    "\n",
    "            data recovery from files (CSV, Excel tables, etc.)\n",
    "\n",
    "            handling this data (deletion / addition, modification, statistical visualization, etc.).\n",
    "\n",
    "    This notebook aims at:\n",
    "\n",
    "            Understanding the format of a DataFrame.\n",
    "\n",
    "            Creating a first Dataframe.\n",
    "\n",
    "            Carrying out a first exploration of a dataset using the DataFrame class.\n",
    "\n",
    "    (a) Import the pandas module under the name pd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aceceba-444c-448d-a5f8-dc7ff2f680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac49d-b23c-4f2e-8985-e018021076ed",
   "metadata": {},
   "source": [
    "## Format of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be53471-b41b-46b6-a130-fe158f45df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Format of a DataFrame\n",
    "\n",
    "    A DataFrame is in the form of a matrix whose rows and columns each have an index. Typically, columns are indexed by name and rows by unique identifiers.\n",
    "\n",
    "    A DataFrame is used to store a database. The different entries in the database (individuals, animals, objects, etc.) are the different lines and their features are the different columns:\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    0 \tRobert \tM \t174 \t23\n",
    "    1 \tMark \tM \t182 \t40\n",
    "    2 \tAline \tF \t169 \t56\n",
    "\n",
    "            The DataFrame above groups together information on 3 individuals: the DataFrame therefore has 3 lines.\n",
    "\n",
    "            For each of these individuals, there are 4 variables (name, gender, height and age) : therefore, the DataFrame has 4 columns.\n",
    "\n",
    "    The column containing the numbering of the lines is called the index and is not managed in the same way as other columns of the DataFrame.\n",
    "\n",
    "    The index can be set by default (will follow the row numbering), defined with one (or several) of the columns of the DataFrame or even defined with a list that we specify.\n",
    "\n",
    "    Example: Default indexing (line numbering), you don't have to specify anything :\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    0 \tRobert \tM \t174 \t23\n",
    "    1 \tMark \tM \t182 \t40\n",
    "    2 \tAline \tF \t169 \t56\n",
    "\n",
    "    Example: Indexing by the column 'Name':\n",
    "    \tGender \tHeight \tAge\n",
    "    Robert \tM \t174 \t23\n",
    "    Mark \tM \t182 \t40\n",
    "    Aline \tF \t169 \t56\n",
    "\n",
    "    Example: Indexing by the list ['person_1', 'person_2', 'person_3']:\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    person_1 \tRobert \tM \t174 \t23\n",
    "    person_2 \tMark \tM \t182 \t40\n",
    "    person_3 \tAline \tF \t169 \t56\n",
    "\n",
    "    We will detail later how to define the index when creating a DataFrame.\n",
    "\n",
    "    The DataFrame class has several advantages over aNumpy array:\n",
    "\n",
    "            Visually, a DataFrame is much more readable thanks to more explicit column and row indexing.\n",
    "\n",
    "            Within the same column the elements are of the same type but from one column to another, the type of the elements may vary, which is not the case of Numpy arrays which only support data of the same type.\n",
    "\n",
    "            The DataFrame class contains more methods for handling and preprocessing databases, while NumPy specializes instead in optimized computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14cd18-7069-478b-8dd2-453997e22272",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f19e82-c37a-4d24-8c0e-22fbe833545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Creation of a DataFrame: from a NumPy array\n",
    "\n",
    "    It is possible to directly create a DataFrame from a NumPy array using the DataFrame() constructor. The disadvantage of this method is that it is not very practical and the data type is necessarily the same for all the columns.\n",
    "\n",
    "    Let's take a closer look at the header of this constructor.\n",
    "\n",
    "    pd.DataFrame(data, index, columns, ...)\n",
    "\n",
    "            The data parameter contains the data to be formatted (NumPy array, list, dictionary or another DataFrame).\n",
    "\n",
    "            The index parameter, if specified, must be a list containing the indices of the entries.\n",
    "\n",
    "            The columns parameter, if specified, must be a list containing the name of the columns.\n",
    "\n",
    "    For other parameters, you can consult the Python documentation.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # Creation of a NumPy array with 3 rows and 4 columns\n",
    "    array = np.array ([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8],\n",
    "                       [9, 10, 11, 12]])\n",
    "\n",
    "    # Instantiation of a DataFrame\n",
    "    df = pd.DataFrame (data = array, # The data to format\n",
    "                       index = ['i_1', 'i_2', 'i_3'], # The indices of each entry\n",
    "                       columns = ['A', 'B', 'C', 'D']) # The name of the columns\n",
    "\n",
    "    This produces the following DataFrame:\n",
    "    \tA \tB \tC \tD\n",
    "    i_1 \t1 \t2 \t3 \t4\n",
    "    i_2 \t5 \t6 \t7 \t8\n",
    "    i_3 \t9 \t10 \t11 \t12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584ee0d-65a2-4538-97ae-ef12f54a1e14",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd9a97-cf59-421b-9c24-aed6c1a6ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Creation of a DataFrame: from a dictionary\n",
    "\n",
    "    Another way to create a DataFrame is to use a dictionary. Thanks to this technique, the columns can be of different type and their names are already given when creating the DataFrame.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # Creation of a dictionary\n",
    "    dictionary = {'A': [1, 5, 9],\n",
    "                  'B': [2, 6, 10],\n",
    "                  'C': [3, 7, 11],\n",
    "                  'D': [4, 8, 12]}\n",
    "\n",
    "    # Instantiation of a DataFrame\n",
    "    df = pd.DataFrame (data = dictionary,\n",
    "                       index = ['i_1', 'i_2', 'i_3'])\n",
    "\n",
    "    This produces the same DataFrame as before:\n",
    "    \tA \tB \tC \tD\n",
    "    i_1 \t1 \t2 \t3 \t4\n",
    "    i_2 \t5 \t6 \t7 \t8\n",
    "    i_3 \t9 \t10 \t11 \t12\n",
    "\n",
    "The manager of a grocery store has the following stock of food products:\n",
    "\n",
    "    100 jars of honey with an expiration date of 08/10/2025 and worth €2 each.\n",
    "\n",
    "    55 packets of flour expiring on 09/25/2024 each costing € 3.\n",
    "\n",
    "    1800 bottles of wine costing € 10 per unit and expiring on 10/15/2023.\n",
    "\n",
    "    (a) From a dictionary, create and display a DataFrame df that contains for each product:\n",
    "\n",
    "            Its name.\n",
    "            Its expiration date.\n",
    "            Its quantity.\n",
    "            Its price per unit.\n",
    "\n",
    "You will choose relevant column names and the index will be the default one (in this case we do not specify the index parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b09c8dfa-50e4-4078-ae09-eb8aa5c5da58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Expiration date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price per unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honey</td>\n",
       "      <td>10/08/2025</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flour</td>\n",
       "      <td>25/09/2024</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine</td>\n",
       "      <td>15/10/2023</td>\n",
       "      <td>1800</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Expiration date  Quantity  Price per unit\n",
       "0   honey      10/08/2025       100               2\n",
       "1   flour      25/09/2024        55               3\n",
       "2    wine      15/10/2023      1800              10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your Code\n",
    "\n",
    "dictionary = {\"Product\"          : ['honey', 'flour', 'wine'],\n",
    "              \"Expiration date\"  : ['10/08/2025', '25/09/2024', '15/10/2023'],\n",
    "              \"Quantity\"         : [100, 55, 1800], \n",
    "              \"Price per unit\"   : [2, 3, 10]}\n",
    "\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74731371-de11-4edb-ab26-d923820f088e",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e0d47-d614-48ad-bda0-207ca0f70beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Creation of a DataFrame: from a data file\n",
    "\n",
    "    Most often a DataFrame is created directly from a file containing the data of interest. The file's format can be a CSV, Excel, txt, etc.\n",
    "\n",
    "    The most common format is the CSV format, which stands for Comma-Separated Values and denotes a spreadsheet-like file whose values are separated by commas.\n",
    "\n",
    "    Here is an example:\n",
    "\n",
    "    A, B, C, D,\n",
    "    1, 2, 3, 4,\n",
    "    5, 6, 7, 8,\n",
    "    9, 10, 11, 12\n",
    "\n",
    "    In this format:\n",
    "\n",
    "            The first line contains the name of the columns, but sometimes the name of the columns is not filled in.\n",
    "\n",
    "            Each line corresponds to an entry in the database.\n",
    "\n",
    "            The values are separated by a separator character. In this example, it is ',' but it could be a ';'.\n",
    "\n",
    "    To import the data into a DataFrame, we need to use the read_csv function of pandas whose header is as follows:\n",
    "\n",
    "    pd.read_csv(filepath_or_buffer, sep = ',', header = 0, index_col = 0 ...)\n",
    "\n",
    "    The essential arguments of the pd.read_csv function to know are:\n",
    "\n",
    "            filepath_or_buffer: The path of the .csv file relative to the execution environment.\n",
    "                If the file is in the same folder as the Python environment, just fill in the name of the file.\n",
    "                This path must be entered in the form of character string.\n",
    "\n",
    "            sep: The character used in the .csv file to to separate the different columns.\n",
    "                This argument must be specified as character.\n",
    "\n",
    "            header: The number of the row that contains the names of the columns.\n",
    "                If for example the column names are entered in the first line of the .csv file, then we must specify header = 0.\n",
    "                If the names are not included, we will put header = None.\n",
    "\n",
    "            index_col: The name or number of the column containing the indices of the database.\n",
    "                If the database entries are indexed by the first column, you will need to fill in index_col = 0.\n",
    "                Alternatively, if the entries are indexed by a column which bears the name \"Id\", we can specify index_col = \"Id\".\n",
    "\n",
    "    This function will return an object of type DataFrame which contains all the data of the file.\n",
    "\n",
    "    (a) Load the data contained in the file transactions.csv into aDataFrame named transactions:\n",
    "\n",
    "            The file is located in the same folder as the environment of this notebook.\n",
    "            Columns are separated by commas.\n",
    "            The names of the columns are in the first line of the file.\n",
    "            The rows of the database are indexed by the \"transaction_id\" column which is also the first column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b3425-52d0-4993-b3c4-90c7b9d3dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# You can directly specify the name of the column containing the indices\n",
    "\n",
    "transactions = pd.read_csv(filepath_or_buffer = 'transactions.csv', # file path\n",
    "                           sep = ',',                               # character separating values\n",
    "                           header = 0,                              # number of the row containing column names\n",
    "                           index_col = 'transaction_id')            # name of the column that indexes the entries\n",
    "\n",
    "\n",
    "# You can also directly enter the number of the column that indexes the entries\n",
    "\n",
    "transactions = pd.read_csv(filepath_or_buffer = 'transactions.csv',\n",
    "                           sep = ',',\n",
    "                           header = 0,\n",
    "                           index_col = 0) # number of the column that indexes the entries\n",
    "\n",
    "# We loaded the transactions.csv file in theDataFrame transactions which gathers a history of transactions carried out between 2011 and 2014. \n",
    "#In the next section, we will study this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506e9cf-2b48-465b-8748-1a720974c5ec",
   "metadata": {},
   "source": [
    "## First exploration of a dataset using the DataFrame class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cde126-fb58-4743-b1f6-718a3591a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. First exploration of a dataset using the DataFrame class\n",
    "\n",
    "    The rest of this notebook briefly presents the main methods of the DataFrame class which will allow us to do a quick analysis of our data set, that is:\n",
    "\n",
    "            Having a brief overview of the data (head method,columns and shape attributes).\n",
    "\n",
    "            Selecting values in the DataFrame (loc and iloc methods).\n",
    "\n",
    "            Carrying out a quick statistical study of our data (describe and value _counts methods)\n",
    "\n",
    "    As a reminder, to apply a method to an object in Python (such as a DataFrame for example), you must add the method as a suffix of the object. Example: my_object.my_method()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5764ad-c505-4224-ab2a-79cf30635a73",
   "metadata": {},
   "source": [
    "## Visualization of a DataFrame: head method, columns and shape attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384dad2-969a-4c11-b6a5-b8dc406c7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Visualization of a DataFrame: head method, columns and shape attributes\n",
    "\n",
    "        It is possible to have a preview of a dataset by displaying only the first lines of the DataFrame.\n",
    "\n",
    "    For that, we must use the head() method, specifying as an argument the number of lines that we want to display (by default 5).\n",
    "\n",
    "    It is also possible to preview the last lines using the tail() method which is applied in the same way:\n",
    "\n",
    "    # Display of the first 10 lines of my_dataframe\n",
    "    my_dataframe.head(10)\n",
    "\n",
    "    (a) Display the first 20 lines of the transactions DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f4645-75e9-4027-9a08-e79ac61c3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b3c4-aecb-439b-93fa-f4dd4b52f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Display the last 10 lines of the transactions DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4349a8-0ef4-4632-8491-ff8b9818fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e01940-a6d8-496d-aab7-6f4b5ba55112",
   "metadata": {},
   "outputs": [],
   "source": [
    "     \tA \tB \tC \tD\n",
    "    i_ 1 \t1 \t2 \t3 \t4\n",
    "    i _2 \t5 \t6 \t7 \t8\n",
    "    i_ 3 \t9 \t10 \t11 \t12\n",
    "\n",
    "    # Display of df DataFrame columns\n",
    "    print(df.columns)\n",
    "    >>> ['A', 'B', 'C', 'D']\n",
    "\n",
    "    The list of the column names can be used to iterate over the columns of a DataFrame within a loop.\n",
    "\n",
    "    It can be interesting to know how many transactions (rows) and how many features (columns) the dataset contains.\n",
    "\n",
    "    For this we will use the shape attribute of the DataFrame class which displays the dimensions of our DataFrame in the form of a tuple (number of rows, number of columns):\n",
    "\n",
    "    # Display the dimensions of df\n",
    "    print (df.shape)\n",
    "    >>> (3,4)\n",
    "\n",
    "    (c) Display the dimensions of the DataFrame transactions as well as the name of the 5th column. Remember that in Python the indices start from 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977eca5f-fb8e-4fa1-adcd-4547fe48c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "print(transactions.shape)\n",
    "\n",
    "transactions.columns[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad1b8e-26ef-475c-a814-c4c9b7d71519",
   "metadata": {},
   "source": [
    "## Selecting columns from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d405d9b-56ac-49d5-a196-a7a9dec5176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Selecting columns from a DataFrame\n",
    "\n",
    "    Extracting columns from a DataFrame is almost identical to extracting data from a dictionary.\n",
    "\n",
    "    To extract a column from a DataFrame, all we have to do is enter between brackets the name of the column to extract. To extract several columns, we must enter between brackets the list of the names of the columns to extract:\n",
    "\n",
    "    # Display of the 'cust_id' column\n",
    "    print(transactions['cust_id'])\n",
    "\n",
    "    # Extraction of 'cust_id' and 'Qty' columns from transactions\n",
    "    cust_id_qty = transactions[[\"cust_id\", \"Qty\"]]\n",
    "\n",
    "    cust_id_qty is a new DataFrame containing only the 'cust_id' and 'Qty' columns.\n",
    "\n",
    "    The display of the first 3 lines of cust_id_qty yields:\n",
    "\n",
    "\n",
    "\n",
    "    transactions_id \tcust_id \tQty\n",
    "    80712190438 \t270351 \t-5\n",
    "    29258453508 \t270384 \t-5\n",
    "    51750724947 \t273420 \t-2\n",
    "\n",
    "    When we prepare a dataset for later use, it is better to separate the categorical variables from the quantitative variables:\n",
    "\n",
    "            A categorical variable is a variable that takes only a finite number of modalities.\n",
    "\n",
    "            The categorical variables of the DataFrame transactions are: ['cust_id', 'tran_date', 'prod_subcat_code', 'prod_cat_code', 'Store_type'].\n",
    "\n",
    "            A quantitative variable is a variable that measures a quantity that can take an infinite number of values.\n",
    "\n",
    "            The quantitative variables of transactions are: ['Qty', 'Rate', 'Tax', 'total_amt'].\n",
    "\n",
    "    This distinction is made because some basic operations like calculating an average only make sense for quantitative variables.\n",
    "\n",
    "    (a) In a DataFrame named cat_vars, store the categorical variables of transactions.\n",
    "\n",
    "    (b) In a DataFrame named num_vars, store the quantitative variables of transactions.\n",
    "\n",
    "    (c) Display the first 5 lines of each DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a03c3-86c3-4613-9859-f6ca982d0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# Extraction of categorical variables\n",
    "cat_var_names = ['cust_id', 'tran_date', 'prod_subcat_code', 'prod_cat_code' , 'Store_type']\n",
    "cat_vars = transactions[cat_var_names]\n",
    "\n",
    "# Extraction of quantitative variables\n",
    "num_var_names = ['Qty', 'Rate', 'Tax', 'total_amt']\n",
    "num_vars = transactions[num_var_names]\n",
    "\n",
    "# Display of the first 5 lines of each DataFrame\n",
    "print (\"Categorical variables: \\n\")\n",
    "print (cat_vars.head(), \"\\n \\n\")\n",
    "\n",
    "print (\"Quantitative variables: \\n\")\n",
    "print (num_vars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c5095-e2fc-4d01-9b39-0a5ecf0b6da8",
   "metadata": {},
   "source": [
    "## Selecting rows of a DataFrame: loc and iloc methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cd06a-65a0-4d45-bd0a-ef13608965c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Selecting rows of a DataFrame: loc and iloc methods\n",
    "\n",
    "    To extract one or more rows from a DataFrame, we use the loc method. loc is a very special type of method because the arguments are filled in between square brackets and not between parentheses. Using this method is very similar to indexing lists.\n",
    "\n",
    "    In order to retrieve the line of index i of a DataFrame, all we have to do is enter i as an argument of the loc method:\n",
    "\n",
    "    # We retrieve the line of index 80712190438 of the num_vars DataFrame\n",
    "    print(num_vars.loc[80712190438])\n",
    "\n",
    "    >>                 Rate    Tax  total_amt\n",
    "    >> transaction_id                         \n",
    "    >> 80712190438    -772.0  405.3    -4265.3\n",
    "    >> 80712190438     772.0  405.3     4265.3\n",
    "\n",
    "    In order to retrieve several rows, we can either:\n",
    "\n",
    "            Enter a list of indices.\n",
    "\n",
    "            Enter a slice by specifying the start and end indices of the slice. To use slicing with loc, the indices must be unique, which is not the case for transactions.\n",
    "\n",
    "    # We retrieve the rows at indices 80712190438, 29258453508 and 51750724947 from the transactions DataFrame\n",
    "    transactions.loc[[80712190438, 29258453508, 51750724947]]\n",
    "\n",
    "    loc can also take a column or list of columns as an argument in order to refine the data extraction:\n",
    "\n",
    "    # We extract the columns 'Tax' and 'total_amt' from the rows at index 80712190438 and 29258453508\n",
    "    transactions.loc[[80712190438, 29258453508], ['Tax', 'total_amt']]\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    transaction_id \tTax \ttotal_amt\n",
    "    80712190438 \t405.300 \t-4265.300\n",
    "    80712190438 \t405.300 \t4265.300\n",
    "    29258453508 \t785.925 \t-8270.925\n",
    "    29258453508 \t785.925 \t8270.925\n",
    "\n",
    "    The iloc method is used to index a DataFrame exactly like a numpy array, that is to say by only filling in the numeric indices of the rows and columns. This allows the use of slicing without constraint:\n",
    "\n",
    "    # Extraction of the first 4 rows and the first 3 columns of transactions\n",
    "    transactions.iloc[0:4, 0:3]\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    transaction_id \tcust_id \ttran_date \tprod_subcat_code\n",
    "    80712190438 \t270351 \t28-02-2014 \t1.0\n",
    "    29258453508 \t270384 \t27-02-2014 \t5.0\n",
    "    51750724947 \t273420 \t24-02-2014 \t6.0\n",
    "    93274880719 \t271509 \t24-02-2014 \t11.0\n",
    "\n",
    "    If the row indexing is the one by default (row numbering), the loc and iloc methods are equivalent.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83c629-6615-4a5a-93a8-4722f262494b",
   "metadata": {},
   "source": [
    "## Conditional indexing of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2eb568-f61d-4637-b60a-eb0ccefcaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Conditional indexing of a DataFrame\n",
    "\n",
    "    As with Numpy arrays, we can use conditional indexing to extract rows from a Dataframe that meet a given condition.\n",
    "\n",
    "    In the following illustration, we select the rows of the DataFrame df for which the column col 2 is equal to 3.\n",
    "\n",
    "\n",
    "    There are two syntaxes for conditionally indexing a DataFrame:\n",
    "\n",
    "\n",
    "    # We select the rows of the DataFrame df for which the column 'col 2' is equal to 3.\n",
    "    df[df['col 2'] == 3]\n",
    "\n",
    "    df.loc[df['col 2'] == 3]\n",
    "\n",
    "    If we want to assign a new value to these entries, we must absolutely use the loc method.\n",
    "\n",
    "    Indeed, indexing with the syntax df[df['col 2'] == 3] only returns a copy of these entries and does not provide access the memory location where the data is located.\n",
    "\n",
    "The manager of the transactions listed in the transactions DataFrame wishes to have access to the identifiers of customers who have made an online purchase (i.e. in a \"e-Shop\") as well as the date of the corresponding transaction.\n",
    "\n",
    "We have the following information about the columns of transactions:\n",
    "Column name \tDescription\n",
    "'cust_id' \tThe identifier of the customer\n",
    "'Store_type' \tThe type of store where the transaction took place\n",
    "'tran_date' \tThe date of the transaction\n",
    "\n",
    "    (a) In a DataFrame named transactions_eshop, store the transactions that took place in an \"e-Shop\" type store.\n",
    "\n",
    "    (b) In another DataFrame named transactions_id_date, store the customer identifiers and the transaction date of the transactions_eshop DataFrame.\n",
    "\n",
    "    (c) Display the first 5 rows of transactions_id_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc8cd2-67f9-4d93-a76b-da33e30be988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# Creation of transactions_eshop by conditional indexing\n",
    "transactions_eshop = transactions.loc[transactions['Store_type'] == 'e-Shop']\n",
    "\n",
    "# Extraction of the 'cust_ id' and 'tran _date' columns\n",
    "transactions_id_date = transactions_eshop[['cust_id', 'tran_date']]\n",
    "\n",
    "# Display of the first 5 lines of transactions_id_date\n",
    "transactions_id_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32d2a7-a0e1-4cb7-a73d-077d25755f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, the manager would like to have access to the transactions carried out by the client whose identifier is 268819.\n",
    "\n",
    "    (d) In a DataFrame named transactions_client_268819, store all transactions with client identifier 268819.\n",
    "\n",
    "    (e) A column in a DataFrame can be iterated over with a loop exactly like a list (for value in df['column']:). Using a for loop on the 'total_amt' column, compute and display the total transaction amount for the client with identifier 268819.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ad531-d02a-4189-8b02-fd0d651e778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# Extraction of the transactions ofthe customer which identifier is 268819\n",
    "transactions_client_268819 = transactions[transactions['cust_id'] == 268819]\n",
    "\n",
    "\n",
    "# Computation of the total amount of transactions\n",
    "total = 0\n",
    "\n",
    "# For each amount in the column 'total_amt'\n",
    "for amount in transactions_client_268819['total_amt']:\n",
    "    # We sum the amounts\n",
    "    total += amount\n",
    "    \n",
    "print(total)\n",
    "\n",
    "# Second Way\n",
    "transactions.loc[transactions.cust_id == 268819]['total_amt'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd9401-1f16-4894-8563-81bd24739fad",
   "metadata": {},
   "source": [
    "## Quick statistical study of the data in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf4ace-48c7-4656-9e63-9b55fd35b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Quick statistical study of the data in a DataFrame.\n",
    "\n",
    "    The describe method of a DataFrame returns a summary of the descriptive statistics (min, max, mean, quantiles,...) of its quantitative variables. It is therefore a very useful tool for a first visualisation of the type and distribution of these variables.\n",
    "\n",
    "    To analyse the categorical variables, it is recommended to start by using the value_counts method which returns the number of occurrences for each modality of these variables. The value_counts method cannot be used directly on a DataFrame but only on the columns of the DataFrame which are objects of the pd.Series class.\n",
    "\n",
    "    (a) Use the describe method of the DataFrame transactions.\n",
    "\n",
    "    (b) The quantitative variables of transactions are 'Qty', 'Rate', 'Tax' and total_amt'. By default, are the statistics produced by the describe method only computed on the quantitative variables?\n",
    "\n",
    "    (c) Display the number of occurrences of each modality of the Store_type column using the value_counts method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987b0a5-7c14-4c56-a396-35867eb76e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "transactions.describe()\n",
    "\n",
    "transactions['Store_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbb9de-6372-4b7d-acc4-87782b2cbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The describe method computed statistics on the variables cust_id, prod_subcat_code and prod_cat_code while these are categorical variables.\n",
    "\n",
    "    Of course, these statistics make no sense. The describe method has treated these variables as quantitative because the modalities they take are of numerical type.\n",
    "\n",
    "    This is why it is necessary to pay attention to the results returned by the describe method and always take a step back to remember what the variables are reflecting.\n",
    "\n",
    "    The manager wishes to make a quick report on the characteristics of the transactions DataFrame: in particular, he wants to know the average amount spent as well as the maximum quantity purchased.\n",
    "\n",
    "    (d) What is the average total amount spent? We are interested in the 'total_amt' column of transactions.\n",
    "\n",
    "    (e) What is the maximum quantity purchased? We will look at the 'Qty' column of transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a4f91-cec0-4937-8791-1c07fddf2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "print('average total amount spent :', transactions['total_amt'].mean())\n",
    "print('maximum quantity purchased :', transactions['Qty'].max())\n",
    "\n",
    "transactions.describe()\n",
    "\n",
    "# Applying the describe method to the transactions DataFrame\n",
    "transactions.describe()\n",
    "\n",
    "# The average total amount spent is €2109.\n",
    "# The maximum quantity purchased is 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0e072-0760-44cd-90ce-017657bcedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some transactions have negative amounts.\n",
    "\n",
    "These are transactions that have been cancelled and refunded to the client. These amounts will disrupt the distribution of the amounts which gives us bad estimates of the mean and quantiles of the variable total_amt.\n",
    "\n",
    "    (f) What is the average amount of transactions with positive amounts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad9db6-7c1f-4aa4-ac8f-5b8c3548edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "\n",
    "transactions[transactions['total_amt'] > 0].describe()\n",
    "\n",
    "# the average amount of transactions with positive amounts is worth €2608 which is\n",
    "# €500 more than we had before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8634bb-9c81-4454-ae13-2a734d96c7a1",
   "metadata": {},
   "source": [
    "## Conclusion and recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40401943-1bc8-4a85-83e5-c02229c7c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Conclusion and recap\n",
    "\n",
    "    The DataFrame class of the pandas module will be your favorite data structure when exploring, analysing and processing datasets and databases.\n",
    "\n",
    "    In this brief introduction, you have learned to:\n",
    "\n",
    "            Create a DataFrame from a numpy array and a dictionary using the pd.DataFrame constructor.\n",
    "\n",
    "            Create a DataFrame from a .csv file using the pd.read_csv function.\n",
    "\n",
    "            Display the first and last lines of a DataFrame using the head and tail methods.\n",
    "\n",
    "            Select one or more columns of a DataFrame by entering their names in square brackets as in a dictionary.\n",
    "\n",
    "            Select one or more lines of a DataFrame by filling in their index using the loc and iloc methods.\n",
    "\n",
    "            Select the lines of a DataFrame that meet a specific condition using conditional indexing.\n",
    "\n",
    "            Perform a quick statistical study of the quantitative variables of a DataFrame using the describe method.\n",
    "\n",
    "    The dataset transactions we used is very clean. The variables are cleanly filled in and do not contain any missing value. In practice, this is rarely the case. This is why in the following notebook we will see how to clean datasets with pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c78f4c90-b1a8-4cbf-a04e-6c09c7097bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type  \n",
       "transaction_id                                          \n",
       "80712190438     -772.0  405.300  -4265.300           1  \n",
       "29258453508    -1497.0  785.925  -8270.925           1  \n",
       "51750724947     -791.0  166.110  -1748.110           2  \n",
       "93274880719    -1363.0  429.345  -4518.345           1  \n",
       "51750724947     -791.0  166.110  -1748.110           2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('transactions.csv', index_col='transaction_id')\n",
    "df['\\ttran_date'] = df['\\ttran_date'].apply(lambda x : x.replace('\\t', ''))\n",
    "df.rename(columns= lambda x : x.replace('\\t', ''), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a92401ef-2fbc-4adf-98c8-6e6cdd079ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type day month  year  \n",
       "transaction_id                                                          \n",
       "80712190438     -772.0  405.300  -4265.300           1  28    02  2014  \n",
       "29258453508    -1497.0  785.925  -8270.925           1  27    02  2014  \n",
       "51750724947     -791.0  166.110  -1748.110           2  24    02  2014  \n",
       "93274880719    -1363.0  429.345  -4518.345           1  24    02  2014  \n",
       "51750724947     -791.0  166.110  -1748.110           2  23    02  2014  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'] = df['tran_date'].apply(lambda x : x.split('-')[0])\n",
    "df['month'] = df['tran_date'].apply(lambda x : x.split('-')[1])\n",
    "df['year'] = df['tran_date'].apply(lambda x : x.split('-')[2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47ab560d-2c28-42ab-8599-86c0ea32d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>853.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1654.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1506.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type day month  year  \\\n",
       "transaction_id                                                           \n",
       "80712190438     -772.0  405.300  -4265.300           1  28    02  2014   \n",
       "29258453508    -1497.0  785.925  -8270.925           1  27    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  24    02  2014   \n",
       "93274880719    -1363.0  429.345  -4518.345           1  24    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  23    02  2014   \n",
       "\n",
       "                unit_price  \n",
       "transaction_id              \n",
       "80712190438        853.060  \n",
       "29258453508       1654.185  \n",
       "51750724947        874.055  \n",
       "93274880719       1506.115  \n",
       "51750724947        874.055  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unit_price'] = df.apply(lambda row : row['total_amt']/row['qty'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057664cf-b354-4f7f-859d-ffb0543752ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28-02-2014'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date1 = df.tran_date.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709dba7-ec0e-4281-9bcd-c9d27aedb903",
   "metadata": {},
   "source": [
    "# Data Cleaning and Missing Values Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c0be4-62fb-4329-a489-1e4a14921af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('transactions.csv', sep=',', index_col='transaction_id')\n",
    "df1 = df.copy()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc83837-4446-43fd-baeb-fc7b93725415",
   "metadata": {},
   "source": [
    "## Cleaning up a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4cbb63-8e53-47b4-8e10-35027458967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Cleaning up a dataset\n",
    "\n",
    "    In this part we will introduce the methods of the DataFrame class that are essential to clean a dataset. These methods can be grouped into three different categories :\n",
    "\n",
    "            Duplicates management (duplicated and drop_duplicates methods)\n",
    "\n",
    "            Modification of the elements of a DataFrame (replace, rename and astype methods)\n",
    "\n",
    "            Operations on the values of a DataFrame (apply method and lambda functions)\n",
    "\n",
    "Managing duplicates (duplicated and drop_duplicates methods)\n",
    "\n",
    "    Duplicates are identical entries that appear more than once in a dataset.\n",
    "\n",
    "    When we first discover a dataset it is very important to check up front that there are no duplicates. The presence of duplicates will generate errors in the computation of statistics or the plotting of graphs.\n",
    "\n",
    "    Let df be the following DataFrame:\n",
    "    \tAge \tGender \tHeight\n",
    "    Robert \t56 \tM \t174\n",
    "    Mark \t23 \tM \t182\n",
    "    Alina \t32 \tF \t169\n",
    "    Mark \t23 \tM \t182\n",
    "\n",
    "    The presence of duplicates is checked using the duplicated method of a DataFrame:\n",
    "\n",
    "    # We identify the rows containing duplicates\n",
    "    df.duplicated()\n",
    "\n",
    "    >>> 0 False\n",
    "    >>> 1 False\n",
    "    >>> 2 False\n",
    "    >>> 3 True\n",
    "\n",
    "    This method returns Series object from pandas, which is equivalent to the column of a DataFrame. The Series object tells us for each row wether it is a duplicate.\n",
    "\n",
    "    In this example, the result of the duplicated method informs us that the row with index 3 is a duplicate. Indeed, it is the exact copy of the row with index 1.\n",
    "\n",
    "    Since the duplicated method returns an object of the Series class, we can apply the sum method to it in order to count the number of duplicates:\n",
    "\n",
    "    # To calculate the sum of boolean values, we consider that True is worth 1 and False is worth 0.\n",
    "    print(df.duplicated().sum())\n",
    "    >>> 1\n",
    "\n",
    "    The method of the DataFrame class used to remove duplicates is drop_duplicates. Its header is as follows:\n",
    "\n",
    "    drop_duplicates(subset, keep, inplace)\n",
    "\n",
    "            The subset parameter indicates the column(s) to consider in order to identify and remove duplicates. By default, subset = None namely we consider all the columns of the DataFrame.\n",
    "\n",
    "            The keep parameter indicates which entry should be kept :\n",
    "\n",
    "                    'first' : We keep the first occurrence.\n",
    "                    'last': We keep the last occurrence.\n",
    "                    False: We do not keep any occurrence.\n",
    "                    By default, keep = 'first'.\n",
    "\n",
    "            The inplace parameter (very common in the methods of the DataFrame class), specifies whether you modify directly the DataFrame (in this case inplace = True) or if the method returns a copy of the DataFrame (inplace = False). A method applied with the argument inplace = True is irreversible. By default, inplace = False.\n",
    "\n",
    "    You have to be very careful when using the inplace parameter. A good practice is to forget this parameter and assign the DataFrame returned by the method to a new DataFrame.\n",
    "\n",
    "    The keep parameter is the one that is most often specified. Indeed, a database can have duplicates created on different dates. We will then specify the value of the keep argument to keep only the most recent entries, for example.\n",
    "\n",
    "    Let us go back to the df DataFrame :\n",
    "    \tAge \tGender \tHeight\n",
    "    Robert \t56 \tM \t174\n",
    "    Mark \t23 \tM \t182\n",
    "    Alina \t32 \tF \t169\n",
    "    Mark \t23 \tM \t182\n",
    "\n",
    "    We illustrate df with the following illustration :\n",
    "\n",
    "    We illustrate in the following examples the entries that are deleted by the drop_duplicates method depending on the value of the keep parameter:\n",
    "\n",
    "    # We keep only the first occurrence of the duplicate\n",
    "    df_first = df.drop_duplicates(keep = 'first')\n",
    "\n",
    "\n",
    "\n",
    "    # We keep only the last occurrence of the duplicate\n",
    "    df_last = df.drop_duplicates(keep = 'last')\n",
    "\n",
    "    # We keep no duplicates\n",
    "    df_false = df.drop_duplicates(keep = False)\n",
    "\n",
    "    (a) How many duplicates are there in the transactions DataFrame ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942080a5-cc6e-4af1-aae8-96a315a9503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of duplicates\n",
    "duplicates = transactions.duplicated().sum()\n",
    "\n",
    "print (\"There are\", duplicates, \"duplicates in transactions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e20d86-4c8e-4b9b-b241-2b3efbb1296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The transactions were recorded in anti-chronological order, i.e. the first rows contain the most recent transactions and the last rows the oldest transactions.\n",
    "\n",
    "    (b) Eliminate duplicates from the database by keeping only the first occurrence, i.e. the most recent transaction.\n",
    "\n",
    "    (c) Using the subset and keep parameters of the drop_duplicates method of transactions, display the most recent transaction for each category of prod_cat_code. To do this, you can remove all the duplicates from the prod_cat_code column by keeping only the first occurrence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de930143-8d73-4a2c-9e47-e31f8bcf43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "\n",
    "transactions.drop_duplicates(subset = ['prod_cat_code'], keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0790037-2171-44bf-bcba-a0539f1ea62d",
   "metadata": {},
   "source": [
    "### Modification of the elements of a DataFrame (replace, rename and astype methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc8dcf-a7cc-4c8e-b5be-65c5f40445c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modification of the elements of a DataFrame (replace, rename and astype methods)\n",
    "\n",
    "    The replace method allows to replace one or more values ​​of a column of aDataFrame.\n",
    "\n",
    "    Its header is as follows:\n",
    "\n",
    "    replace(to_replace, value, ...)\n",
    "\n",
    "            The to_replace parameter contains the value or the list of values to be replaced. It can be a list of integers, strings, booleans, etc.\n",
    "\n",
    "            The value parameter contains the value or the list of the substitute values. It can also be a list of integers, strings, booleans, etc.\n",
    "\n",
    "\n",
    "\n",
    "    In addition to modifying the elements of a DataFrame, it is possible to rename its columns.\n",
    "\n",
    "    This is possible thanks to the rename method which takes as argument a dictionary whose keys are the old names and the values are the new names. You must also fill in the argument axis = 1 to specify that the names to rename are those of the columns.\n",
    "\n",
    "    # Creation of the dictionary associating the old names with the new column names\n",
    "    dictionary = {'old_name1': 'new_name1',\n",
    "                  'old_name2': 'new_name2'}\n",
    "\n",
    "    # We rename the variables using the rename method\n",
    "    df = df.rename(dictionary, axis = 1)\n",
    "\n",
    "    It is sometimes necessary to modify not only the name of a column but also its type.\n",
    "\n",
    "    For example, it is possible that when importing a database, a variable is of type string when in fact it is a numerical variable. Whenever one of the entries in the column is incorrectly recognized, pandas will consider that this column is of type string.\n",
    "\n",
    "    This is possible thanks to the astype method.\n",
    "\n",
    "    The types that we will see most often are:\n",
    "\n",
    "            str: Character string ('Hello').\n",
    "            float: Floating point number (1.0, 1.14123).\n",
    "            Int: Integer (1,1231)\n",
    "\n",
    "    As for the rename method, astype can take as argument a dictionary whose keys are the names of the columns whose type should be modified and the values are the new types to assign. This is useful if you want to change the type of several columns at once.\n",
    "\n",
    "    Most often, we will directly select the column whose type should be modified and overwrite it by applying the astype method to it.\n",
    "\n",
    "    # Method 1: Creation of a dictionary then call to the astype method of the DataFrame\n",
    "    dictionary = {'col_1': 'int',\n",
    "                  'col_2': 'float'}\n",
    "    df = df.astype(dictionary)\n",
    "\n",
    "    # Method 2: Selection of the column and then calling the astype method of a Series\n",
    "    df['col_1'] = df['col_1'].astype('int')\n",
    "\n",
    "    These methods also have the inplace parameter to perform the operation directly on the DataFrame. To be used with great caution.\n",
    "\n",
    "    If you make a mistake in the next exercise, you can re-import and redo the preprocessing by running the following cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273e3d9-6476-4bbc-8240-140157e49a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fdc2b-2f2e-4b8c-b3a7-4c995f984654",
   "metadata": {},
   "outputs": [],
   "source": [
    "    d) Import the numpy module under the namenp.\n",
    "\n",
    "    (e) Replace the modalities ['e-Shop', 'TeleShop', 'MBR', 'Flagship store', np.nan] of the Store_type column by the modalities [1, 2, 3, 4, 0].\n",
    "\n",
    "        The np.nan value is the one that encodes a missing value. We will replace this value with 0.\n",
    "\n",
    "    (f) Convert the type of the columns Store_type and prod_subcat_code to type 'int'.\n",
    "\n",
    "    (g) Rename the 'Store_type','Qty', 'Rate' and 'Tax' columns with 'store_type','qty', 'rate' and 'tax'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10305ad-5604-4a03-8ddf-84e5e973c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "## Exercise\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Replacement of values\n",
    "transactions = transactions.replace(to_replace = ['e-Shop', 'TeleShop', 'MBR', 'Flagship store', np.nan],\n",
    "                                    value = [1, 2, 3, 4, 0])\n",
    "\n",
    "# Conversion of column types\n",
    "new_types = {'Store_type'       : 'int',\n",
    "             'prod_subcat_code' : 'int'}\n",
    "\n",
    "transactions = transactions.astype(new_types)\n",
    "\n",
    "# Renaming the columns\n",
    "new_names = {'Store_type'   : 'store_type',\n",
    "              'Qty'         : 'qty',\n",
    "              'Rate'        : 'rate',\n",
    "              'Tax'         : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "# Display of the first rows of transactions\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb24d22-8c72-4e64-9600-c74f167b1c40",
   "metadata": {},
   "source": [
    "### Operations on the values of a DataFrame (apply method and lambda functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7a8d6-c2be-4111-ba57-ac49e61d8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Operations on the values ​​of a DataFrame (apply method and lambda functions)\n",
    "\n",
    "    It is often interesting to modify or aggregate the information of the columns of a DataFrame using an operation or a function.\n",
    "\n",
    "    These operations can be any type of function which takes a column as argument. Thus, the numpy module is perfectly suited to perform operations on this type of object.\n",
    "\n",
    "    The method used to perform an operation on a column is the apply method of a DataFrame whose header is:\n",
    "\n",
    "    apply(func, axis, ...)\n",
    "\n",
    "    where:\n",
    "\n",
    "            func is the function to apply to the column.\n",
    "            axis is the dimension on which the operation must be applied.\n",
    "\n",
    "    Example: apply and np.sum\n",
    "\n",
    "    For each column with numerical values, we want to calculate the sum of all rows. The sum function of numpy does this, so we can use it with the apply method.\n",
    "\n",
    "    Since we are going to perform an operation on the rows, we must therefore specify the argument axis = 0 in the apply method.\n",
    "\n",
    "    # Sum of the ROWS for each column of df\n",
    "    df_lines = df.apply(np.sum, axis = 0)\n",
    "\n",
    "    The result is the following:\n",
    "\n",
    "\n",
    "    Now, for each row we want to compute the sum of all the columns.\n",
    "\n",
    "    We are going to perform this operation on the columns, we must therefore specify the argument axis = 1 in the apply method.\n",
    "\n",
    "    # Sum of columns for each ROW of df\n",
    "    df_columns = df.apply(np.sum, axis = 1)\n",
    "\n",
    "    The result is the following:\n",
    "\n",
    "    These examples only illustrate the use of the apply method. To actually compute the sum of rows or columns, it is better to use the sum method of a DataFrame or a Series, which behaves in exactly the same way as the sum method of a numpy array.\n",
    "\n",
    "The tran_date column of transactions contains the dates of the transactions in the format ('day-month-year') (ex: '28-02-2014'). The dates are of type string: it is not possible to perform statistics on this variable for the moment.\n",
    "\n",
    "We would rather have 3 different columns for the day, month and year of each transaction. This would allow us, for example, to analyze and detect trends in transaction dates.\n",
    "\n",
    "The date '28-02-2014' is a string. The day, month and year are separated by a hyphen '-'. The character string class has the split method to split a string on a specific character:\n",
    "\n",
    "date = '28-02-2014 '\n",
    "\n",
    "# Splitting the string on the '-' character\n",
    "print(date.split('-'))\n",
    ">>> ['28', '02', '2014']\n",
    "\n",
    "This method returns a list containing the slices of the string on the specified character. Thus, to retrieve the day, all you have to do is select the first element of the split. To recover the month, we must take the second element and for the year the third.\n",
    "\n",
    "    (h) Define a function get_day taking as argument a string and which returns the first element of its split by the character '-'.\n",
    "\n",
    "    (i) Define the functions get_month and get_year which do the same with the second and third element of the split.\n",
    "\n",
    "    (j) In 3 variables called days, months and years, store the result of the apply method on the tran_date column with the get_day, get_month and get_year functions. As these functions work element-wise, it is not necessary to specify the argument axis in the apply method.\n",
    "\n",
    "    (k) Create the columns 'day', 'month' and 'year' in the transactions DataFrame and store the values of the days, months and years. Creating a new column is simply done by declaring it:\n",
    "\n",
    "        # Create a new column 'day' with the values contained in days.\n",
    "        transactions['day'] = days\n",
    "\n",
    "    (l) Display the first 5 rows of transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791eb2a5-c82b-49c9-9b57-10030b4d6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the functions to apply to the 'tran_date' column\n",
    "def get_day(date):\n",
    "    \"\"\"\n",
    "    Takes a date as a string argument.\n",
    "    \n",
    "    The date must have the format 'DD-MM-YYYY'.\n",
    "    \n",
    "    This function returns the day (DD).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Splitting the string on the '-' character\n",
    "    splits = date.split('-')\n",
    "    \n",
    "    # We return the first element of the breakdown (day)\n",
    "    day = splits[0]\n",
    "    return day\n",
    "\n",
    "def get_month(date):\n",
    "    return date.split('-')[1]\n",
    "\n",
    "def get_year(date):\n",
    "    return date.split('-')[2]\n",
    "    \n",
    "    \n",
    "# Retrieving the day, month and year of each transaction\n",
    "days = transactions['tran_date'].apply(get_day)\n",
    "months = transactions['tran_date'].apply(get_month)\n",
    "years = transactions['tran_date'].apply(get_year)\n",
    "\n",
    "# Creation of new columns\n",
    "transactions['day'] = days\n",
    "transactions['month'] = months\n",
    "transactions['year'] = years\n",
    "\n",
    "# Displaying first rows of transactions\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e9aab-68b0-4a53-88eb-40cd6845f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The apply method is very powerful when combined with a lambda function.\n",
    "\n",
    "    In Python, the keyword lambda is used to define an anonymous function: a function declared without name.\n",
    "\n",
    "    A function lambda can take any number of arguments, but can only have one expression.\n",
    "\n",
    "    Here is its syntax:\n",
    "\n",
    "    lambda arguments: expression\n",
    "\n",
    "    Lambda functions allow you to define functions with a very short syntax :\n",
    "\n",
    "    # Example 1 \n",
    "    x = lambda a: a + 2\n",
    "    print(x(3))\n",
    "    >>> 5\n",
    "\n",
    "    # Example 2 \n",
    "    x = lambda a, b : a * b\n",
    "    print(x(2, 3))\n",
    "    >>> 6\n",
    "\n",
    "    # Example 3 \n",
    "    x = lambda a, b, c : a - b + c\n",
    "    print(x(1, 2, 3))\n",
    "    >>> 2\n",
    "\n",
    "    Although syntactically different, lambda functions behave in the same way as regular functions that are declared using the def keyword.\n",
    "\n",
    "    The classic definition of a function is done with the def keyword:\n",
    "\n",
    "    def increment(x):\n",
    "        return x + 1\n",
    "\n",
    "    It is also possible to define a function with the keyword lambda:\n",
    "\n",
    "    increment = lambda x: x + 1\n",
    "\n",
    "    The first method is very clean but the advantage of the second is that it can be defined on-the-fly directly within the apply method.\n",
    "\n",
    "    Thus, the previous exercise can be done with a very compact syntax:\n",
    "\n",
    "    transactions['day'] = transactions['tran_date'].apply(lambda date: date.split('-')[0])\n",
    "\n",
    "    This kind of syntax is very practical and very often used for cleaning databases.\n",
    "\n",
    "    The prod_subcat_code column of transactions depends on the prod_cat_code column because it identifies a subcategory of product. It would make more sense to have the category and subcategory of a product in the same variable.\n",
    "\n",
    "    To do this, we will merge the values of these two columns:\n",
    "\n",
    "            We will first convert the values of these two columns into strings using the astype method.\n",
    "\n",
    "            Then, we will concatenate these strings to have a unique code representing both the category and sub-category. This can be done in the following way:\n",
    "\n",
    "        string1 = \"I think\"\n",
    "        string2 = \"therefore I am.\"\n",
    "\n",
    "        # Concatenation of the two strings by separating them with a space\n",
    "        print (string1 + \" \" + string2)\n",
    "        >>> I think therefore I am.\n",
    "\n",
    "To apply a lambda function to an entire row, you must specify the argument axis = 1 in the apply method. In the function itself, the columns of the row can be accessed as on a DataFrame:\n",
    "\n",
    "# Computation of the unit price of a product\n",
    "transactions.apply(lambda row: row['total_ amt']/row['qty'], axis = 1)\n",
    "\n",
    "    (m) Using a lambda function applied to transactions, create a column 'prod_cat' in transactions containing the concatenation of the values ofprod_cat_code and prod_subcat_code separated by a hyphen '-'. Remember to convert the values to strings.\n",
    "\n",
    "    Displaying this column should yield:\n",
    "\n",
    "    transaction_id\n",
    "    80712190438     1-1\n",
    "    29258453508     3-5\n",
    "    51750724947     5-6\n",
    "    93274880719     6-11\n",
    "    51750724947     5-6\n",
    "                   ...\n",
    "    94340757522     5-12\n",
    "    89780862956     1-4\n",
    "    85115299378     6-2\n",
    "    72870271171     5-11\n",
    "    77960931771     5-11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01812d1a-af3b-4245-904e-c5c00d160eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions['prod_cat'] = transactions.apply(lambda row : str(row['prod_cat_code']) + '-' + str(row['prod_subcat_code']),\n",
    "                                    axis=1)\n",
    "transactions.head()\n",
    "\n",
    "# original cozum\n",
    "transactions['prod_cat'] = transactions.astype('str').apply(lambda row: row['prod_cat_code']+'-'+row['prod_subcat_code'],\n",
    "                                                            axis = 1)\n",
    "\n",
    "print(transactions['prod_cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab02afb-fd94-4071-8d72-bdc4d00f5ea2",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e407e-2766-44c0-9f7a-8b906f29ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Dealing with missing values\n",
    "\n",
    "    A missing value is either:\n",
    "\n",
    "            An unspecified value.\n",
    "            A value that does not exist. In general, they result from mathematical calculations having no solution (a division by zero for example).\n",
    "\n",
    "    A missing value appears under the name NaN (\"Not a Number\") in a DataFrame.\n",
    "\n",
    "    In this part, we will see several methods to:\n",
    "\n",
    "            Detect missing values (isna and any methods)\n",
    "            Replace these values (fillna method)\n",
    "            Delete missing values (dropna method)\n",
    "\n",
    "    In one of the previous exercises, we used the replace method of transactions to replace missing values with 0. This approach is not rigorous and should not be done in practice.\n",
    "\n",
    "    For this reason, we are going to re-import the raw version of transactions to undo the steps we did in the previous exercises.\n",
    "\n",
    "    (a) Run the cell below to re-import transactions, remove duplicates and rename its columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41321379-0ac6-4665-9b12-e7624ad64ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Duplicates removal\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Renaming the columns\n",
    "new_names = {'Store_type'  : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7808142-4d1c-4dab-a0c5-49e643106afc",
   "metadata": {},
   "source": [
    "### Detecting missing values (isna and any methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b76593-f9d2-4d84-a2ca-6859c91af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detecting missing values (isna and any methods)\n",
    "\n",
    "    The isna method of a DataFrame detects its missing values. This method does not take any arguments.\n",
    "\n",
    "    This method returns the same DataFrame whose values are:\n",
    "\n",
    "            True if the original table cell is a missing value (np.nan)\n",
    "            False otherwise.\n",
    "\n",
    "\n",
    "\n",
    "    Since the isna method returns a DataFrame, we can use it with other methods of the DataFrame class to get more precise information:\n",
    "\n",
    "            The any method - thanks to its axis argument - allows to determine which columns (axis = 0) or which rows (axis = 1) contain at least one missing value.\n",
    "\n",
    "            The sum method counts the number of missing values per column or row (by specifying the axis argument). It is possible to use other statistical methods like mean,max, argmax, etc.\n",
    "\n",
    "    Here are many examples of using the any and sum methods with isna:\n",
    "\n",
    "    We use the DataFrame df from the previous illustrations:\n",
    "    \tName \tCountry \tAge\n",
    "    0 \tNaN \tAustralia \tNaN\n",
    "    1 \tDuchamp \tFrance \t25\n",
    "    2 \tHana \tJapan \t54\n",
    "\n",
    "    The df.isna() instruction returns:\n",
    "    \tName \tCountry \tAge\n",
    "    0 \tTrue \tFalse \tTrue\n",
    "    1 \tFalse \tFalse \tFalse\n",
    "    2 \tFalse \tFalse \tFalse\n",
    "\n",
    "    # COLUMNS containing at least one missing value are detected\n",
    "    df.isna().any(axis = 0)\n",
    "\n",
    "    >>> Name     True\n",
    "    >>> Country  False\n",
    "    >>> Age      True\n",
    "\n",
    "    # ROWS containing at least one missing value are detected\n",
    "    df.isna().any (axis = 1)\n",
    "\n",
    "    >>> 0    True\n",
    "    >>> 1    False\n",
    "    >>> 2    False\n",
    "\n",
    "    # Using conditional indexing to display entries\n",
    "    # containing missing values\n",
    "    df[df.isna().any(axis = 1)]\n",
    "\n",
    "    which returns the DataFrame:\n",
    "    \tName \tCountry \tAge\n",
    "    0 \tNaN \tAustralia \tNaN\n",
    "\n",
    "    # We count the number of missing values for each COLUMN\n",
    "    df.isnull().sum(axis = 0)\n",
    "\n",
    "    >>> Name     1\n",
    "    >>> Country  0\n",
    "    >>> Age      1\n",
    "\n",
    "    # Count the number of missing values for each ROW\n",
    "    df.isnull().sum(axis = 1)\n",
    "\n",
    "    >>> 0   2\n",
    "    >>> 1   0\n",
    "    >>> 2   0\n",
    "\n",
    "    The methods isnaand isnullhave exactly the same behavior.\n",
    "\n",
    "    (b) How many columns of the transactions DataFrame contain missing values?\n",
    "\n",
    "    (c) How many of transactions' entries contain missing values? You can use the any method along with the sum method.\n",
    "\n",
    "    (d) Which column of transactions contains the most of missing values? You can use the idxmax method that returns the index of first occurrence of maximum over the requested axis.\n",
    "\n",
    "    (e) Show transaction entries that contain at least one missing value in the 'rate', 'tax' and 'total_amt' columns. What do you notice?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d50d58-ef20-4c82-8558-ca4d7cb01fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns contain NaNs\n",
    "columns_na = transactions.isna().any(axis = 0)\n",
    "\n",
    "print(columns_na.sum(), \"columns of transactions contain NaNs. \\n\")\n",
    "\n",
    "# Which rows contain NaNs\n",
    "rows_na = transactions.isna().any(axis = 1)\n",
    "\n",
    "print(rows_na.sum(), \"rows of transactions contain NaNs. \\n\")\n",
    "\n",
    "# Number of NaNs per column\n",
    "columns_nbna = transactions.isna().sum(axis = 0)\n",
    "\n",
    "print (\"The column containing the most NaNs is:\",  columns_nbna.idxmax())\n",
    "\n",
    "# Display the first 10 entries containing at least one NaN in 'rate', 'tax' or 'total_amt'\n",
    "transactions[transactions[['rate', 'tax', 'total_amt']].isna().any(axis = 1)].head(10)\n",
    "\n",
    "# The three variables are still missing together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7226c-4677-4db5-bde5-e6055be992f8",
   "metadata": {},
   "source": [
    "### Replacing missing values (fillna method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b4960-bec8-4d79-9fea-b28260bfadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Replacing missing values (fillna method)\n",
    "\n",
    "    The fillna method allows you to replace the missing values of a DataFrame by values you want.\n",
    "\n",
    "    # We replace all the NaNs of the DataFrame by zeros\n",
    "    df.fillna(0)\n",
    "\n",
    "    # We replace the NaNs of each numerical column by the average on this column\n",
    "    df.fillna(df.mean()) # df.mean() can be replaced by any statistical method.\n",
    "\n",
    "    It is common to replace missing values of a column containing numerical values with statistics like:\n",
    "\n",
    "            The mean: .mean\n",
    "            The median: .median\n",
    "            The minimum / maximum: .min / .max.\n",
    "\n",
    "    For categorical type columns, replace the missing values with:\n",
    "\n",
    "            The mode, i.e. the most frequent modality: .mode.\n",
    "            A constant or arbitrary category: 0,-1.\n",
    "\n",
    "    To avoid making replacement errors, it is very important to select the correct columns before using the fillna method.\n",
    "\n",
    "If you make mistakes in the following exercise, you can re-import transactions using the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8f110-9129-4fed-bed9-df5862a67311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Renaming the columns\n",
    "new_names = {'Store_type' : 'store_type',\n",
    "              'Qty'       : 'qty',\n",
    "              'Rate'      : 'rate',\n",
    "              'Tax'       : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b5c17-1ef7-42dc-ae0f-2fdc7a4505ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    (f) Replace the missing values in prod_subcat_code column of transactions with -1.\n",
    "\n",
    "    (g) Determine the most frequent modality (the mode) of the store_type column of transactions.\n",
    "\n",
    "    (h) Replace the missing values of the store_type column by this modality. The value of this modality is accessed at index 0 of the Series returned by mode.\n",
    "\n",
    "    (i) Check that the prod_subcat_code and store_type columns of transactions no longer contain missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e257ae6-fd57-4f05-af0a-18d2cffaf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the NaNs of 'prod_subcat_code' by -1\n",
    "transactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1)\n",
    "\n",
    "# Determining the mode of 'store_type'\n",
    "store_type_mode = transactions['store_type'].mode()\n",
    "print (\"The most frequent mode of 'store_type' is:\", store_type_mode[0])\n",
    "\n",
    "# Replacing the NaNs of 'store_type' by its mode\n",
    "transactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n",
    "\n",
    "# Checking that these two columns no longer contain NANs\n",
    "transactions[['prod_subcat_code', 'store_type']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da779626-4bd8-4e67-a447-f5922738024f",
   "metadata": {},
   "source": [
    "### Removing missing values (dropna method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ba4e8-1d41-4e79-8e54-6a638055dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removing missing values (dropna method)\n",
    "\n",
    "    The dropna method allows you to remove rows or columns containing missing values.\n",
    "\n",
    "    The header of the method is as follows:\n",
    "\n",
    "    dropna(axis, how, subset, ..)\n",
    "\n",
    "            The axis parameter specifies whether to delete rows or columns (0 for rows, 1 for columns).\n",
    "\n",
    "            The how parameter lets you specify how the rows (or columns) are deleted:\n",
    "\n",
    "                    how = 'any': We delete the row (or column) if it contains at least one missing value.\n",
    "                    how = 'all': We delete the row (or column) if it contains only missing values.\n",
    "\n",
    "            The subset parameter is used to specify the columns/rows on which the search for missing values is carried out.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # We delete all the rows containing at least one missing value\n",
    "    df = df.dropna(axis = 0, how = 'any')\n",
    "\n",
    "    # We delete the empty columns\n",
    "    df = df.dropna(axis = 1, how = 'all')\n",
    "\n",
    "    # We remove the rows with missing values in the 3 columns 'col2', 'col3' and 'col4'\n",
    "    df.dropna(axis = 0, how = 'all', subset = ['col2', 'col3', 'col4'])\n",
    "\n",
    "    As with the other methods of replacing values of a DataFrame, the inplace argument can be used with great care to perform the modification directly without reassignment.\n",
    "\n",
    "Transaction data for which the transaction amount is not provided is of no interest to us. For this reason:\n",
    "\n",
    "    (j) Delete the transaction entries for which the rate, tax and total_amt columns are all empty.\n",
    "\n",
    "    (k) Check that the columns of transactions no longer contain missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6a353-a505-4606-a6de-eaffbbda1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.dropna(axis = 0, how = 'all', subset = ['rate', 'tax', 'total_amt'])\n",
    "\n",
    "transactions.isna().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230e19d-11a0-43ef-af5a-9ce852b66836",
   "metadata": {},
   "source": [
    "## Conclusion and recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6b436-5a42-4c76-a9ef-e1a727e4d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion and recap\n",
    "\n",
    "    In this chapter we have seen the essential methods of the pandas module in order to clean up a dataset and manage missing values ​​(NaN).\n",
    "\n",
    "    This step of preparing a dataset is always the first step of a data project.\n",
    "\n",
    "    Regarding data cleaning, we have learned how to:\n",
    "\n",
    "            Identify and delete duplicates of a DataFrame using the duplicated and drop_duplicates methods.\n",
    "\n",
    "            Modify the elements of a DataFrame and their type using the replace, rename and astype methods.\n",
    "\n",
    "            Apply a function to a DataFrame with the apply method and the lambda clause.\n",
    "\n",
    "    Regarding the management of missing values, we have learned to:\n",
    "\n",
    "            Detect them using the isna method followed by the any and sum methods.\n",
    "\n",
    "            Replace them using the fillna method and the statistical methods.\n",
    "\n",
    "            Delete them using the dropna method.\n",
    "\n",
    "    In the following notebook, you will see other manipulations of DataFrames for a more advanced exploration of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea0eda-5654-4c32-b6b7-768f413e2ad6",
   "metadata": {},
   "source": [
    "## Apply, Lamda, Func Ornekleri (EXTRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "902b49e9-3419-413f-b789-30135dabc168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transaction_id\n",
       "80712190438    28\n",
       "29258453508    27\n",
       "51750724947    24\n",
       "93274880719    24\n",
       "51750724947    23\n",
       "Name: day2, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_day(string):\n",
    "    day = string.split('-')[0]\n",
    "    return day\n",
    "\n",
    "def get_day_column(df, column):\n",
    "    lst1 = [i.split('-')[0] for i in column]\n",
    "    df['day2'] = np.array(lst1)\n",
    "    return df['day2']\n",
    "        \n",
    "date1 = df.tran_date.iloc[0]\n",
    "date1\n",
    "\n",
    "print(get_day(date1))\n",
    "# 1. Yol\n",
    "df['day'] = df.tran_date.apply(get_day)\n",
    "\n",
    "# 2. Yol\n",
    "get_day_column(df, df.tran_date.values)\n",
    "\n",
    "# 3. Yol \n",
    "df['day'] = df['tran_date'].apply(lambda x : x.split('-')[0])\n",
    "\n",
    "# 4.yol\n",
    "df[['day', 'month', 'year']] = df['tran_date'].str.split(expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38910a81-9694-4d1c-ab2a-619b64f95be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['28-02-2014', '27-02-2014', '24-02-2014', '24-02-2014',\n",
       "       '23-02-2014'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tran_date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f517951b-ae5c-45e3-80de-5414f40c7b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>day2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>853.060</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1654.185</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1506.115</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type day month  year  \\\n",
       "transaction_id                                                           \n",
       "80712190438     -772.0  405.300  -4265.300           1  28    02  2014   \n",
       "29258453508    -1497.0  785.925  -8270.925           1  27    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  24    02  2014   \n",
       "93274880719    -1363.0  429.345  -4518.345           1  24    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  23    02  2014   \n",
       "\n",
       "                unit_price day2  \n",
       "transaction_id                   \n",
       "80712190438        853.060   28  \n",
       "29258453508       1654.185   27  \n",
       "51750724947        874.055   24  \n",
       "93274880719       1506.115   24  \n",
       "51750724947        874.055   23  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da4a9cfe-6810-4eae-ae69-dd133db072bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lila</td>\n",
       "      <td>Twingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiago</td>\n",
       "      <td>Clio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berenice</td>\n",
       "      <td>C4 Cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Twingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kader</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Romy</td>\n",
       "      <td>Scenic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name         Car\n",
       "0      Lila      Twingo\n",
       "1     Tiago        Clio\n",
       "2  Berenice   C4 Cactus\n",
       "3    Joseph      Twingo\n",
       "4     Kader       Swift\n",
       "5      Romy      Scenic"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df_names = pd.read_clipboard()\n",
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1e1ba19-8077-4e5c-bd18-2c74eb9aff83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twingo</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swift</td>\n",
       "      <td>14500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4 Cactus</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clio</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prius</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Car  Price\n",
       "0     Twingo   11000\n",
       "1      Swift   14500\n",
       "2  C4 Cactus   23000\n",
       "3       Clio   16000\n",
       "4      Prius   30000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_cars = pd.read_clipboard()\n",
    "df_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a1bca30-dbb8-4e35-94ca-2ae9d36abedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95.7</td>\n",
       "      <td>166.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>52.8</td>\n",
       "      <td>2122</td>\n",
       "      <td>98</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>4800</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>8358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>95.7</td>\n",
       "      <td>166.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>52.8</td>\n",
       "      <td>2140</td>\n",
       "      <td>98</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>4800</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>9258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>94.5</td>\n",
       "      <td>168.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>2169</td>\n",
       "      <td>98</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>4800</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>8058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>94.5</td>\n",
       "      <td>168.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>2204</td>\n",
       "      <td>98</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.03</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>4800</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>8238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>94.5</td>\n",
       "      <td>168.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>2265</td>\n",
       "      <td>98</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.08</td>\n",
       "      <td>9.4</td>\n",
       "      <td>112</td>\n",
       "      <td>6600</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>9298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>94.5</td>\n",
       "      <td>168.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>52.6</td>\n",
       "      <td>2300</td>\n",
       "      <td>98</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.08</td>\n",
       "      <td>9.4</td>\n",
       "      <td>112</td>\n",
       "      <td>6600</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>98.4</td>\n",
       "      <td>176.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2540</td>\n",
       "      <td>146</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>116</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>98.4</td>\n",
       "      <td>176.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2536</td>\n",
       "      <td>146</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>116</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>9639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>98.4</td>\n",
       "      <td>176.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2551</td>\n",
       "      <td>146</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>116</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>98.4</td>\n",
       "      <td>176.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2679</td>\n",
       "      <td>146</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>116</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>11199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>98.4</td>\n",
       "      <td>176.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2714</td>\n",
       "      <td>146</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>116</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>11549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2</td>\n",
       "      <td>134</td>\n",
       "      <td>98.4</td>\n",
       "      <td>176.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2975</td>\n",
       "      <td>146</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.50</td>\n",
       "      <td>9.3</td>\n",
       "      <td>116</td>\n",
       "      <td>4800</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>17669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>102.4</td>\n",
       "      <td>175.6</td>\n",
       "      <td>66.5</td>\n",
       "      <td>54.9</td>\n",
       "      <td>2326</td>\n",
       "      <td>122</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.54</td>\n",
       "      <td>8.7</td>\n",
       "      <td>92</td>\n",
       "      <td>4200</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>8948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>102.4</td>\n",
       "      <td>175.6</td>\n",
       "      <td>66.5</td>\n",
       "      <td>54.9</td>\n",
       "      <td>2480</td>\n",
       "      <td>110</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>22.5</td>\n",
       "      <td>73</td>\n",
       "      <td>4500</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>10698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>102.4</td>\n",
       "      <td>175.6</td>\n",
       "      <td>66.5</td>\n",
       "      <td>53.9</td>\n",
       "      <td>2414</td>\n",
       "      <td>122</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.54</td>\n",
       "      <td>8.7</td>\n",
       "      <td>92</td>\n",
       "      <td>4200</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>9988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>102.4</td>\n",
       "      <td>175.6</td>\n",
       "      <td>66.5</td>\n",
       "      <td>54.9</td>\n",
       "      <td>2414</td>\n",
       "      <td>122</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.54</td>\n",
       "      <td>8.7</td>\n",
       "      <td>92</td>\n",
       "      <td>4200</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>10898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-1</td>\n",
       "      <td>65</td>\n",
       "      <td>102.4</td>\n",
       "      <td>175.6</td>\n",
       "      <td>66.5</td>\n",
       "      <td>53.9</td>\n",
       "      <td>2458</td>\n",
       "      <td>122</td>\n",
       "      <td>3.31</td>\n",
       "      <td>3.54</td>\n",
       "      <td>8.7</td>\n",
       "      <td>92</td>\n",
       "      <td>4200</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>11248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>102.9</td>\n",
       "      <td>183.5</td>\n",
       "      <td>67.7</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2976</td>\n",
       "      <td>171</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>9.3</td>\n",
       "      <td>161</td>\n",
       "      <td>5200</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>16558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>3</td>\n",
       "      <td>197</td>\n",
       "      <td>102.9</td>\n",
       "      <td>183.5</td>\n",
       "      <td>67.7</td>\n",
       "      <td>52.0</td>\n",
       "      <td>3016</td>\n",
       "      <td>171</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>9.3</td>\n",
       "      <td>161</td>\n",
       "      <td>5200</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>15998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-1</td>\n",
       "      <td>90</td>\n",
       "      <td>104.5</td>\n",
       "      <td>187.8</td>\n",
       "      <td>66.5</td>\n",
       "      <td>54.1</td>\n",
       "      <td>3131</td>\n",
       "      <td>171</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.35</td>\n",
       "      <td>9.2</td>\n",
       "      <td>156</td>\n",
       "      <td>5200</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>15690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2261</td>\n",
       "      <td>97</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4800</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>7775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2209</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85</td>\n",
       "      <td>5250</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>7975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2264</td>\n",
       "      <td>97</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>52</td>\n",
       "      <td>4800</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>7995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2212</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85</td>\n",
       "      <td>5250</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>8195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2275</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>9.0</td>\n",
       "      <td>85</td>\n",
       "      <td>5250</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>8495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2319</td>\n",
       "      <td>97</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>68</td>\n",
       "      <td>4500</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>97.3</td>\n",
       "      <td>171.7</td>\n",
       "      <td>65.5</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2300</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100</td>\n",
       "      <td>5500</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>94.5</td>\n",
       "      <td>165.7</td>\n",
       "      <td>64.0</td>\n",
       "      <td>51.4</td>\n",
       "      <td>2221</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>90</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>29</td>\n",
       "      <td>9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-2</td>\n",
       "      <td>103</td>\n",
       "      <td>104.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>2912</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>12940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>104.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>57.5</td>\n",
       "      <td>3034</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>13415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-2</td>\n",
       "      <td>103</td>\n",
       "      <td>104.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>2935</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>15985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>104.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>57.5</td>\n",
       "      <td>3042</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>16515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-2</td>\n",
       "      <td>103</td>\n",
       "      <td>104.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>3045</td>\n",
       "      <td>130</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.15</td>\n",
       "      <td>7.5</td>\n",
       "      <td>162</td>\n",
       "      <td>5100</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>18420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-1</td>\n",
       "      <td>74</td>\n",
       "      <td>104.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>67.2</td>\n",
       "      <td>57.5</td>\n",
       "      <td>3157</td>\n",
       "      <td>130</td>\n",
       "      <td>3.62</td>\n",
       "      <td>3.15</td>\n",
       "      <td>7.5</td>\n",
       "      <td>162</td>\n",
       "      <td>5100</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>18950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2952</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>16845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.8</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3049</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>19045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3012</td>\n",
       "      <td>173</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3217</td>\n",
       "      <td>145</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3062</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>22625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling  normalized-losses  wheel-base  length  width  height  \\\n",
       "120          0                 91        95.7   166.3   64.4    52.8   \n",
       "121          0                 91        95.7   166.3   64.4    52.8   \n",
       "122          1                168        94.5   168.7   64.0    52.6   \n",
       "123          1                168        94.5   168.7   64.0    52.6   \n",
       "124          1                168        94.5   168.7   64.0    52.6   \n",
       "125          1                168        94.5   168.7   64.0    52.6   \n",
       "126          2                134        98.4   176.2   65.6    52.0   \n",
       "127          2                134        98.4   176.2   65.6    52.0   \n",
       "128          2                134        98.4   176.2   65.6    52.0   \n",
       "129          2                134        98.4   176.2   65.6    52.0   \n",
       "130          2                134        98.4   176.2   65.6    52.0   \n",
       "131          2                134        98.4   176.2   65.6    53.0   \n",
       "132         -1                 65       102.4   175.6   66.5    54.9   \n",
       "133         -1                 65       102.4   175.6   66.5    54.9   \n",
       "134         -1                 65       102.4   175.6   66.5    53.9   \n",
       "135         -1                 65       102.4   175.6   66.5    54.9   \n",
       "136         -1                 65       102.4   175.6   66.5    53.9   \n",
       "137          3                197       102.9   183.5   67.7    52.0   \n",
       "138          3                197       102.9   183.5   67.7    52.0   \n",
       "139         -1                 90       104.5   187.8   66.5    54.1   \n",
       "140          2                122        97.3   171.7   65.5    55.7   \n",
       "141          2                122        97.3   171.7   65.5    55.7   \n",
       "142          2                 94        97.3   171.7   65.5    55.7   \n",
       "143          2                 94        97.3   171.7   65.5    55.7   \n",
       "144          2                 94        97.3   171.7   65.5    55.7   \n",
       "145          2                 94        97.3   171.7   65.5    55.7   \n",
       "146          2                 94        97.3   171.7   65.5    55.7   \n",
       "147          3                256        94.5   165.7   64.0    51.4   \n",
       "148         -2                103       104.3   188.8   67.2    56.2   \n",
       "149         -1                 74       104.3   188.8   67.2    57.5   \n",
       "150         -2                103       104.3   188.8   67.2    56.2   \n",
       "151         -1                 74       104.3   188.8   67.2    57.5   \n",
       "152         -2                103       104.3   188.8   67.2    56.2   \n",
       "153         -1                 74       104.3   188.8   67.2    57.5   \n",
       "154         -1                 95       109.1   188.8   68.9    55.5   \n",
       "155         -1                 95       109.1   188.8   68.8    55.5   \n",
       "156         -1                 95       109.1   188.8   68.9    55.5   \n",
       "157         -1                 95       109.1   188.8   68.9    55.5   \n",
       "158         -1                 95       109.1   188.8   68.9    55.5   \n",
       "\n",
       "     curb-weight  engine-size  bore  stroke  compression-ratio  horsepower  \\\n",
       "120         2122           98  3.19    3.03                9.0          70   \n",
       "121         2140           98  3.19    3.03                9.0          70   \n",
       "122         2169           98  3.19    3.03                9.0          70   \n",
       "123         2204           98  3.19    3.03                9.0          70   \n",
       "124         2265           98  3.24    3.08                9.4         112   \n",
       "125         2300           98  3.24    3.08                9.4         112   \n",
       "126         2540          146  3.62    3.50                9.3         116   \n",
       "127         2536          146  3.62    3.50                9.3         116   \n",
       "128         2551          146  3.62    3.50                9.3         116   \n",
       "129         2679          146  3.62    3.50                9.3         116   \n",
       "130         2714          146  3.62    3.50                9.3         116   \n",
       "131         2975          146  3.62    3.50                9.3         116   \n",
       "132         2326          122  3.31    3.54                8.7          92   \n",
       "133         2480          110  3.27    3.35               22.5          73   \n",
       "134         2414          122  3.31    3.54                8.7          92   \n",
       "135         2414          122  3.31    3.54                8.7          92   \n",
       "136         2458          122  3.31    3.54                8.7          92   \n",
       "137         2976          171  3.27    3.35                9.3         161   \n",
       "138         3016          171  3.27    3.35                9.3         161   \n",
       "139         3131          171  3.27    3.35                9.2         156   \n",
       "140         2261           97  3.01    3.40               23.0          52   \n",
       "141         2209          109  3.19    3.40                9.0          85   \n",
       "142         2264           97  3.01    3.40               23.0          52   \n",
       "143         2212          109  3.19    3.40                9.0          85   \n",
       "144         2275          109  3.19    3.40                9.0          85   \n",
       "145         2319           97  3.01    3.40               23.0          68   \n",
       "146         2300          109  3.19    3.40               10.0         100   \n",
       "147         2221          109  3.19    3.40                8.5          90   \n",
       "148         2912          141  3.78    3.15                9.5         114   \n",
       "149         3034          141  3.78    3.15                9.5         114   \n",
       "150         2935          141  3.78    3.15                9.5         114   \n",
       "151         3042          141  3.78    3.15                9.5         114   \n",
       "152         3045          130  3.62    3.15                7.5         162   \n",
       "153         3157          130  3.62    3.15                7.5         162   \n",
       "154         2952          141  3.78    3.15                9.5         114   \n",
       "155         3049          141  3.78    3.15                8.7         160   \n",
       "156         3012          173  3.58    2.87                8.8         134   \n",
       "157         3217          145  3.01    3.40               23.0         106   \n",
       "158         3062          141  3.78    3.15                9.5         114   \n",
       "\n",
       "     peak-rpm  city-mpg  highway-mpg  price  \n",
       "120      4800        28           34   8358  \n",
       "121      4800        28           34   9258  \n",
       "122      4800        29           34   8058  \n",
       "123      4800        29           34   8238  \n",
       "124      6600        26           29   9298  \n",
       "125      6600        26           29   9538  \n",
       "126      4800        24           30   8449  \n",
       "127      4800        24           30   9639  \n",
       "128      4800        24           30   9989  \n",
       "129      4800        24           30  11199  \n",
       "130      4800        24           30  11549  \n",
       "131      4800        24           30  17669  \n",
       "132      4200        29           34   8948  \n",
       "133      4500        30           33  10698  \n",
       "134      4200        27           32   9988  \n",
       "135      4200        27           32  10898  \n",
       "136      4200        27           32  11248  \n",
       "137      5200        20           24  16558  \n",
       "138      5200        19           24  15998  \n",
       "139      5200        20           24  15690  \n",
       "140      4800        37           46   7775  \n",
       "141      5250        27           34   7975  \n",
       "142      4800        37           46   7995  \n",
       "143      5250        27           34   8195  \n",
       "144      5250        27           34   8495  \n",
       "145      4500        37           42   9495  \n",
       "146      5500        26           32   9995  \n",
       "147      5500        24           29   9980  \n",
       "148      5400        23           28  12940  \n",
       "149      5400        23           28  13415  \n",
       "150      5400        24           28  15985  \n",
       "151      5400        24           28  16515  \n",
       "152      5100        17           22  18420  \n",
       "153      5100        17           22  18950  \n",
       "154      5400        23           28  16845  \n",
       "155      5300        19           25  19045  \n",
       "156      5500        18           23  21485  \n",
       "157      4800        26           27  22470  \n",
       "158      5400        19           25  22625  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df120158 = pd.read_clipboard()\n",
    "df120158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f185a3fe-7428-431e-859e-650665e8d761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2337</td>\n",
       "      <td>109</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2824</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.7</td>\n",
       "      <td>2844</td>\n",
       "      <td>136</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.5</td>\n",
       "      <td>110</td>\n",
       "      <td>5500</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>17710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>105.8</td>\n",
       "      <td>192.7</td>\n",
       "      <td>71.4</td>\n",
       "      <td>55.9</td>\n",
       "      <td>3086</td>\n",
       "      <td>131</td>\n",
       "      <td>3.13</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.3</td>\n",
       "      <td>140</td>\n",
       "      <td>5500</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>23875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>192</td>\n",
       "      <td>101.2</td>\n",
       "      <td>176.8</td>\n",
       "      <td>64.8</td>\n",
       "      <td>54.3</td>\n",
       "      <td>2395</td>\n",
       "      <td>108</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2.80</td>\n",
       "      <td>8.8</td>\n",
       "      <td>101</td>\n",
       "      <td>5800</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>16430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>2952</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>23</td>\n",
       "      <td>28</td>\n",
       "      <td>16845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.8</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3049</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>8.7</td>\n",
       "      <td>160</td>\n",
       "      <td>5300</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>19045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3012</td>\n",
       "      <td>173</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2.87</td>\n",
       "      <td>8.8</td>\n",
       "      <td>134</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>21485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3217</td>\n",
       "      <td>145</td>\n",
       "      <td>3.01</td>\n",
       "      <td>3.40</td>\n",
       "      <td>23.0</td>\n",
       "      <td>106</td>\n",
       "      <td>4800</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>22470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1</td>\n",
       "      <td>95</td>\n",
       "      <td>109.1</td>\n",
       "      <td>188.8</td>\n",
       "      <td>68.9</td>\n",
       "      <td>55.5</td>\n",
       "      <td>3062</td>\n",
       "      <td>141</td>\n",
       "      <td>3.78</td>\n",
       "      <td>3.15</td>\n",
       "      <td>9.5</td>\n",
       "      <td>114</td>\n",
       "      <td>5400</td>\n",
       "      <td>19</td>\n",
       "      <td>25</td>\n",
       "      <td>22625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     symboling  normalized-losses  wheel-base  length  width  height  \\\n",
       "0            2                164        99.8   176.6   66.2    54.3   \n",
       "1            2                164        99.4   176.6   66.4    54.3   \n",
       "2            1                158       105.8   192.7   71.4    55.7   \n",
       "3            1                158       105.8   192.7   71.4    55.9   \n",
       "4            2                192       101.2   176.8   64.8    54.3   \n",
       "..         ...                ...         ...     ...    ...     ...   \n",
       "154         -1                 95       109.1   188.8   68.9    55.5   \n",
       "155         -1                 95       109.1   188.8   68.8    55.5   \n",
       "156         -1                 95       109.1   188.8   68.9    55.5   \n",
       "157         -1                 95       109.1   188.8   68.9    55.5   \n",
       "158         -1                 95       109.1   188.8   68.9    55.5   \n",
       "\n",
       "     curb-weight  engine-size  bore  stroke  compression-ratio  horsepower  \\\n",
       "0           2337          109  3.19    3.40               10.0         102   \n",
       "1           2824          136  3.19    3.40                8.0         115   \n",
       "2           2844          136  3.19    3.40                8.5         110   \n",
       "3           3086          131  3.13    3.40                8.3         140   \n",
       "4           2395          108  3.50    2.80                8.8         101   \n",
       "..           ...          ...   ...     ...                ...         ...   \n",
       "154         2952          141  3.78    3.15                9.5         114   \n",
       "155         3049          141  3.78    3.15                8.7         160   \n",
       "156         3012          173  3.58    2.87                8.8         134   \n",
       "157         3217          145  3.01    3.40               23.0         106   \n",
       "158         3062          141  3.78    3.15                9.5         114   \n",
       "\n",
       "     peak-rpm  city-mpg  highway-mpg  price  \n",
       "0        5500        24           30  13950  \n",
       "1        5500        18           22  17450  \n",
       "2        5500        19           25  17710  \n",
       "3        5500        17           20  23875  \n",
       "4        5800        23           29  16430  \n",
       "..        ...       ...          ...    ...  \n",
       "154      5400        23           28  16845  \n",
       "155      5300        19           25  19045  \n",
       "156      5500        18           23  21485  \n",
       "157      4800        26           27  22470  \n",
       "158      5400        19           25  22625  \n",
       "\n",
       "[159 rows x 16 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_auto = pd.concat([df60, df60120, df120158])\n",
    "df_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb8bb264-5868-40d9-a796-dbd53cf2232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auto.to_csv('automobiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6dbdc202-069c-4473-b433-4dd056d33afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>159.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.735849</td>\n",
       "      <td>121.132075</td>\n",
       "      <td>98.264151</td>\n",
       "      <td>172.413836</td>\n",
       "      <td>65.607547</td>\n",
       "      <td>53.899371</td>\n",
       "      <td>2461.138365</td>\n",
       "      <td>119.226415</td>\n",
       "      <td>3.300126</td>\n",
       "      <td>3.236352</td>\n",
       "      <td>10.161132</td>\n",
       "      <td>95.836478</td>\n",
       "      <td>5113.836478</td>\n",
       "      <td>26.522013</td>\n",
       "      <td>32.081761</td>\n",
       "      <td>11445.729560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.193086</td>\n",
       "      <td>35.651285</td>\n",
       "      <td>5.167416</td>\n",
       "      <td>11.523177</td>\n",
       "      <td>1.947883</td>\n",
       "      <td>2.268761</td>\n",
       "      <td>481.941321</td>\n",
       "      <td>30.460791</td>\n",
       "      <td>0.267336</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>3.889475</td>\n",
       "      <td>30.718583</td>\n",
       "      <td>465.754864</td>\n",
       "      <td>6.097142</td>\n",
       "      <td>6.459189</td>\n",
       "      <td>5877.856195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>49.400000</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>2.540000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>4150.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>165.650000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>52.250000</td>\n",
       "      <td>2065.500000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>3.105000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>4800.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7372.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>96.900000</td>\n",
       "      <td>172.400000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>2340.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>3.270000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>9233.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>100.800000</td>\n",
       "      <td>177.800000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2809.500000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>3.560000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>14719.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>202.600000</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>6600.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>35056.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        symboling  normalized-losses  wheel-base      length       width  \\\n",
       "count  159.000000         159.000000  159.000000  159.000000  159.000000   \n",
       "mean     0.735849         121.132075   98.264151  172.413836   65.607547   \n",
       "std      1.193086          35.651285    5.167416   11.523177    1.947883   \n",
       "min     -2.000000          65.000000   86.600000  141.100000   60.300000   \n",
       "25%      0.000000          94.000000   94.500000  165.650000   64.000000   \n",
       "50%      1.000000         113.000000   96.900000  172.400000   65.400000   \n",
       "75%      2.000000         148.000000  100.800000  177.800000   66.500000   \n",
       "max      3.000000         256.000000  115.600000  202.600000   71.700000   \n",
       "\n",
       "           height  curb-weight  engine-size        bore      stroke  \\\n",
       "count  159.000000   159.000000   159.000000  159.000000  159.000000   \n",
       "mean    53.899371  2461.138365   119.226415    3.300126    3.236352   \n",
       "std      2.268761   481.941321    30.460791    0.267336    0.294888   \n",
       "min     49.400000  1488.000000    61.000000    2.540000    2.070000   \n",
       "25%     52.250000  2065.500000    97.000000    3.050000    3.105000   \n",
       "50%     54.100000  2340.000000   110.000000    3.270000    3.270000   \n",
       "75%     55.500000  2809.500000   135.000000    3.560000    3.410000   \n",
       "max     59.800000  4066.000000   258.000000    3.940000    4.170000   \n",
       "\n",
       "       compression-ratio  horsepower     peak-rpm    city-mpg  highway-mpg  \\\n",
       "count         159.000000  159.000000   159.000000  159.000000   159.000000   \n",
       "mean           10.161132   95.836478  5113.836478   26.522013    32.081761   \n",
       "std             3.889475   30.718583   465.754864    6.097142     6.459189   \n",
       "min             7.000000   48.000000  4150.000000   15.000000    18.000000   \n",
       "25%             8.700000   69.000000  4800.000000   23.000000    28.000000   \n",
       "50%             9.000000   88.000000  5200.000000   26.000000    32.000000   \n",
       "75%             9.400000  114.000000  5500.000000   31.000000    37.000000   \n",
       "max            23.000000  200.000000  6600.000000   49.000000    54.000000   \n",
       "\n",
       "              price  \n",
       "count    159.000000  \n",
       "mean   11445.729560  \n",
       "std     5877.856195  \n",
       "min     5118.000000  \n",
       "25%     7372.000000  \n",
       "50%     9233.000000  \n",
       "75%    14719.500000  \n",
       "max    35056.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12dbe1ab-31ca-4c85-a1b5-3951f949e0ca",
   "metadata": {},
   "source": [
    "# Extra Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2e258-9a26-4ed0-89fc-4d8647752702",
   "metadata": {},
   "outputs": [],
   "source": [
    "listem = ['y', 'n'] # İstenen veri listesi\n",
    "count = 0 # Sayacı sıfırla\n",
    "for col in df.iloc[:, 1:].columns: # Sütunları döngüye sok\n",
    "    for val in df[col].values: # Her bir hücreyi döngüye sok\n",
    "        if val not in listem: # Eğer hücrenin değeri listede yoksa\n",
    "            count += 1 # Sayacı arttır\n",
    "count\n",
    "\n",
    "\n",
    "count = sum([sum([1 for val in col if val not in ['y', 'n']]) for col in df.values])\n",
    "count\n",
    "\n",
    "\n",
    "check = all(all(val in ['y', 'n'] for val in col) for col in df.values)\n",
    "check\n",
    "\n",
    "\n",
    "df.apply(lambda x : x.isin(['y', 'n']) == False) # bitmedi daha???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e092831e-eb54-4277-9652-d8dfe2e97169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scpraing_portfolio_deneme",
   "language": "python",
   "name": "web_scpraing_portfolio_deneme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

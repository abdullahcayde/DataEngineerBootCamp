{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47d1a1d9-c745-411a-a0ce-2ddad14b8b4f",
   "metadata": {},
   "source": [
    "# Introduction to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f6e66-9086-413d-bb39-9ac94b3d171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Introduction\n",
    "\n",
    "    The pandas module has been developed to provide Python with the tools necessary to manipulate and analyze large volumes of data.\n",
    "\n",
    "    Pandas introduces the DataFrame class, an array-like data structure that offers more advanced data manipulation and exploration than NumPy arrays.\n",
    "\n",
    "    The main features of pandas are:\n",
    "\n",
    "            data recovery from files (CSV, Excel tables, etc.)\n",
    "\n",
    "            handling this data (deletion / addition, modification, statistical visualization, etc.).\n",
    "\n",
    "    This notebook aims at:\n",
    "\n",
    "            Understanding the format of a DataFrame.\n",
    "\n",
    "            Creating a first Dataframe.\n",
    "\n",
    "            Carrying out a first exploration of a dataset using the DataFrame class.\n",
    "\n",
    "    (a) Import the pandas module under the name pd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aceceba-444c-448d-a5f8-dc7ff2f680a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447ac49d-b23c-4f2e-8985-e018021076ed",
   "metadata": {},
   "source": [
    "## Format of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be53471-b41b-46b6-a130-fe158f45df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Format of a DataFrame\n",
    "\n",
    "    A DataFrame is in the form of a matrix whose rows and columns each have an index. Typically, columns are indexed by name and rows by unique identifiers.\n",
    "\n",
    "    A DataFrame is used to store a database. The different entries in the database (individuals, animals, objects, etc.) are the different lines and their features are the different columns:\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    0 \tRobert \tM \t174 \t23\n",
    "    1 \tMark \tM \t182 \t40\n",
    "    2 \tAline \tF \t169 \t56\n",
    "\n",
    "            The DataFrame above groups together information on 3 individuals: the DataFrame therefore has 3 lines.\n",
    "\n",
    "            For each of these individuals, there are 4 variables (name, gender, height and age) : therefore, the DataFrame has 4 columns.\n",
    "\n",
    "    The column containing the numbering of the lines is called the index and is not managed in the same way as other columns of the DataFrame.\n",
    "\n",
    "    The index can be set by default (will follow the row numbering), defined with one (or several) of the columns of the DataFrame or even defined with a list that we specify.\n",
    "\n",
    "    Example: Default indexing (line numbering), you don't have to specify anything :\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    0 \tRobert \tM \t174 \t23\n",
    "    1 \tMark \tM \t182 \t40\n",
    "    2 \tAline \tF \t169 \t56\n",
    "\n",
    "    Example: Indexing by the column 'Name':\n",
    "    \tGender \tHeight \tAge\n",
    "    Robert \tM \t174 \t23\n",
    "    Mark \tM \t182 \t40\n",
    "    Aline \tF \t169 \t56\n",
    "\n",
    "    Example: Indexing by the list ['person_1', 'person_2', 'person_3']:\n",
    "    \tName \tGender \tHeight \tAge\n",
    "    person_1 \tRobert \tM \t174 \t23\n",
    "    person_2 \tMark \tM \t182 \t40\n",
    "    person_3 \tAline \tF \t169 \t56\n",
    "\n",
    "    We will detail later how to define the index when creating a DataFrame.\n",
    "\n",
    "    The DataFrame class has several advantages over aNumpy array:\n",
    "\n",
    "            Visually, a DataFrame is much more readable thanks to more explicit column and row indexing.\n",
    "\n",
    "            Within the same column the elements are of the same type but from one column to another, the type of the elements may vary, which is not the case of Numpy arrays which only support data of the same type.\n",
    "\n",
    "            The DataFrame class contains more methods for handling and preprocessing databases, while NumPy specializes instead in optimized computation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14cd18-7069-478b-8dd2-453997e22272",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f19e82-c37a-4d24-8c0e-22fbe833545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Creation of a DataFrame: from a NumPy array\n",
    "\n",
    "    It is possible to directly create a DataFrame from a NumPy array using the DataFrame() constructor. The disadvantage of this method is that it is not very practical and the data type is necessarily the same for all the columns.\n",
    "\n",
    "    Let's take a closer look at the header of this constructor.\n",
    "\n",
    "    pd.DataFrame(data, index, columns, ...)\n",
    "\n",
    "            The data parameter contains the data to be formatted (NumPy array, list, dictionary or another DataFrame).\n",
    "\n",
    "            The index parameter, if specified, must be a list containing the indices of the entries.\n",
    "\n",
    "            The columns parameter, if specified, must be a list containing the name of the columns.\n",
    "\n",
    "    For other parameters, you can consult the Python documentation.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # Creation of a NumPy array with 3 rows and 4 columns\n",
    "    array = np.array ([[1, 2, 3, 4],\n",
    "                       [5, 6, 7, 8],\n",
    "                       [9, 10, 11, 12]])\n",
    "\n",
    "    # Instantiation of a DataFrame\n",
    "    df = pd.DataFrame (data = array, # The data to format\n",
    "                       index = ['i_1', 'i_2', 'i_3'], # The indices of each entry\n",
    "                       columns = ['A', 'B', 'C', 'D']) # The name of the columns\n",
    "\n",
    "    This produces the following DataFrame:\n",
    "    \tA \tB \tC \tD\n",
    "    i_1 \t1 \t2 \t3 \t4\n",
    "    i_2 \t5 \t6 \t7 \t8\n",
    "    i_3 \t9 \t10 \t11 \t12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b584ee0d-65a2-4538-97ae-ef12f54a1e14",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cd9a97-cf59-421b-9c24-aed6c1a6ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. Creation of a DataFrame: from a dictionary\n",
    "\n",
    "    Another way to create a DataFrame is to use a dictionary. Thanks to this technique, the columns can be of different type and their names are already given when creating the DataFrame.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # Creation of a dictionary\n",
    "    dictionary = {'A': [1, 5, 9],\n",
    "                  'B': [2, 6, 10],\n",
    "                  'C': [3, 7, 11],\n",
    "                  'D': [4, 8, 12]}\n",
    "\n",
    "    # Instantiation of a DataFrame\n",
    "    df = pd.DataFrame (data = dictionary,\n",
    "                       index = ['i_1', 'i_2', 'i_3'])\n",
    "\n",
    "    This produces the same DataFrame as before:\n",
    "    \tA \tB \tC \tD\n",
    "    i_1 \t1 \t2 \t3 \t4\n",
    "    i_2 \t5 \t6 \t7 \t8\n",
    "    i_3 \t9 \t10 \t11 \t12\n",
    "\n",
    "The manager of a grocery store has the following stock of food products:\n",
    "\n",
    "    100 jars of honey with an expiration date of 08/10/2025 and worth €2 each.\n",
    "\n",
    "    55 packets of flour expiring on 09/25/2024 each costing € 3.\n",
    "\n",
    "    1800 bottles of wine costing € 10 per unit and expiring on 10/15/2023.\n",
    "\n",
    "    (a) From a dictionary, create and display a DataFrame df that contains for each product:\n",
    "\n",
    "            Its name.\n",
    "            Its expiration date.\n",
    "            Its quantity.\n",
    "            Its price per unit.\n",
    "\n",
    "You will choose relevant column names and the index will be the default one (in this case we do not specify the index parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b09c8dfa-50e4-4078-ae09-eb8aa5c5da58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Expiration date</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price per unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>honey</td>\n",
       "      <td>10/08/2025</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flour</td>\n",
       "      <td>25/09/2024</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wine</td>\n",
       "      <td>15/10/2023</td>\n",
       "      <td>1800</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Expiration date  Quantity  Price per unit\n",
       "0   honey      10/08/2025       100               2\n",
       "1   flour      25/09/2024        55               3\n",
       "2    wine      15/10/2023      1800              10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your Code\n",
    "\n",
    "dictionary = {\"Product\"          : ['honey', 'flour', 'wine'],\n",
    "              \"Expiration date\"  : ['10/08/2025', '25/09/2024', '15/10/2023'],\n",
    "              \"Quantity\"         : [100, 55, 1800], \n",
    "              \"Price per unit\"   : [2, 3, 10]}\n",
    "\n",
    "df = pd.DataFrame(dictionary)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74731371-de11-4edb-ab26-d923820f088e",
   "metadata": {},
   "source": [
    "## Creation of a DataFrame: from a data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e0d47-d614-48ad-bda0-207ca0f70beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. Creation of a DataFrame: from a data file\n",
    "\n",
    "    Most often a DataFrame is created directly from a file containing the data of interest. The file's format can be a CSV, Excel, txt, etc.\n",
    "\n",
    "    The most common format is the CSV format, which stands for Comma-Separated Values and denotes a spreadsheet-like file whose values are separated by commas.\n",
    "\n",
    "    Here is an example:\n",
    "\n",
    "    A, B, C, D,\n",
    "    1, 2, 3, 4,\n",
    "    5, 6, 7, 8,\n",
    "    9, 10, 11, 12\n",
    "\n",
    "    In this format:\n",
    "\n",
    "            The first line contains the name of the columns, but sometimes the name of the columns is not filled in.\n",
    "\n",
    "            Each line corresponds to an entry in the database.\n",
    "\n",
    "            The values are separated by a separator character. In this example, it is ',' but it could be a ';'.\n",
    "\n",
    "    To import the data into a DataFrame, we need to use the read_csv function of pandas whose header is as follows:\n",
    "\n",
    "    pd.read_csv(filepath_or_buffer, sep = ',', header = 0, index_col = 0 ...)\n",
    "\n",
    "    The essential arguments of the pd.read_csv function to know are:\n",
    "\n",
    "            filepath_or_buffer: The path of the .csv file relative to the execution environment.\n",
    "                If the file is in the same folder as the Python environment, just fill in the name of the file.\n",
    "                This path must be entered in the form of character string.\n",
    "\n",
    "            sep: The character used in the .csv file to to separate the different columns.\n",
    "                This argument must be specified as character.\n",
    "\n",
    "            header: The number of the row that contains the names of the columns.\n",
    "                If for example the column names are entered in the first line of the .csv file, then we must specify header = 0.\n",
    "                If the names are not included, we will put header = None.\n",
    "\n",
    "            index_col: The name or number of the column containing the indices of the database.\n",
    "                If the database entries are indexed by the first column, you will need to fill in index_col = 0.\n",
    "                Alternatively, if the entries are indexed by a column which bears the name \"Id\", we can specify index_col = \"Id\".\n",
    "\n",
    "    This function will return an object of type DataFrame which contains all the data of the file.\n",
    "\n",
    "    (a) Load the data contained in the file transactions.csv into aDataFrame named transactions:\n",
    "\n",
    "            The file is located in the same folder as the environment of this notebook.\n",
    "            Columns are separated by commas.\n",
    "            The names of the columns are in the first line of the file.\n",
    "            The rows of the database are indexed by the \"transaction_id\" column which is also the first column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b3425-52d0-4993-b3c4-90c7b9d3dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# You can directly specify the name of the column containing the indices\n",
    "\n",
    "transactions = pd.read_csv(filepath_or_buffer = 'transactions.csv', # file path\n",
    "                           sep = ',',                               # character separating values\n",
    "                           header = 0,                              # number of the row containing column names\n",
    "                           index_col = 'transaction_id')            # name of the column that indexes the entries\n",
    "\n",
    "\n",
    "# You can also directly enter the number of the column that indexes the entries\n",
    "\n",
    "transactions = pd.read_csv(filepath_or_buffer = 'transactions.csv',\n",
    "                           sep = ',',\n",
    "                           header = 0,\n",
    "                           index_col = 0) # number of the column that indexes the entries\n",
    "\n",
    "# We loaded the transactions.csv file in theDataFrame transactions which gathers a history of transactions carried out between 2011 and 2014. \n",
    "#In the next section, we will study this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506e9cf-2b48-465b-8748-1a720974c5ec",
   "metadata": {},
   "source": [
    "## First exploration of a dataset using the DataFrame class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cde126-fb58-4743-b1f6-718a3591a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. First exploration of a dataset using the DataFrame class\n",
    "\n",
    "    The rest of this notebook briefly presents the main methods of the DataFrame class which will allow us to do a quick analysis of our data set, that is:\n",
    "\n",
    "            Having a brief overview of the data (head method,columns and shape attributes).\n",
    "\n",
    "            Selecting values in the DataFrame (loc and iloc methods).\n",
    "\n",
    "            Carrying out a quick statistical study of our data (describe and value _counts methods)\n",
    "\n",
    "    As a reminder, to apply a method to an object in Python (such as a DataFrame for example), you must add the method as a suffix of the object. Example: my_object.my_method()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5764ad-c505-4224-ab2a-79cf30635a73",
   "metadata": {},
   "source": [
    "## Visualization of a DataFrame: head method, columns and shape attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5384dad2-969a-4c11-b6a5-b8dc406c7402",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Visualization of a DataFrame: head method, columns and shape attributes\n",
    "\n",
    "        It is possible to have a preview of a dataset by displaying only the first lines of the DataFrame.\n",
    "\n",
    "    For that, we must use the head() method, specifying as an argument the number of lines that we want to display (by default 5).\n",
    "\n",
    "    It is also possible to preview the last lines using the tail() method which is applied in the same way:\n",
    "\n",
    "    # Display of the first 10 lines of my_dataframe\n",
    "    my_dataframe.head(10)\n",
    "\n",
    "    (a) Display the first 20 lines of the transactions DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2f4645-75e9-4027-9a08-e79ac61c3599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3216b3c4-aecb-439b-93fa-f4dd4b52f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Display the last 10 lines of the transactions DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4349a8-0ef4-4632-8491-ff8b9818fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e01940-a6d8-496d-aab7-6f4b5ba55112",
   "metadata": {},
   "outputs": [],
   "source": [
    "     \tA \tB \tC \tD\n",
    "    i_ 1 \t1 \t2 \t3 \t4\n",
    "    i _2 \t5 \t6 \t7 \t8\n",
    "    i_ 3 \t9 \t10 \t11 \t12\n",
    "\n",
    "    # Display of df DataFrame columns\n",
    "    print(df.columns)\n",
    "    >>> ['A', 'B', 'C', 'D']\n",
    "\n",
    "    The list of the column names can be used to iterate over the columns of a DataFrame within a loop.\n",
    "\n",
    "    It can be interesting to know how many transactions (rows) and how many features (columns) the dataset contains.\n",
    "\n",
    "    For this we will use the shape attribute of the DataFrame class which displays the dimensions of our DataFrame in the form of a tuple (number of rows, number of columns):\n",
    "\n",
    "    # Display the dimensions of df\n",
    "    print (df.shape)\n",
    "    >>> (3,4)\n",
    "\n",
    "    (c) Display the dimensions of the DataFrame transactions as well as the name of the 5th column. Remember that in Python the indices start from 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977eca5f-fb8e-4fa1-adcd-4547fe48c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "print(transactions.shape)\n",
    "\n",
    "transactions.columns[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad1b8e-26ef-475c-a814-c4c9b7d71519",
   "metadata": {},
   "source": [
    "## Selecting columns from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d405d9b-56ac-49d5-a196-a7a9dec5176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. Selecting columns from a DataFrame\n",
    "\n",
    "    Extracting columns from a DataFrame is almost identical to extracting data from a dictionary.\n",
    "\n",
    "    To extract a column from a DataFrame, all we have to do is enter between brackets the name of the column to extract. To extract several columns, we must enter between brackets the list of the names of the columns to extract:\n",
    "\n",
    "    # Display of the 'cust_id' column\n",
    "    print(transactions['cust_id'])\n",
    "\n",
    "    # Extraction of 'cust_id' and 'Qty' columns from transactions\n",
    "    cust_id_qty = transactions[[\"cust_id\", \"Qty\"]]\n",
    "\n",
    "    cust_id_qty is a new DataFrame containing only the 'cust_id' and 'Qty' columns.\n",
    "\n",
    "    The display of the first 3 lines of cust_id_qty yields:\n",
    "\n",
    "\n",
    "\n",
    "    transactions_id \tcust_id \tQty\n",
    "    80712190438 \t270351 \t-5\n",
    "    29258453508 \t270384 \t-5\n",
    "    51750724947 \t273420 \t-2\n",
    "\n",
    "    When we prepare a dataset for later use, it is better to separate the categorical variables from the quantitative variables:\n",
    "\n",
    "            A categorical variable is a variable that takes only a finite number of modalities.\n",
    "\n",
    "            The categorical variables of the DataFrame transactions are: ['cust_id', 'tran_date', 'prod_subcat_code', 'prod_cat_code', 'Store_type'].\n",
    "\n",
    "            A quantitative variable is a variable that measures a quantity that can take an infinite number of values.\n",
    "\n",
    "            The quantitative variables of transactions are: ['Qty', 'Rate', 'Tax', 'total_amt'].\n",
    "\n",
    "    This distinction is made because some basic operations like calculating an average only make sense for quantitative variables.\n",
    "\n",
    "    (a) In a DataFrame named cat_vars, store the categorical variables of transactions.\n",
    "\n",
    "    (b) In a DataFrame named num_vars, store the quantitative variables of transactions.\n",
    "\n",
    "    (c) Display the first 5 lines of each DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a03c3-86c3-4613-9859-f6ca982d0775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# Extraction of categorical variables\n",
    "cat_var_names = ['cust_id', 'tran_date', 'prod_subcat_code', 'prod_cat_code' , 'Store_type']\n",
    "cat_vars = transactions[cat_var_names]\n",
    "\n",
    "# Extraction of quantitative variables\n",
    "num_var_names = ['Qty', 'Rate', 'Tax', 'total_amt']\n",
    "num_vars = transactions[num_var_names]\n",
    "\n",
    "# Display of the first 5 lines of each DataFrame\n",
    "print (\"Categorical variables: \\n\")\n",
    "print (cat_vars.head(), \"\\n \\n\")\n",
    "\n",
    "print (\"Quantitative variables: \\n\")\n",
    "print (num_vars.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c5095-e2fc-4d01-9b39-0a5ecf0b6da8",
   "metadata": {},
   "source": [
    "## Selecting rows of a DataFrame: loc and iloc methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cd06a-65a0-4d45-bd0a-ef13608965c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. Selecting rows of a DataFrame: loc and iloc methods\n",
    "\n",
    "    To extract one or more rows from a DataFrame, we use the loc method. loc is a very special type of method because the arguments are filled in between square brackets and not between parentheses. Using this method is very similar to indexing lists.\n",
    "\n",
    "    In order to retrieve the line of index i of a DataFrame, all we have to do is enter i as an argument of the loc method:\n",
    "\n",
    "    # We retrieve the line of index 80712190438 of the num_vars DataFrame\n",
    "    print(num_vars.loc[80712190438])\n",
    "\n",
    "    >>                 Rate    Tax  total_amt\n",
    "    >> transaction_id                         \n",
    "    >> 80712190438    -772.0  405.3    -4265.3\n",
    "    >> 80712190438     772.0  405.3     4265.3\n",
    "\n",
    "    In order to retrieve several rows, we can either:\n",
    "\n",
    "            Enter a list of indices.\n",
    "\n",
    "            Enter a slice by specifying the start and end indices of the slice. To use slicing with loc, the indices must be unique, which is not the case for transactions.\n",
    "\n",
    "    # We retrieve the rows at indices 80712190438, 29258453508 and 51750724947 from the transactions DataFrame\n",
    "    transactions.loc[[80712190438, 29258453508, 51750724947]]\n",
    "\n",
    "    loc can also take a column or list of columns as an argument in order to refine the data extraction:\n",
    "\n",
    "    # We extract the columns 'Tax' and 'total_amt' from the rows at index 80712190438 and 29258453508\n",
    "    transactions.loc[[80712190438, 29258453508], ['Tax', 'total_amt']]\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    transaction_id \tTax \ttotal_amt\n",
    "    80712190438 \t405.300 \t-4265.300\n",
    "    80712190438 \t405.300 \t4265.300\n",
    "    29258453508 \t785.925 \t-8270.925\n",
    "    29258453508 \t785.925 \t8270.925\n",
    "\n",
    "    The iloc method is used to index a DataFrame exactly like a numpy array, that is to say by only filling in the numeric indices of the rows and columns. This allows the use of slicing without constraint:\n",
    "\n",
    "    # Extraction of the first 4 rows and the first 3 columns of transactions\n",
    "    transactions.iloc[0:4, 0:3]\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    transaction_id \tcust_id \ttran_date \tprod_subcat_code\n",
    "    80712190438 \t270351 \t28-02-2014 \t1.0\n",
    "    29258453508 \t270384 \t27-02-2014 \t5.0\n",
    "    51750724947 \t273420 \t24-02-2014 \t6.0\n",
    "    93274880719 \t271509 \t24-02-2014 \t11.0\n",
    "\n",
    "    If the row indexing is the one by default (row numbering), the loc and iloc methods are equivalent.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc83c629-6615-4a5a-93a8-4722f262494b",
   "metadata": {},
   "source": [
    "## Conditional indexing of a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2eb568-f61d-4637-b60a-eb0ccefcaf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Conditional indexing of a DataFrame\n",
    "\n",
    "    As with Numpy arrays, we can use conditional indexing to extract rows from a Dataframe that meet a given condition.\n",
    "\n",
    "    In the following illustration, we select the rows of the DataFrame df for which the column col 2 is equal to 3.\n",
    "\n",
    "\n",
    "    There are two syntaxes for conditionally indexing a DataFrame:\n",
    "\n",
    "\n",
    "    # We select the rows of the DataFrame df for which the column 'col 2' is equal to 3.\n",
    "    df[df['col 2'] == 3]\n",
    "\n",
    "    df.loc[df['col 2'] == 3]\n",
    "\n",
    "    If we want to assign a new value to these entries, we must absolutely use the loc method.\n",
    "\n",
    "    Indeed, indexing with the syntax df[df['col 2'] == 3] only returns a copy of these entries and does not provide access the memory location where the data is located.\n",
    "\n",
    "The manager of the transactions listed in the transactions DataFrame wishes to have access to the identifiers of customers who have made an online purchase (i.e. in a \"e-Shop\") as well as the date of the corresponding transaction.\n",
    "\n",
    "We have the following information about the columns of transactions:\n",
    "Column name \tDescription\n",
    "'cust_id' \tThe identifier of the customer\n",
    "'Store_type' \tThe type of store where the transaction took place\n",
    "'tran_date' \tThe date of the transaction\n",
    "\n",
    "    (a) In a DataFrame named transactions_eshop, store the transactions that took place in an \"e-Shop\" type store.\n",
    "\n",
    "    (b) In another DataFrame named transactions_id_date, store the customer identifiers and the transaction date of the transactions_eshop DataFrame.\n",
    "\n",
    "    (c) Display the first 5 rows of transactions_id_date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc8cd2-67f9-4d93-a76b-da33e30be988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code\n",
    "\n",
    "# Creation of transactions_eshop by conditional indexing\n",
    "transactions_eshop = transactions.loc[transactions['Store_type'] == 'e-Shop']\n",
    "\n",
    "# Extraction of the 'cust_ id' and 'tran _date' columns\n",
    "transactions_id_date = transactions_eshop[['cust_id', 'tran_date']]\n",
    "\n",
    "# Display of the first 5 lines of transactions_id_date\n",
    "transactions_id_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32d2a7-a0e1-4cb7-a73d-077d25755f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, the manager would like to have access to the transactions carried out by the client whose identifier is 268819.\n",
    "\n",
    "    (d) In a DataFrame named transactions_client_268819, store all transactions with client identifier 268819.\n",
    "\n",
    "    (e) A column in a DataFrame can be iterated over with a loop exactly like a list (for value in df['column']:). Using a for loop on the 'total_amt' column, compute and display the total transaction amount for the client with identifier 268819.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ad531-d02a-4189-8b02-fd0d651e778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# Extraction of the transactions ofthe customer which identifier is 268819\n",
    "transactions_client_268819 = transactions[transactions['cust_id'] == 268819]\n",
    "\n",
    "\n",
    "# Computation of the total amount of transactions\n",
    "total = 0\n",
    "\n",
    "# For each amount in the column 'total_amt'\n",
    "for amount in transactions_client_268819['total_amt']:\n",
    "    # We sum the amounts\n",
    "    total += amount\n",
    "    \n",
    "print(total)\n",
    "\n",
    "# Second Way\n",
    "transactions.loc[transactions.cust_id == 268819]['total_amt'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debd9401-1f16-4894-8563-81bd24739fad",
   "metadata": {},
   "source": [
    "## Quick statistical study of the data in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bf4ace-48c7-4656-9e63-9b55fd35b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. Quick statistical study of the data in a DataFrame.\n",
    "\n",
    "    The describe method of a DataFrame returns a summary of the descriptive statistics (min, max, mean, quantiles,...) of its quantitative variables. It is therefore a very useful tool for a first visualisation of the type and distribution of these variables.\n",
    "\n",
    "    To analyse the categorical variables, it is recommended to start by using the value_counts method which returns the number of occurrences for each modality of these variables. The value_counts method cannot be used directly on a DataFrame but only on the columns of the DataFrame which are objects of the pd.Series class.\n",
    "\n",
    "    (a) Use the describe method of the DataFrame transactions.\n",
    "\n",
    "    (b) The quantitative variables of transactions are 'Qty', 'Rate', 'Tax' and total_amt'. By default, are the statistics produced by the describe method only computed on the quantitative variables?\n",
    "\n",
    "    (c) Display the number of occurrences of each modality of the Store_type column using the value_counts method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987b0a5-7c14-4c56-a396-35867eb76e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "transactions.describe()\n",
    "\n",
    "transactions['Store_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbb9de-6372-4b7d-acc4-87782b2cbaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The describe method computed statistics on the variables cust_id, prod_subcat_code and prod_cat_code while these are categorical variables.\n",
    "\n",
    "    Of course, these statistics make no sense. The describe method has treated these variables as quantitative because the modalities they take are of numerical type.\n",
    "\n",
    "    This is why it is necessary to pay attention to the results returned by the describe method and always take a step back to remember what the variables are reflecting.\n",
    "\n",
    "    The manager wishes to make a quick report on the characteristics of the transactions DataFrame: in particular, he wants to know the average amount spent as well as the maximum quantity purchased.\n",
    "\n",
    "    (d) What is the average total amount spent? We are interested in the 'total_amt' column of transactions.\n",
    "\n",
    "    (e) What is the maximum quantity purchased? We will look at the 'Qty' column of transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a4f91-cec0-4937-8791-1c07fddf2f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "print('average total amount spent :', transactions['total_amt'].mean())\n",
    "print('maximum quantity purchased :', transactions['Qty'].max())\n",
    "\n",
    "transactions.describe()\n",
    "\n",
    "# Applying the describe method to the transactions DataFrame\n",
    "transactions.describe()\n",
    "\n",
    "# The average total amount spent is €2109.\n",
    "# The maximum quantity purchased is 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0e072-0760-44cd-90ce-017657bcedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some transactions have negative amounts.\n",
    "\n",
    "These are transactions that have been cancelled and refunded to the client. These amounts will disrupt the distribution of the amounts which gives us bad estimates of the mean and quantiles of the variable total_amt.\n",
    "\n",
    "    (f) What is the average amount of transactions with positive amounts?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad9db6-7c1f-4aa4-ac8f-5b8c3548edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n",
    "\n",
    "transactions[transactions['total_amt'] > 0].describe()\n",
    "\n",
    "# the average amount of transactions with positive amounts is worth €2608 which is\n",
    "# €500 more than we had before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8634bb-9c81-4454-ae13-2a734d96c7a1",
   "metadata": {},
   "source": [
    "## Conclusion and recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40401943-1bc8-4a85-83e5-c02229c7c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. Conclusion and recap\n",
    "\n",
    "    The DataFrame class of the pandas module will be your favorite data structure when exploring, analysing and processing datasets and databases.\n",
    "\n",
    "    In this brief introduction, you have learned to:\n",
    "\n",
    "            Create a DataFrame from a numpy array and a dictionary using the pd.DataFrame constructor.\n",
    "\n",
    "            Create a DataFrame from a .csv file using the pd.read_csv function.\n",
    "\n",
    "            Display the first and last lines of a DataFrame using the head and tail methods.\n",
    "\n",
    "            Select one or more columns of a DataFrame by entering their names in square brackets as in a dictionary.\n",
    "\n",
    "            Select one or more lines of a DataFrame by filling in their index using the loc and iloc methods.\n",
    "\n",
    "            Select the lines of a DataFrame that meet a specific condition using conditional indexing.\n",
    "\n",
    "            Perform a quick statistical study of the quantitative variables of a DataFrame using the describe method.\n",
    "\n",
    "    The dataset transactions we used is very clean. The variables are cleanly filled in and do not contain any missing value. In practice, this is rarely the case. This is why in the following notebook we will see how to clean datasets with pandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c78f4c90-b1a8-4cbf-a04e-6c09c7097bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type  \n",
       "transaction_id                                          \n",
       "80712190438     -772.0  405.300  -4265.300           1  \n",
       "29258453508    -1497.0  785.925  -8270.925           1  \n",
       "51750724947     -791.0  166.110  -1748.110           2  \n",
       "93274880719    -1363.0  429.345  -4518.345           1  \n",
       "51750724947     -791.0  166.110  -1748.110           2  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df= pd.read_csv('transactions.csv', index_col='transaction_id')\n",
    "df['\\ttran_date'] = df['\\ttran_date'].apply(lambda x : x.replace('\\t', ''))\n",
    "df.rename(columns= lambda x : x.replace('\\t', ''), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a92401ef-2fbc-4adf-98c8-6e6cdd079ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type day month  year  \n",
       "transaction_id                                                          \n",
       "80712190438     -772.0  405.300  -4265.300           1  28    02  2014  \n",
       "29258453508    -1497.0  785.925  -8270.925           1  27    02  2014  \n",
       "51750724947     -791.0  166.110  -1748.110           2  24    02  2014  \n",
       "93274880719    -1363.0  429.345  -4518.345           1  24    02  2014  \n",
       "51750724947     -791.0  166.110  -1748.110           2  23    02  2014  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day'] = df['tran_date'].apply(lambda x : x.split('-')[0])\n",
    "df['month'] = df['tran_date'].apply(lambda x : x.split('-')[1])\n",
    "df['year'] = df['tran_date'].apply(lambda x : x.split('-')[2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47ab560d-2c28-42ab-8599-86c0ea32d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>853.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1654.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1506.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type day month  year  \\\n",
       "transaction_id                                                           \n",
       "80712190438     -772.0  405.300  -4265.300           1  28    02  2014   \n",
       "29258453508    -1497.0  785.925  -8270.925           1  27    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  24    02  2014   \n",
       "93274880719    -1363.0  429.345  -4518.345           1  24    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  23    02  2014   \n",
       "\n",
       "                unit_price  \n",
       "transaction_id              \n",
       "80712190438        853.060  \n",
       "29258453508       1654.185  \n",
       "51750724947        874.055  \n",
       "93274880719       1506.115  \n",
       "51750724947        874.055  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['unit_price'] = df.apply(lambda row : row['total_amt']/row['qty'], axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057664cf-b354-4f7f-859d-ffb0543752ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28-02-2014'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date1 = df.tran_date.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709dba7-ec0e-4281-9bcd-c9d27aedb903",
   "metadata": {},
   "source": [
    "# Data Cleaning and Missing Values Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5c0be4-62fb-4329-a489-1e4a14921af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('transactions.csv', sep=',', index_col='transaction_id')\n",
    "df1 = df.copy()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc83837-4446-43fd-baeb-fc7b93725415",
   "metadata": {},
   "source": [
    "## Cleaning up a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4cbb63-8e53-47b4-8e10-35027458967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Cleaning up a dataset\n",
    "\n",
    "    In this part we will introduce the methods of the DataFrame class that are essential to clean a dataset. These methods can be grouped into three different categories :\n",
    "\n",
    "            Duplicates management (duplicated and drop_duplicates methods)\n",
    "\n",
    "            Modification of the elements of a DataFrame (replace, rename and astype methods)\n",
    "\n",
    "            Operations on the values of a DataFrame (apply method and lambda functions)\n",
    "\n",
    "Managing duplicates (duplicated and drop_duplicates methods)\n",
    "\n",
    "    Duplicates are identical entries that appear more than once in a dataset.\n",
    "\n",
    "    When we first discover a dataset it is very important to check up front that there are no duplicates. The presence of duplicates will generate errors in the computation of statistics or the plotting of graphs.\n",
    "\n",
    "    Let df be the following DataFrame:\n",
    "    \tAge \tGender \tHeight\n",
    "    Robert \t56 \tM \t174\n",
    "    Mark \t23 \tM \t182\n",
    "    Alina \t32 \tF \t169\n",
    "    Mark \t23 \tM \t182\n",
    "\n",
    "    The presence of duplicates is checked using the duplicated method of a DataFrame:\n",
    "\n",
    "    # We identify the rows containing duplicates\n",
    "    df.duplicated()\n",
    "\n",
    "    >>> 0 False\n",
    "    >>> 1 False\n",
    "    >>> 2 False\n",
    "    >>> 3 True\n",
    "\n",
    "    This method returns Series object from pandas, which is equivalent to the column of a DataFrame. The Series object tells us for each row wether it is a duplicate.\n",
    "\n",
    "    In this example, the result of the duplicated method informs us that the row with index 3 is a duplicate. Indeed, it is the exact copy of the row with index 1.\n",
    "\n",
    "    Since the duplicated method returns an object of the Series class, we can apply the sum method to it in order to count the number of duplicates:\n",
    "\n",
    "    # To calculate the sum of boolean values, we consider that True is worth 1 and False is worth 0.\n",
    "    print(df.duplicated().sum())\n",
    "    >>> 1\n",
    "\n",
    "    The method of the DataFrame class used to remove duplicates is drop_duplicates. Its header is as follows:\n",
    "\n",
    "    drop_duplicates(subset, keep, inplace)\n",
    "\n",
    "            The subset parameter indicates the column(s) to consider in order to identify and remove duplicates. By default, subset = None namely we consider all the columns of the DataFrame.\n",
    "\n",
    "            The keep parameter indicates which entry should be kept :\n",
    "\n",
    "                    'first' : We keep the first occurrence.\n",
    "                    'last': We keep the last occurrence.\n",
    "                    False: We do not keep any occurrence.\n",
    "                    By default, keep = 'first'.\n",
    "\n",
    "            The inplace parameter (very common in the methods of the DataFrame class), specifies whether you modify directly the DataFrame (in this case inplace = True) or if the method returns a copy of the DataFrame (inplace = False). A method applied with the argument inplace = True is irreversible. By default, inplace = False.\n",
    "\n",
    "    You have to be very careful when using the inplace parameter. A good practice is to forget this parameter and assign the DataFrame returned by the method to a new DataFrame.\n",
    "\n",
    "    The keep parameter is the one that is most often specified. Indeed, a database can have duplicates created on different dates. We will then specify the value of the keep argument to keep only the most recent entries, for example.\n",
    "\n",
    "    Let us go back to the df DataFrame :\n",
    "    \tAge \tGender \tHeight\n",
    "    Robert \t56 \tM \t174\n",
    "    Mark \t23 \tM \t182\n",
    "    Alina \t32 \tF \t169\n",
    "    Mark \t23 \tM \t182\n",
    "\n",
    "    We illustrate df with the following illustration :\n",
    "\n",
    "    We illustrate in the following examples the entries that are deleted by the drop_duplicates method depending on the value of the keep parameter:\n",
    "\n",
    "    # We keep only the first occurrence of the duplicate\n",
    "    df_first = df.drop_duplicates(keep = 'first')\n",
    "\n",
    "\n",
    "\n",
    "    # We keep only the last occurrence of the duplicate\n",
    "    df_last = df.drop_duplicates(keep = 'last')\n",
    "\n",
    "    # We keep no duplicates\n",
    "    df_false = df.drop_duplicates(keep = False)\n",
    "\n",
    "    (a) How many duplicates are there in the transactions DataFrame ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942080a5-cc6e-4af1-aae8-96a315a9503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the number of duplicates\n",
    "duplicates = transactions.duplicated().sum()\n",
    "\n",
    "print (\"There are\", duplicates, \"duplicates in transactions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e20d86-4c8e-4b9b-b241-2b3efbb1296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The transactions were recorded in anti-chronological order, i.e. the first rows contain the most recent transactions and the last rows the oldest transactions.\n",
    "\n",
    "    (b) Eliminate duplicates from the database by keeping only the first occurrence, i.e. the most recent transaction.\n",
    "\n",
    "    (c) Using the subset and keep parameters of the drop_duplicates method of transactions, display the most recent transaction for each category of prod_cat_code. To do this, you can remove all the duplicates from the prod_cat_code column by keeping only the first occurrence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de930143-8d73-4a2c-9e47-e31f8bcf43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "\n",
    "transactions.drop_duplicates(subset = ['prod_cat_code'], keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0790037-2171-44bf-bcba-a0539f1ea62d",
   "metadata": {},
   "source": [
    "### Modification of the elements of a DataFrame (replace, rename and astype methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fc8dcf-a7cc-4c8e-b5be-65c5f40445c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Modification of the elements of a DataFrame (replace, rename and astype methods)\n",
    "\n",
    "    The replace method allows to replace one or more values ​​of a column of aDataFrame.\n",
    "\n",
    "    Its header is as follows:\n",
    "\n",
    "    replace(to_replace, value, ...)\n",
    "\n",
    "            The to_replace parameter contains the value or the list of values to be replaced. It can be a list of integers, strings, booleans, etc.\n",
    "\n",
    "            The value parameter contains the value or the list of the substitute values. It can also be a list of integers, strings, booleans, etc.\n",
    "\n",
    "\n",
    "\n",
    "    In addition to modifying the elements of a DataFrame, it is possible to rename its columns.\n",
    "\n",
    "    This is possible thanks to the rename method which takes as argument a dictionary whose keys are the old names and the values are the new names. You must also fill in the argument axis = 1 to specify that the names to rename are those of the columns.\n",
    "\n",
    "    # Creation of the dictionary associating the old names with the new column names\n",
    "    dictionary = {'old_name1': 'new_name1',\n",
    "                  'old_name2': 'new_name2'}\n",
    "\n",
    "    # We rename the variables using the rename method\n",
    "    df = df.rename(dictionary, axis = 1)\n",
    "\n",
    "    It is sometimes necessary to modify not only the name of a column but also its type.\n",
    "\n",
    "    For example, it is possible that when importing a database, a variable is of type string when in fact it is a numerical variable. Whenever one of the entries in the column is incorrectly recognized, pandas will consider that this column is of type string.\n",
    "\n",
    "    This is possible thanks to the astype method.\n",
    "\n",
    "    The types that we will see most often are:\n",
    "\n",
    "            str: Character string ('Hello').\n",
    "            float: Floating point number (1.0, 1.14123).\n",
    "            Int: Integer (1,1231)\n",
    "\n",
    "    As for the rename method, astype can take as argument a dictionary whose keys are the names of the columns whose type should be modified and the values are the new types to assign. This is useful if you want to change the type of several columns at once.\n",
    "\n",
    "    Most often, we will directly select the column whose type should be modified and overwrite it by applying the astype method to it.\n",
    "\n",
    "    # Method 1: Creation of a dictionary then call to the astype method of the DataFrame\n",
    "    dictionary = {'col_1': 'int',\n",
    "                  'col_2': 'float'}\n",
    "    df = df.astype(dictionary)\n",
    "\n",
    "    # Method 2: Selection of the column and then calling the astype method of a Series\n",
    "    df['col_1'] = df['col_1'].astype('int')\n",
    "\n",
    "    These methods also have the inplace parameter to perform the operation directly on the DataFrame. To be used with great caution.\n",
    "\n",
    "    If you make a mistake in the next exercise, you can re-import and redo the preprocessing by running the following cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273e3d9-6476-4bbc-8240-140157e49a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843fdc2b-2f2e-4b8c-b3a7-4c995f984654",
   "metadata": {},
   "outputs": [],
   "source": [
    "    d) Import the numpy module under the namenp.\n",
    "\n",
    "    (e) Replace the modalities ['e-Shop', 'TeleShop', 'MBR', 'Flagship store', np.nan] of the Store_type column by the modalities [1, 2, 3, 4, 0].\n",
    "\n",
    "        The np.nan value is the one that encodes a missing value. We will replace this value with 0.\n",
    "\n",
    "    (f) Convert the type of the columns Store_type and prod_subcat_code to type 'int'.\n",
    "\n",
    "    (g) Rename the 'Store_type','Qty', 'Rate' and 'Tax' columns with 'store_type','qty', 'rate' and 'tax'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10305ad-5604-4a03-8ddf-84e5e973c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "## Exercise\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Replacement of values\n",
    "transactions = transactions.replace(to_replace = ['e-Shop', 'TeleShop', 'MBR', 'Flagship store', np.nan],\n",
    "                                    value = [1, 2, 3, 4, 0])\n",
    "\n",
    "# Conversion of column types\n",
    "new_types = {'Store_type'       : 'int',\n",
    "             'prod_subcat_code' : 'int'}\n",
    "\n",
    "transactions = transactions.astype(new_types)\n",
    "\n",
    "# Renaming the columns\n",
    "new_names = {'Store_type'   : 'store_type',\n",
    "              'Qty'         : 'qty',\n",
    "              'Rate'        : 'rate',\n",
    "              'Tax'         : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "# Display of the first rows of transactions\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb24d22-8c72-4e64-9600-c74f167b1c40",
   "metadata": {},
   "source": [
    "### Operations on the values of a DataFrame (apply method and lambda functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e7a8d6-c2be-4111-ba57-ac49e61d8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Operations on the values ​​of a DataFrame (apply method and lambda functions)\n",
    "\n",
    "    It is often interesting to modify or aggregate the information of the columns of a DataFrame using an operation or a function.\n",
    "\n",
    "    These operations can be any type of function which takes a column as argument. Thus, the numpy module is perfectly suited to perform operations on this type of object.\n",
    "\n",
    "    The method used to perform an operation on a column is the apply method of a DataFrame whose header is:\n",
    "\n",
    "    apply(func, axis, ...)\n",
    "\n",
    "    where:\n",
    "\n",
    "            func is the function to apply to the column.\n",
    "            axis is the dimension on which the operation must be applied.\n",
    "\n",
    "    Example: apply and np.sum\n",
    "\n",
    "    For each column with numerical values, we want to calculate the sum of all rows. The sum function of numpy does this, so we can use it with the apply method.\n",
    "\n",
    "    Since we are going to perform an operation on the rows, we must therefore specify the argument axis = 0 in the apply method.\n",
    "\n",
    "    # Sum of the ROWS for each column of df\n",
    "    df_lines = df.apply(np.sum, axis = 0)\n",
    "\n",
    "    The result is the following:\n",
    "\n",
    "\n",
    "    Now, for each row we want to compute the sum of all the columns.\n",
    "\n",
    "    We are going to perform this operation on the columns, we must therefore specify the argument axis = 1 in the apply method.\n",
    "\n",
    "    # Sum of columns for each ROW of df\n",
    "    df_columns = df.apply(np.sum, axis = 1)\n",
    "\n",
    "    The result is the following:\n",
    "\n",
    "    These examples only illustrate the use of the apply method. To actually compute the sum of rows or columns, it is better to use the sum method of a DataFrame or a Series, which behaves in exactly the same way as the sum method of a numpy array.\n",
    "\n",
    "The tran_date column of transactions contains the dates of the transactions in the format ('day-month-year') (ex: '28-02-2014'). The dates are of type string: it is not possible to perform statistics on this variable for the moment.\n",
    "\n",
    "We would rather have 3 different columns for the day, month and year of each transaction. This would allow us, for example, to analyze and detect trends in transaction dates.\n",
    "\n",
    "The date '28-02-2014' is a string. The day, month and year are separated by a hyphen '-'. The character string class has the split method to split a string on a specific character:\n",
    "\n",
    "date = '28-02-2014 '\n",
    "\n",
    "# Splitting the string on the '-' character\n",
    "print(date.split('-'))\n",
    ">>> ['28', '02', '2014']\n",
    "\n",
    "This method returns a list containing the slices of the string on the specified character. Thus, to retrieve the day, all you have to do is select the first element of the split. To recover the month, we must take the second element and for the year the third.\n",
    "\n",
    "    (h) Define a function get_day taking as argument a string and which returns the first element of its split by the character '-'.\n",
    "\n",
    "    (i) Define the functions get_month and get_year which do the same with the second and third element of the split.\n",
    "\n",
    "    (j) In 3 variables called days, months and years, store the result of the apply method on the tran_date column with the get_day, get_month and get_year functions. As these functions work element-wise, it is not necessary to specify the argument axis in the apply method.\n",
    "\n",
    "    (k) Create the columns 'day', 'month' and 'year' in the transactions DataFrame and store the values of the days, months and years. Creating a new column is simply done by declaring it:\n",
    "\n",
    "        # Create a new column 'day' with the values contained in days.\n",
    "        transactions['day'] = days\n",
    "\n",
    "    (l) Display the first 5 rows of transactions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791eb2a5-c82b-49c9-9b57-10030b4d6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the functions to apply to the 'tran_date' column\n",
    "def get_day(date):\n",
    "    \"\"\"\n",
    "    Takes a date as a string argument.\n",
    "    \n",
    "    The date must have the format 'DD-MM-YYYY'.\n",
    "    \n",
    "    This function returns the day (DD).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Splitting the string on the '-' character\n",
    "    splits = date.split('-')\n",
    "    \n",
    "    # We return the first element of the breakdown (day)\n",
    "    day = splits[0]\n",
    "    return day\n",
    "\n",
    "def get_month(date):\n",
    "    return date.split('-')[1]\n",
    "\n",
    "def get_year(date):\n",
    "    return date.split('-')[2]\n",
    "    \n",
    "    \n",
    "# Retrieving the day, month and year of each transaction\n",
    "days = transactions['tran_date'].apply(get_day)\n",
    "months = transactions['tran_date'].apply(get_month)\n",
    "years = transactions['tran_date'].apply(get_year)\n",
    "\n",
    "# Creation of new columns\n",
    "transactions['day'] = days\n",
    "transactions['month'] = months\n",
    "transactions['year'] = years\n",
    "\n",
    "# Displaying first rows of transactions\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e9aab-68b0-4a53-88eb-40cd6845f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The apply method is very powerful when combined with a lambda function.\n",
    "\n",
    "    In Python, the keyword lambda is used to define an anonymous function: a function declared without name.\n",
    "\n",
    "    A function lambda can take any number of arguments, but can only have one expression.\n",
    "\n",
    "    Here is its syntax:\n",
    "\n",
    "    lambda arguments: expression\n",
    "\n",
    "    Lambda functions allow you to define functions with a very short syntax :\n",
    "\n",
    "    # Example 1 \n",
    "    x = lambda a: a + 2\n",
    "    print(x(3))\n",
    "    >>> 5\n",
    "\n",
    "    # Example 2 \n",
    "    x = lambda a, b : a * b\n",
    "    print(x(2, 3))\n",
    "    >>> 6\n",
    "\n",
    "    # Example 3 \n",
    "    x = lambda a, b, c : a - b + c\n",
    "    print(x(1, 2, 3))\n",
    "    >>> 2\n",
    "\n",
    "    Although syntactically different, lambda functions behave in the same way as regular functions that are declared using the def keyword.\n",
    "\n",
    "    The classic definition of a function is done with the def keyword:\n",
    "\n",
    "    def increment(x):\n",
    "        return x + 1\n",
    "\n",
    "    It is also possible to define a function with the keyword lambda:\n",
    "\n",
    "    increment = lambda x: x + 1\n",
    "\n",
    "    The first method is very clean but the advantage of the second is that it can be defined on-the-fly directly within the apply method.\n",
    "\n",
    "    Thus, the previous exercise can be done with a very compact syntax:\n",
    "\n",
    "    transactions['day'] = transactions['tran_date'].apply(lambda date: date.split('-')[0])\n",
    "\n",
    "    This kind of syntax is very practical and very often used for cleaning databases.\n",
    "\n",
    "    The prod_subcat_code column of transactions depends on the prod_cat_code column because it identifies a subcategory of product. It would make more sense to have the category and subcategory of a product in the same variable.\n",
    "\n",
    "    To do this, we will merge the values of these two columns:\n",
    "\n",
    "            We will first convert the values of these two columns into strings using the astype method.\n",
    "\n",
    "            Then, we will concatenate these strings to have a unique code representing both the category and sub-category. This can be done in the following way:\n",
    "\n",
    "        string1 = \"I think\"\n",
    "        string2 = \"therefore I am.\"\n",
    "\n",
    "        # Concatenation of the two strings by separating them with a space\n",
    "        print (string1 + \" \" + string2)\n",
    "        >>> I think therefore I am.\n",
    "\n",
    "To apply a lambda function to an entire row, you must specify the argument axis = 1 in the apply method. In the function itself, the columns of the row can be accessed as on a DataFrame:\n",
    "\n",
    "# Computation of the unit price of a product\n",
    "transactions.apply(lambda row: row['total_ amt']/row['qty'], axis = 1)\n",
    "\n",
    "    (m) Using a lambda function applied to transactions, create a column 'prod_cat' in transactions containing the concatenation of the values ofprod_cat_code and prod_subcat_code separated by a hyphen '-'. Remember to convert the values to strings.\n",
    "\n",
    "    Displaying this column should yield:\n",
    "\n",
    "    transaction_id\n",
    "    80712190438     1-1\n",
    "    29258453508     3-5\n",
    "    51750724947     5-6\n",
    "    93274880719     6-11\n",
    "    51750724947     5-6\n",
    "                   ...\n",
    "    94340757522     5-12\n",
    "    89780862956     1-4\n",
    "    85115299378     6-2\n",
    "    72870271171     5-11\n",
    "    77960931771     5-11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01812d1a-af3b-4245-904e-c5c00d160eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "transactions['prod_cat'] = transactions.apply(lambda row : str(row['prod_cat_code']) + '-' + str(row['prod_subcat_code']),\n",
    "                                    axis=1)\n",
    "transactions.head()\n",
    "\n",
    "# original cozum\n",
    "transactions['prod_cat'] = transactions.astype('str').apply(lambda row: row['prod_cat_code']+'-'+row['prod_subcat_code'],\n",
    "                                                            axis = 1)\n",
    "\n",
    "print(transactions['prod_cat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab02afb-fd94-4071-8d72-bdc4d00f5ea2",
   "metadata": {},
   "source": [
    "## Dealing with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e407e-2766-44c0-9f7a-8b906f29ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Dealing with missing values\n",
    "\n",
    "    A missing value is either:\n",
    "\n",
    "            An unspecified value.\n",
    "            A value that does not exist. In general, they result from mathematical calculations having no solution (a division by zero for example).\n",
    "\n",
    "    A missing value appears under the name NaN (\"Not a Number\") in a DataFrame.\n",
    "\n",
    "    In this part, we will see several methods to:\n",
    "\n",
    "            Detect missing values (isna and any methods)\n",
    "            Replace these values (fillna method)\n",
    "            Delete missing values (dropna method)\n",
    "\n",
    "    In one of the previous exercises, we used the replace method of transactions to replace missing values with 0. This approach is not rigorous and should not be done in practice.\n",
    "\n",
    "    For this reason, we are going to re-import the raw version of transactions to undo the steps we did in the previous exercises.\n",
    "\n",
    "    (a) Run the cell below to re-import transactions, remove duplicates and rename its columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41321379-0ac6-4665-9b12-e7624ad64ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Duplicates removal\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Renaming the columns\n",
    "new_names = {'Store_type'  : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7808142-4d1c-4dab-a0c5-49e643106afc",
   "metadata": {},
   "source": [
    "### Detecting missing values (isna and any methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b76593-f9d2-4d84-a2ca-6859c91af382",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detecting missing values (isna and any methods)\n",
    "\n",
    "    The isna method of a DataFrame detects its missing values. This method does not take any arguments.\n",
    "\n",
    "    This method returns the same DataFrame whose values are:\n",
    "\n",
    "            True if the original table cell is a missing value (np.nan)\n",
    "            False otherwise.\n",
    "\n",
    "\n",
    "\n",
    "    Since the isna method returns a DataFrame, we can use it with other methods of the DataFrame class to get more precise information:\n",
    "\n",
    "            The any method - thanks to its axis argument - allows to determine which columns (axis = 0) or which rows (axis = 1) contain at least one missing value.\n",
    "\n",
    "            The sum method counts the number of missing values per column or row (by specifying the axis argument). It is possible to use other statistical methods like mean,max, argmax, etc.\n",
    "\n",
    "    Here are many examples of using the any and sum methods with isna:\n",
    "\n",
    "    We use the DataFrame df from the previous illustrations:\n",
    "    \tName \tCountry \tAge\n",
    "    0 \tNaN \tAustralia \tNaN\n",
    "    1 \tDuchamp \tFrance \t25\n",
    "    2 \tHana \tJapan \t54\n",
    "\n",
    "    The df.isna() instruction returns:\n",
    "    \tName \tCountry \tAge\n",
    "    0 \tTrue \tFalse \tTrue\n",
    "    1 \tFalse \tFalse \tFalse\n",
    "    2 \tFalse \tFalse \tFalse\n",
    "\n",
    "    # COLUMNS containing at least one missing value are detected\n",
    "    df.isna().any(axis = 0)\n",
    "\n",
    "    >>> Name     True\n",
    "    >>> Country  False\n",
    "    >>> Age      True\n",
    "\n",
    "    # ROWS containing at least one missing value are detected\n",
    "    df.isna().any (axis = 1)\n",
    "\n",
    "    >>> 0    True\n",
    "    >>> 1    False\n",
    "    >>> 2    False\n",
    "\n",
    "    # Using conditional indexing to display entries\n",
    "    # containing missing values\n",
    "    df[df.isna().any(axis = 1)]\n",
    "\n",
    "    which returns the DataFrame:\n",
    "    \tName \tCountry \tAge\n",
    "    0 \tNaN \tAustralia \tNaN\n",
    "\n",
    "    # We count the number of missing values for each COLUMN\n",
    "    df.isnull().sum(axis = 0)\n",
    "\n",
    "    >>> Name     1\n",
    "    >>> Country  0\n",
    "    >>> Age      1\n",
    "\n",
    "    # Count the number of missing values for each ROW\n",
    "    df.isnull().sum(axis = 1)\n",
    "\n",
    "    >>> 0   2\n",
    "    >>> 1   0\n",
    "    >>> 2   0\n",
    "\n",
    "    The methods isnaand isnullhave exactly the same behavior.\n",
    "\n",
    "    (b) How many columns of the transactions DataFrame contain missing values?\n",
    "\n",
    "    (c) How many of transactions' entries contain missing values? You can use the any method along with the sum method.\n",
    "\n",
    "    (d) Which column of transactions contains the most of missing values? You can use the idxmax method that returns the index of first occurrence of maximum over the requested axis.\n",
    "\n",
    "    (e) Show transaction entries that contain at least one missing value in the 'rate', 'tax' and 'total_amt' columns. What do you notice?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d50d58-ef20-4c82-8558-ca4d7cb01fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which columns contain NaNs\n",
    "columns_na = transactions.isna().any(axis = 0)\n",
    "\n",
    "print(columns_na.sum(), \"columns of transactions contain NaNs. \\n\")\n",
    "\n",
    "# Which rows contain NaNs\n",
    "rows_na = transactions.isna().any(axis = 1)\n",
    "\n",
    "print(rows_na.sum(), \"rows of transactions contain NaNs. \\n\")\n",
    "\n",
    "# Number of NaNs per column\n",
    "columns_nbna = transactions.isna().sum(axis = 0)\n",
    "\n",
    "print (\"The column containing the most NaNs is:\",  columns_nbna.idxmax())\n",
    "\n",
    "# Display the first 10 entries containing at least one NaN in 'rate', 'tax' or 'total_amt'\n",
    "transactions[transactions[['rate', 'tax', 'total_amt']].isna().any(axis = 1)].head(10)\n",
    "\n",
    "# The three variables are still missing together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a7226c-4677-4db5-bde5-e6055be992f8",
   "metadata": {},
   "source": [
    "### Replacing missing values (fillna method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b4960-bec8-4d79-9fea-b28260bfadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Replacing missing values (fillna method)\n",
    "\n",
    "    The fillna method allows you to replace the missing values of a DataFrame by values you want.\n",
    "\n",
    "    # We replace all the NaNs of the DataFrame by zeros\n",
    "    df.fillna(0)\n",
    "\n",
    "    # We replace the NaNs of each numerical column by the average on this column\n",
    "    df.fillna(df.mean()) # df.mean() can be replaced by any statistical method.\n",
    "\n",
    "    It is common to replace missing values of a column containing numerical values with statistics like:\n",
    "\n",
    "            The mean: .mean\n",
    "            The median: .median\n",
    "            The minimum / maximum: .min / .max.\n",
    "\n",
    "    For categorical type columns, replace the missing values with:\n",
    "\n",
    "            The mode, i.e. the most frequent modality: .mode.\n",
    "            A constant or arbitrary category: 0,-1.\n",
    "\n",
    "    To avoid making replacement errors, it is very important to select the correct columns before using the fillna method.\n",
    "\n",
    "If you make mistakes in the following exercise, you can re-import transactions using the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8f110-9129-4fed-bed9-df5862a67311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep = ',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Renaming the columns\n",
    "new_names = {'Store_type' : 'store_type',\n",
    "              'Qty'       : 'qty',\n",
    "              'Rate'      : 'rate',\n",
    "              'Tax'       : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b5c17-1ef7-42dc-ae0f-2fdc7a4505ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    (f) Replace the missing values in prod_subcat_code column of transactions with -1.\n",
    "\n",
    "    (g) Determine the most frequent modality (the mode) of the store_type column of transactions.\n",
    "\n",
    "    (h) Replace the missing values of the store_type column by this modality. The value of this modality is accessed at index 0 of the Series returned by mode.\n",
    "\n",
    "    (i) Check that the prod_subcat_code and store_type columns of transactions no longer contain missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e257ae6-fd57-4f05-af0a-18d2cffaf8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the NaNs of 'prod_subcat_code' by -1\n",
    "transactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1)\n",
    "\n",
    "# Determining the mode of 'store_type'\n",
    "store_type_mode = transactions['store_type'].mode()\n",
    "print (\"The most frequent mode of 'store_type' is:\", store_type_mode[0])\n",
    "\n",
    "# Replacing the NaNs of 'store_type' by its mode\n",
    "transactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n",
    "\n",
    "# Checking that these two columns no longer contain NANs\n",
    "transactions[['prod_subcat_code', 'store_type']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da779626-4bd8-4e67-a447-f5922738024f",
   "metadata": {},
   "source": [
    "### Removing missing values (dropna method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486ba4e8-1d41-4e79-8e54-6a638055dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Removing missing values (dropna method)\n",
    "\n",
    "    The dropna method allows you to remove rows or columns containing missing values.\n",
    "\n",
    "    The header of the method is as follows:\n",
    "\n",
    "    dropna(axis, how, subset, ..)\n",
    "\n",
    "            The axis parameter specifies whether to delete rows or columns (0 for rows, 1 for columns).\n",
    "\n",
    "            The how parameter lets you specify how the rows (or columns) are deleted:\n",
    "\n",
    "                    how = 'any': We delete the row (or column) if it contains at least one missing value.\n",
    "                    how = 'all': We delete the row (or column) if it contains only missing values.\n",
    "\n",
    "            The subset parameter is used to specify the columns/rows on which the search for missing values is carried out.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # We delete all the rows containing at least one missing value\n",
    "    df = df.dropna(axis = 0, how = 'any')\n",
    "\n",
    "    # We delete the empty columns\n",
    "    df = df.dropna(axis = 1, how = 'all')\n",
    "\n",
    "    # We remove the rows with missing values in the 3 columns 'col2', 'col3' and 'col4'\n",
    "    df.dropna(axis = 0, how = 'all', subset = ['col2', 'col3', 'col4'])\n",
    "\n",
    "    As with the other methods of replacing values of a DataFrame, the inplace argument can be used with great care to perform the modification directly without reassignment.\n",
    "\n",
    "Transaction data for which the transaction amount is not provided is of no interest to us. For this reason:\n",
    "\n",
    "    (j) Delete the transaction entries for which the rate, tax and total_amt columns are all empty.\n",
    "\n",
    "    (k) Check that the columns of transactions no longer contain missing values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6a353-a505-4606-a6de-eaffbbda1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.dropna(axis = 0, how = 'all', subset = ['rate', 'tax', 'total_amt'])\n",
    "\n",
    "transactions.isna().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230e19d-11a0-43ef-af5a-9ce852b66836",
   "metadata": {},
   "source": [
    "## Conclusion and recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6b436-5a42-4c76-a9ef-e1a727e4d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion and recap\n",
    "\n",
    "    In this chapter we have seen the essential methods of the pandas module in order to clean up a dataset and manage missing values ​​(NaN).\n",
    "\n",
    "    This step of preparing a dataset is always the first step of a data project.\n",
    "\n",
    "    Regarding data cleaning, we have learned how to:\n",
    "\n",
    "            Identify and delete duplicates of a DataFrame using the duplicated and drop_duplicates methods.\n",
    "\n",
    "            Modify the elements of a DataFrame and their type using the replace, rename and astype methods.\n",
    "\n",
    "            Apply a function to a DataFrame with the apply method and the lambda clause.\n",
    "\n",
    "    Regarding the management of missing values, we have learned to:\n",
    "\n",
    "            Detect them using the isna method followed by the any and sum methods.\n",
    "\n",
    "            Replace them using the fillna method and the statistical methods.\n",
    "\n",
    "            Delete them using the dropna method.\n",
    "\n",
    "    In the following notebook, you will see other manipulations of DataFrames for a more advanced exploration of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea0eda-5654-4c32-b6b7-768f413e2ad6",
   "metadata": {},
   "source": [
    "## Apply, Lamda, Func Ornekleri (EXTRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "902b49e9-3419-413f-b789-30135dabc168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transaction_id\n",
       "80712190438    28\n",
       "29258453508    27\n",
       "51750724947    24\n",
       "93274880719    24\n",
       "51750724947    23\n",
       "Name: day2, dtype: object"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('Data\\transactions.csv')\n",
    "\n",
    "def get_day(string):\n",
    "    day = string.split('-')[0]\n",
    "    return day\n",
    "\n",
    "def get_day_column(df, column):\n",
    "    lst1 = [i.split('-')[0] for i in column]\n",
    "    df['day2'] = np.array(lst1)\n",
    "    return df['day2']\n",
    "        \n",
    "date1 = df.tran_date.iloc[0]\n",
    "date1\n",
    "\n",
    "print(get_day(date1))\n",
    "# 1. Yol\n",
    "df['day'] = df.tran_date.apply(get_day)\n",
    "\n",
    "# 2. Yol\n",
    "get_day_column(df, df.tran_date.values)\n",
    "\n",
    "# 3. Yol \n",
    "df['day'] = df['tran_date'].apply(lambda x : x.split('-')[0])\n",
    "\n",
    "# 4.yol\n",
    "df[['day', 'month', 'year']] = df['tran_date'].str.split(expand=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38910a81-9694-4d1c-ab2a-619b64f95be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['28-02-2014', '27-02-2014', '24-02-2014', '24-02-2014',\n",
       "       '23-02-2014'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tran_date.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f517951b-ae5c-45e3-80de-5414f40c7b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>tran_date</th>\n",
       "      <th>prod_subcat_code</th>\n",
       "      <th>prod_cat_code</th>\n",
       "      <th>qty</th>\n",
       "      <th>rate</th>\n",
       "      <th>tax</th>\n",
       "      <th>total_amt</th>\n",
       "      <th>store_type</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>day2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80712190438</th>\n",
       "      <td>270351</td>\n",
       "      <td>28-02-2014</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-5</td>\n",
       "      <td>-772.0</td>\n",
       "      <td>405.300</td>\n",
       "      <td>-4265.300</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>853.060</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29258453508</th>\n",
       "      <td>270384</td>\n",
       "      <td>27-02-2014</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-5</td>\n",
       "      <td>-1497.0</td>\n",
       "      <td>785.925</td>\n",
       "      <td>-8270.925</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1654.185</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93274880719</th>\n",
       "      <td>271509</td>\n",
       "      <td>24-02-2014</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>-3</td>\n",
       "      <td>-1363.0</td>\n",
       "      <td>429.345</td>\n",
       "      <td>-4518.345</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>1506.115</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51750724947</th>\n",
       "      <td>273420</td>\n",
       "      <td>23-02-2014</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>-2</td>\n",
       "      <td>-791.0</td>\n",
       "      <td>166.110</td>\n",
       "      <td>-1748.110</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>02</td>\n",
       "      <td>2014</td>\n",
       "      <td>874.055</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                cust_id   tran_date  prod_subcat_code  prod_cat_code  qty  \\\n",
       "transaction_id                                                              \n",
       "80712190438      270351  28-02-2014                 1              1   -5   \n",
       "29258453508      270384  27-02-2014                 5              3   -5   \n",
       "51750724947      273420  24-02-2014                 6              5   -2   \n",
       "93274880719      271509  24-02-2014                11              6   -3   \n",
       "51750724947      273420  23-02-2014                 6              5   -2   \n",
       "\n",
       "                  rate      tax  total_amt  store_type day month  year  \\\n",
       "transaction_id                                                           \n",
       "80712190438     -772.0  405.300  -4265.300           1  28    02  2014   \n",
       "29258453508    -1497.0  785.925  -8270.925           1  27    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  24    02  2014   \n",
       "93274880719    -1363.0  429.345  -4518.345           1  24    02  2014   \n",
       "51750724947     -791.0  166.110  -1748.110           2  23    02  2014   \n",
       "\n",
       "                unit_price day2  \n",
       "transaction_id                   \n",
       "80712190438        853.060   28  \n",
       "29258453508       1654.185   27  \n",
       "51750724947        874.055   24  \n",
       "93274880719       1506.115   24  \n",
       "51750724947        874.055   23  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da4a9cfe-6810-4eae-ae69-dd133db072bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lila</td>\n",
       "      <td>Twingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiago</td>\n",
       "      <td>Clio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Berenice</td>\n",
       "      <td>C4 Cactus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joseph</td>\n",
       "      <td>Twingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kader</td>\n",
       "      <td>Swift</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Romy</td>\n",
       "      <td>Scenic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name         Car\n",
       "0      Lila      Twingo\n",
       "1     Tiago        Clio\n",
       "2  Berenice   C4 Cactus\n",
       "3    Joseph      Twingo\n",
       "4     Kader       Swift\n",
       "5      Romy      Scenic"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#df_names = pd.read_clipboard()\n",
    "df_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1e1ba19-8077-4e5c-bd18-2c74eb9aff83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Twingo</td>\n",
       "      <td>11000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swift</td>\n",
       "      <td>14500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C4 Cactus</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clio</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prius</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Car  Price\n",
       "0     Twingo   11000\n",
       "1      Swift   14500\n",
       "2  C4 Cactus   23000\n",
       "3       Clio   16000\n",
       "4      Prius   30000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_cars = pd.read_clipboard()\n",
    "df_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbe1ab-31ca-4c85-a1b5-3951f949e0ca",
   "metadata": {},
   "source": [
    "# Extra Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2e258-9a26-4ed0-89fc-4d8647752702",
   "metadata": {},
   "outputs": [],
   "source": [
    "listem = ['y', 'n'] # İstenen veri listesi\n",
    "count = 0 # Sayacı sıfırla\n",
    "for col in df.iloc[:, 1:].columns: # Sütunları döngüye sok\n",
    "    for val in df[col].values: # Her bir hücreyi döngüye sok\n",
    "        if val not in listem: # Eğer hücrenin değeri listede yoksa\n",
    "            count += 1 # Sayacı arttır\n",
    "count\n",
    "\n",
    "\n",
    "count = sum([sum([1 for val in col if val not in ['y', 'n']]) for col in df.values])\n",
    "count\n",
    "\n",
    "\n",
    "check = all(all(val in ['y', 'n'] for val in col) for col in df.values)\n",
    "check\n",
    "\n",
    "\n",
    "df.apply(lambda x : x.isin(['y', 'n']) == False) # bitmedi daha???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092831e-eb54-4277-9652-d8dfe2e97169",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdec8d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    Data processing can be reduced to the use of 4 essential operations: filtering, merging, ordering and grouping.\n",
    "\n",
    "    If the DataFrame class has prevailed in the domain of data manipulation, it is because it is often sufficient to repeat or combine these four operations.\n",
    "\n",
    "    In this exercise, you will learn how to use these 4 operations of data processing.\n",
    "\n",
    "    Before starting this notebook, run the following cell in order to retrieve the work done in the previous exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports ###\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Data import\n",
    "transactions = pd.read_csv(\"transactions.csv\", sep =',', index_col = \"transaction_id\")\n",
    "\n",
    "# Removal of duplicates\n",
    "transactions = transactions.drop_duplicates(keep = 'first')\n",
    "\n",
    "# Changing the names of the columns\n",
    "new_names =  {'Store_type' : 'store_type',\n",
    "              'Qty'        : 'qty',\n",
    "              'Rate'       : 'rate',\n",
    "              'Tax'        : 'tax'}\n",
    "\n",
    "transactions = transactions.rename(new_names, axis = 1)\n",
    "\n",
    "### Handling NAs ###\n",
    "\n",
    "#  We replace the NAs in 'prod_subcat_code' by -1\n",
    "transactions['prod_subcat_code'] = transactions['prod_subcat_code'].fillna(-1).astype(int)\n",
    "\n",
    "# We compute the mode of 'store_type'\n",
    "store_type_mode = transactions['store_type'].mode()\n",
    "\n",
    "# We replace the NAs of 'store_type' by its mode\n",
    "transactions['store_type'] = transactions['store_type'].fillna(transactions['store_type'].mode()[0])\n",
    "\n",
    "# Removal of rows where 'rate', 'tax' and 'total_amt' are all NAs\n",
    "transactions = transactions.dropna(axis = 0, how = 'all', subset = ['rate', 'tax', 'total_amt'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3485a7a",
   "metadata": {},
   "source": [
    "## 1. Filtering a DataFrame with binary operators.\n",
    "\n",
    "    Filtering consists in selecting a subset of rows of a DataFrame which meet a condition. Filtering corresponds to what was called conditional indexing until now, but the term \"filtering\" is the one that is used most in database management.\n",
    "\n",
    "    We cannot use the logical operators and and or to filter on multiple conditions. Indeed, these operators create ambiguities that pandas is unable to handle for filtering.\n",
    "\n",
    "    The operators suitable for filtering on several conditions are the binary operators:\n",
    "\n",
    "            The 'and' operator: &.\n",
    "\n",
    "            The 'or' operator: |.\n",
    "\n",
    "            The 'not' operator: -.\n",
    "\n",
    "    These operators are similar to logical operators but their evaluation methods are not the same.\n",
    "\n",
    "The 'and' operator: &.\n",
    "\n",
    "    The & operator is used to filter a DataFrame on several conditions which must be verified simultaneously.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Consider the following DataFrame`` df that contains information on apartments in Paris:\n",
    "    \tdistrict \tyear \tsurface\n",
    "    0 \t'Champs-Elysées' \t1979 \t70\n",
    "    1 \t'Europe' \t1850 \t110\n",
    "    2 \t'Père-Lachaise' \t1935 \t55\n",
    "    3 \t'Bercy' \t1991 \t30\n",
    "\n",
    "    If we want to find an apartment dating from 1979 and with a surface area greater than 60 squared meters, we can filter the lines of df with the following code:\n",
    "\n",
    "\n",
    "    # Filtering of the DataFrame on the 2 previous conditions\n",
    "    print(df[(df['year'] == 1979) & (df['surface']> 60)])\n",
    "\n",
    "    >>>         district  year  surface\n",
    "    >>> 0  Champs-Elysées  1979       70\n",
    "\n",
    "    The conditions must be written between parentheses to eliminate any ambiguity on the order of evaluation of the conditions. Indeed, if the conditions are not properly separated, we will get the following error:\n",
    "\n",
    "    print(df[df['year'] == 1979 & df['surface']> 60])\n",
    "\n",
    "    >>> ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\n",
    "\n",
    "The 'or' operator: |.\n",
    "\n",
    "    The operator | is used to filter a DataFrame on several conditions of which one at least must be verified.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Consider the same DataFrame df:\n",
    "    \tdistrict \tyear \tsurface\n",
    "    0 \t'Champs-Elysées' \t1979 \t70\n",
    "    1 \t'Europe' \t1850 \t110\n",
    "    2 \t'Père-Lachaise' \t1935 \t55\n",
    "    3 \t'Bercy' \t1991 \t30\n",
    "\n",
    "    If we want to find an apartment that dates after 1900 or is located in the Père-Lachaise district, we can filter the lines of df with the following code:\n",
    "\n",
    "\n",
    "    # Filtering of the DataFrame on the 2 previous conditions\n",
    "    print(df[(df['year']> 1900) | (df['district'] == 'Père-Lachaise')])\n",
    "\n",
    "    >>>          district  year  surface\n",
    "    >>> 0  Champs-Elysées  1979       70\n",
    "    >>> 2  Père-Lachaise   1935       55\n",
    "    >>> 3  Bercy           1991       30\n",
    "\n",
    "The 'not' operator: -.\n",
    "\n",
    "    The operator - is used to filter aDataFrame on a condition which must not be true, i.e. whose negation must be verified.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Consider the same DataFrame`` df:\n",
    "    \tdistrict \tyear \tsurface\n",
    "    0 \t'Champs-Elysées' \t1979 \t70\n",
    "    1 \t'Europe' \t1850 \t110\n",
    "    2 \t'Père-Lachaise' \t1935 \t55\n",
    "    3 \t'Bercy' \t1991 \t30\n",
    "\n",
    "    If we want to retrieve apartments not located in the Bercy district then we filter df as follows:\n",
    "\n",
    "    # Filtering of the DataFrame on the the negation of a condition\n",
    "    print(df[-(df['district'] == 'Bercy')])\n",
    "\n",
    "    >>> district year surface\n",
    "    >>> 0 Champs-Elysées 1979 70\n",
    "    >>> 1 Europe 1850 110\n",
    "    >>> 2 Père-Lachaise 1935 55\n",
    "\n",
    "    (a) Display the first 5 lines of the transactions DataFrame.\n",
    "\n",
    "    (b) From transactions, create a DataFrame named e_shop containing only the transactions carried out in stores of type 'e-Shop' with a total amount greater than than 5000 ('store_type' and 'total_ amt' columns).\n",
    "\n",
    "    (c) Similarly, create a DataFrame named teleshop which contains the transactions made in stores of type 'TeleShop' with a total amount of more than 5000.\n",
    "\n",
    "    (d) Which of the two types of store has the most transactions over € 5,000?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df = transactions.copy()\n",
    "\n",
    "print('solution a', 50 * '-')\n",
    "\n",
    "(df.head())\n",
    "\n",
    "print('solution b', 50 * '-')\n",
    "\n",
    "e_shop = df[(df['store_type'] == 'e-Shop') & (df['total_amt'] > 5000)]\n",
    "e_shop\n",
    "\n",
    "print('solution c', 50 * '-')\n",
    "\n",
    "tele_shop = df.loc[(df['store_type'] == 'TeleShop') & (df['total_amt'] > 5000)]\n",
    "tele_shop\n",
    "\n",
    "print('solution d', 50 * '-')\n",
    "\n",
    "print('e_shop shape :', e_shop.shape[0], 'tele_shop shape :', tele_shop.shape[0])\n",
    "\n",
    "\n",
    "#Original Cozum\n",
    "\n",
    "# Creation of e_shop et teleshop\n",
    "e_shop = transactions[(transactions['store_type'] == 'e-Shop') & (transactions['total_amt'] > 5000)]\n",
    "\n",
    "\n",
    "teleshop = transactions[(transactions['store_type'] == 'TeleShop') & (transactions['total_amt'] > 5000)]\n",
    "\n",
    "\n",
    "# We count the number of rows of each DataFrame. Other solutions are possible.\n",
    "print('Number of transactions over 5000€ for e-shop :', len(e_shop))\n",
    "print('Number of transactions over 5000€ for teleshop :', len(teleshop))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89b6bba7",
   "metadata": {},
   "source": [
    "### output \n",
    "Number of transactions over 5000€ for e-shop : 1185\n",
    "\n",
    "Number of transactions over 5000€ for teleshop : 532\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39809f0",
   "metadata": {},
   "source": [
    "\n",
    "    (e) Import into two DataFrames named respectively customer and prod_cat_info the data contained in the files 'customer.csv' and 'prod_cat_info.csv'.\n",
    "\n",
    "    (f) The Gender and city_code columns of customer contain two missing values each. Replace them with their mode using the fillna and mode methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b808d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "print('solution e', 50 * '-')\n",
    "customer = pd.read_csv('customer.csv')\n",
    "customer.head()\n",
    "prod_cat_info = pd.read_csv('prod_cat_info.csv')\n",
    "prod_cat_info.head()\n",
    "\n",
    "print('solution f', 50 * '-')\n",
    "mode_gender = customer['Gender'].mode()[0]\n",
    "customer['Gender'].fillna(mode_gender, inplace=True)\n",
    "\n",
    "mode_city_code = customer['city_code'].mode()[0]\n",
    "customer['city_code'].fillna(mode_city_code, inplace=True)\n",
    "\n",
    "customer.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d930216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "prod_cat_code \tprod_cat \tprod_sub_cat_code \tprod_subcat\n",
    "0 \t1 \tClothing \t4 \tMens\n",
    "1 \t1 \tClothing \t1 \tWomen\n",
    "2 \t1 \tClothing \t3 \tKids\n",
    "3 \t2 \tFootwear \t1 \tMens\n",
    "4 \t2 \tFootwear \t3 \tWomen\n",
    "\n",
    "customer_Id    0\n",
    "DOB            0\n",
    "Gender         0\n",
    "city_code      0\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571b3df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Cozum\n",
    "customer = pd.read_csv('customer.csv')\n",
    "prod_cat_info = pd.read_csv('prod_cat_info.csv')\n",
    "\n",
    "customer['Gender'] = customer['Gender'].fillna(customer['Gender'].mode()[0])\n",
    "customer['city_code'] = customer['city_code'].fillna(customer['city_code'].mode()[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8974ccf",
   "metadata": {},
   "source": [
    "## 2. Joining Dataframes: concat function and merge method.\n",
    "Concatenation of DataFrames with concat\n",
    "\n",
    "    The concat function of thepandas module allows you to concatenate several DataFrames, i.e. juxtapose them horizontally or vertically.\n",
    "\n",
    "    The header of this function is as follows:\n",
    "\n",
    "    pandas.concat (objs, axis ..)\n",
    "\n",
    "            The objs parameter contains the list of DataFrames to concatenate.\n",
    "            The axis parameter specifies whether to concatenate vertically (axis = 0) or horizontally (axis = 1).\n",
    "\n",
    "\n",
    "<img src=\"Photos\\pd_concat_en.png\" width=\"800\" height=\"400\">\n",
    "\n",
    "\n",
    "    When the number of rows or columns of the DataFrames does not match, the concat function fills the empty cells with NaN, as shown in the illustration below.\n",
    "\n",
    "\n",
    "<img src=\"Photos\\pd_concat_none_en.png\" width=\"800\" height=\"400\">\n",
    "\n",
    "    (a) Split the columns of the transactions DataFrame in half with half of the columns in a DataFrame named part_1 and the second half in a DataFrame named part_2.\n",
    "\n",
    "    (b) Reconstitute transactions in a DataFrame named union by concatenating part_1 and part_2 horizontally.\n",
    "\n",
    "    (c) What happens if we concatenate part_1 and part_2 by filling in the argument axis = 0?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fa1e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here \n",
    "\n",
    "print('solution a', 50 * '-')\n",
    "column_part1 = df.columns[:5]\n",
    "part1 = df[column_part1]\n",
    "\n",
    "column_part2  = df.columns[5:]\n",
    "part2 = df[column_part2]\n",
    "\n",
    "part1\n",
    "\n",
    "print('solution b', 50 * '-')\n",
    "\n",
    "union  = pd.concat([part1,part2], axis=1)\n",
    "union\n",
    "\n",
    "print('solution c', 50 * '-')\n",
    "\n",
    "union_axis0 = pd.concat([part1,part2], axis=0)\n",
    "union_axis0\n",
    "\n",
    "# Original Cozum\n",
    "# Splitting of the transactions DataFrame\n",
    "part_1 = transactions[transactions.columns[:4]]\n",
    "part_2 = transactions[transactions.columns[4:]]\n",
    "\n",
    "# Reconstitution of the transactions DataFrame by concatenation\n",
    "union = pd.concat([part_1,part_2], axis = 1)\n",
    "\n",
    "# If we were to concatenate by filling in the argument \"axis = 0\", we would obtain a DataFrame where half of\n",
    "# the valuers are NAs\n",
    "#\n",
    "# This is due to the fact that the argument 'axis = 0' forces the pd.concat function to create new ROWS\n",
    "# in part_1 but it cannot fill them correctly since part_1 and part_2 have no columns in common."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de63bc4d",
   "metadata": {},
   "source": [
    "## Merging DataFrames with the merge method\n",
    "\n",
    "    Two DataFrames can be merged if they have a column in common. This is done thanks to the merge method of the DataFrame class whose header is as follows:\n",
    "\n",
    "    merge(right, on, how, ...)\n",
    "\n",
    "            The right parameter is the DataFrame to merge with the one calling the method.\n",
    "\n",
    "            The on parameter is the name of the columns of the DataFrame which will be used as reference for the merge. They must be common to both DataFrames\n",
    "\n",
    "            The how parameter allows you to choose the type of join to perform for merging the DataFrames. The values for this parameter are based on SQL syntax joins.\n",
    "\n",
    "\n",
    "    The how parameter can take 4 values ('inner', 'outer', 'left', 'right') that we will illustrate on the two DataFrames named Persons and Vehicles below:\n",
    "    \n",
    "    Name \tCar\n",
    "    Lila \tTwingo\n",
    "    Tiago \tClio\n",
    "    Berenice \tC4 Cactus\n",
    "    Joseph \tTwingo\n",
    "    Kader \tSwift\n",
    "    Romy \tScenic\n",
    "    \n",
    "    Car \tPrice\n",
    "    Twingo \t11000\n",
    "    Swift \t14500\n",
    "    C4 Cactus \t23000\n",
    "    Clio \t16000\n",
    "    Prius \t30000\n",
    "\n",
    "            'inner': The inner join returns the rows whose values in the common columns are present in the two DataFrames. This type of join is often not recommended because it can lead to the loss of many entries. However, the inner join does not produces NAs.\n",
    "\n",
    "        The result of the inner join Persons.merge(right = Vehicles, on = 'Car', how = 'inner') is shown below:\n",
    "\n",
    "<img src=\"Photos\\pd_join_inner_en.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "\n",
    "            'outer': The outer join Persons the two DataFrames in their entirety. No row will be deleted. This method can generate a lot of NAs.\n",
    "\n",
    "        The result of the outer join Persons.merge(right = Vehicles, on = 'Car', how = 'outer') is shown below:\n",
    "\n",
    "<img src=\"Photos\\pd_join_outer_en.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "\n",
    "            'left': The left join returns all the rows of the DataFrame on the left (i.e. the one calling the method), and completes them with the rows of the second DataFrame which coincide according to the values of the common column. This is the default value for the how parameter.\n",
    "\n",
    "        The result of the left join Persons.merge(right = Vehicles, on = 'Car', how = 'left') is shown below:\n",
    "\n",
    "<img src=\"Photos\\pd_join_left_en.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "\n",
    "            'right': The right join returns all the rows of the DataFrame on the right, and complete them with the rows of the left DataFrame which coincide according to the values of the common column.\n",
    "\n",
    "        The result of the right join Persons.merge(right = Vehicles, on = 'Car', how = 'right') is shown below:\n",
    "<img src=\"Photos\\pd_join_right_en.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "\n",
    "    Doing a left join, right join, or outer join followed by a dropna(how = 'any') is equivalent to an inner join.\n",
    "\n",
    "    The customer DataFrame contains information about customers in the 'cust_id' column of transactions.\n",
    "\n",
    "    The 'customer_Id' column of the customer DataFrame will be used to make the join between transactions and customer. This will enrich the transactions DataFrame with additional information.\n",
    "\n",
    "    (d) Using the rename method and a dictionary, rename the 'customer_Id' column of the customer DataFrame to 'cust_id'.\n",
    "\n",
    "    (e) Using the merge method, perform the left join between the DataFrames transactions and customer on the 'cust_id' column. Name the created DataFramefusion.\n",
    "\n",
    "    (f) Did the merging produce NAs?\n",
    "\n",
    "    (g) Display the first lines of fusion. What are the new columns?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# d)\n",
    "customer = customer.rename({'customer_Id' : 'cust_id'} , axis= 'columns')\n",
    "customer\n",
    "\n",
    "# e)\n",
    "fusion = transactions.merge(customer, on='cust_id', how='left')\n",
    "fusion\n",
    "\n",
    "#f)\n",
    "fusion.isna().sum()\n",
    "\n",
    "# g)\n",
    "fusion.head()\n",
    "\n",
    "#original cozum\n",
    "# We rename the 'customer_Id' column to 'cust_id' for merging\n",
    "customer = customer.rename(columns = {'customer_Id': 'cust_id'})\n",
    "\n",
    "# Left join between transactions and customer on the 'cust_id' column\n",
    "fusion = transactions.merge(right = customer, on = 'cust_id', how = 'left')\n",
    "\n",
    "# The merging did not produce NAs\n",
    "fusion.isna().sum()\n",
    "\n",
    "# The columns DOB, Gender, city_code have been added to transactions\n",
    "fusion.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5252a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_id \ttran_date \tprod_subcat_code \tprod_cat_code \tqty \trate \ttax \t        total_amt \tstore_type \tDOB      \tGender \tcity_code\n",
    "0 \t270351 \t28-02-2014 \t1                       \t1 \t-5 \t-772.0 \t405.300 \t-4265.300 \te-Shop \t        26-09-1981 \tM \t5.0\n",
    "1 \t270384 \t27-02-2014 \t5                              \t3 \t-5 \t-1497.0 785.925 \t-8270.925 \te-Shop \t        11-05-1973 \tF \t8.0\n",
    "2 \t273420 \t24-02-2014 \t6 \t                        5 \t-2 \t-791.0 \t166.110 \t-1748.110 \tTeleShop \t27-07-1992 \tM \t8.0\n",
    "3 \t271509 \t24-02-2014 \t11 \t                        6 \t-3 \t-1363.0 429.345 \t-4518.345 \te-Shop \t        08-06-1981 \tM \t3.0\n",
    "4 \t273420 \t23-02-2014 \t6 \t                        5 \t-2 \t-791.0 \t166.110 \t-1748.110 \tTeleShop \t27-07-1992 \tM \t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073c293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    The merging went well and produced no NaNs. However, the index of the DataFrame is no longer the column transaction_id' and has been reset with the default index (0,1, 2 , ...).\n",
    "\n",
    "    It is possible to re-define the index of a DataFrame using the set_index method.\n",
    "\n",
    "    This method can take as argument:\n",
    "\n",
    "            The name of a column to use as indexing.\n",
    "            A Numpy array or pandas Series with the same number of rows as the DataFrame calling the method.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Let df be the following DataFrame:\n",
    "    \tName \tCar\n",
    "    0 \tLila \tTwingo\n",
    "    1 \tTiago \tClio\n",
    "    2 \tBerenice \tC4 Cactus\n",
    "    3 \tJoseph \tTwingo\n",
    "    4 \tKader \tSwift\n",
    "    5 \tRomy \tScenic\n",
    "\n",
    "    We can set the column 'Name' as being the new index:\n",
    "\n",
    "    df = df.set_index('Name')\n",
    "\n",
    "    This will produce the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    Name \tCar\n",
    "    Lila \tTwingo\n",
    "    Tiago \tClio\n",
    "    Berenice \tC4 Cactus\n",
    "    Joseph \tTwingo\n",
    "    Kader \tSwift\n",
    "    Romy \tScenic\n",
    "\n",
    "    We can also define the index from a Numpy array, from a Series, etc:\n",
    "\n",
    "    # New index to use\n",
    "    new_index = ['10000' + str(i) for i in range(6)]\n",
    "    print(new_index)\n",
    "    >>> ['100000', '100001', '100002', '100003', '100004', '100005']\n",
    "\n",
    "    # Using an array or a Series is equivalent\n",
    "    index_array = np.array(new_index)\n",
    "    index_series = pd.Series(new_index)\n",
    "\n",
    "\n",
    "    df = df.set_index(index_array)\n",
    "    df = df.set_index(index_series)\n",
    "\n",
    "    This will produce the following DataFrame:\n",
    "    \tName \tCar\n",
    "    100000 \tLila \tTwingo\n",
    "    100001 \tTiago \tClio\n",
    "    100002 \tBerenice \tC4 Cactus\n",
    "    100003 \tJoseph \tTwingo\n",
    "    100004 \tKader \tSwift\n",
    "    100005 \tRomy \tScenic\n",
    "\n",
    "    To return to the default numeric indexing, we use the reset_index method of the DataFrame:\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    The indexing column that was used is not deleted. A new column will be created containing the old index:\n",
    "    \tindex \tName \tCar\n",
    "    0 \t100000 \tLila \tTwingo\n",
    "    1 \t100001 \tTiago \tClio\n",
    "    2 \t100002 \tBerenice \tC4 Cactus\n",
    "    3 \t100003 \tJoseph \tTwingo\n",
    "    4 \t100004 \tKader \tSwift\n",
    "    5 \t100005 \tRomy \tScenic\n",
    "\n",
    "Merging transactions andcustomer removed the index of transactions.\n",
    "\n",
    "The index of a DataFrame can be retrieved using its .index attribute.\n",
    "\n",
    "    (h) Take the index from transactions and use it to index fusion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fc7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "fusio = fusion.set_index(transactions.index)\n",
    "fusion\n",
    "\n",
    "#Original; Cozum\n",
    "# We retrieve the index of transactions\n",
    "new_index = transactions.index\n",
    "\n",
    "# We set the new index of fusion\n",
    "fusion = fusion.set_index(new_index)\n",
    "fusion.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36a1335c",
   "metadata": {},
   "source": [
    "## 3. Sort and order the values of a DataFrame: sort_values and sort_index methods.\n",
    "\n",
    "    The sort_values method allows you to sort the rows of a DataFrame according to the values of one or more columns.\n",
    "\n",
    "    The header of this method is as follows:\n",
    "\n",
    "    sort_values(by, ascending, ...)\n",
    "\n",
    "            The by parameter allows you to specify on which column(s) the sort is performed.\n",
    "\n",
    "            The ascending parameter is a boolean value (True or False) determining whether the sorting order is ascending or descending. By default this parameter is set to True.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Consider the DataFrame df describing students:\n",
    "    Name \tGrade \tBonus points\n",
    "    'Amelie' \tA \t1\n",
    "    'Marin' \tF \t1\n",
    "    'Pierre' \tA \t2\n",
    "    'Zoe' \tC \t1\n",
    "\n",
    "    First of all, we will sort the rows on a single column, for example the column 'Bonus Points':\n",
    "\n",
    "    # We sort the DataFrame df on the column 'Bonus Points'\n",
    "    df_sorted = df.sort_values(by ='Bonus Points', ascending = True)\n",
    "\n",
    "    We obtain the following result:\n",
    "<img src=\"Photos\\pd_sort_values_en.png\" width=\"700\" height=\"500\">\n",
    "\n",
    "    The rows of the DataFrame df_sorted are therefore sorted in ascending order of the 'Bonus points' column. However, if we look at the column 'Grade', we see that it is not sorted alphabetically for the common values of 'Bonus Points'.\n",
    "\n",
    "    This can be remedied by also sorting by the 'Grade' column:\n",
    "\n",
    "    # We first sort the DataFrame df by the column 'Bonus Points' then in case of equality, by the column 'Grade'.\n",
    "    df_sorted = df.sort_values(by = ['Bonus Points', 'Grade'], ascending = True)\n",
    "\n",
    "\n",
    "    We obtain the following result:\n",
    "\n",
    "<img src=\"Photos\\pd_sort_values_2_en.png\" width=\"700\" height=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "    The sort_index method allows you to sort a DataFrame according to its index.\n",
    "\n",
    "    If the index is the default one (numerical), this method is not particularly interesting.\n",
    "\n",
    "    However, it can often be combined with the set_index method of a DataFrame that we have just seen.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    # We define the column 'Grade' as the index of df\n",
    "    df = df.set_index('Grade')\n",
    "\n",
    "    # We sort the DataFrame df according to its index\n",
    "    df = df.sort_index()\n",
    "\n",
    "    This produces the following DataFrame:\n",
    "\n",
    "\n",
    "\n",
    "    Grade \tName \tBonus points\n",
    "    A \t'Amelie' \t1\n",
    "    A \t'Peter' \t2\n",
    "    C \t'Zoe' \t1\n",
    "    F \t'Sailor' \t1\n",
    "\n",
    "    Consider the two following DataFrames containing boat rental data.\n",
    "\n",
    "    Below are the boats DataFrame:\n",
    "    \tboat_name \tcolor \treservation_number \tn_reservations\n",
    "    0 \tJulia \tblue \t2 \t34\n",
    "    1 \tSiren \tgreen \t3 \t10\n",
    "    2 \tSea Sons \tred \t6 \t20\n",
    "    3 \tHercules \tblue \t1 \t41\n",
    "    4 \tCesar \tyellow \t4 \t12\n",
    "    5 \tMinerva \tgreen \t5 \t16\n",
    "\n",
    "    And the clients DataFrame:\n",
    "    \tclient_id \tclient_name \treservation_id\n",
    "    0 \t91 \tMarie \t1\n",
    "    1 \t154 \tAnna \t2\n",
    "    2 \t124 \tYann \t3\n",
    "    3 \t320 \tLea \t7\n",
    "    4 \t87 \tMarc \t9\n",
    "    5 \t22 \tYassine \t10\n",
    "\n",
    "    (a) Run the following cell to instantiate these DataFrames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63c49c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data dictionnaries\n",
    "import pandas as pd\n",
    "data_boats = {'boat_name'         : ['Julia', 'Siren', 'Sea Sons', 'Hercules', 'Cesar', 'Minerva'], \n",
    "              'color'             : ['blue', 'green', 'red', 'blue', 'yellow', 'green'],\n",
    "              'reservation_number': [2, 3, 6, 1, 4, 5],\n",
    "              'n_reservations'    : [34, 10, 20, 41, 12, 16]}\n",
    "\n",
    "data_clients = {'client_id'     : [91, 154, 124, 320, 87, 22], \n",
    "                'client_name'   : ['Marie', 'Anna', 'Yann', 'Lea', 'Marc', 'Yassine'],\n",
    "                'reservation_id': [1, 2, 3, 7, 9, 5]}\n",
    "\n",
    "# Instantiation of the DataFrames\n",
    "boats = pd.DataFrame(data_boats)\n",
    "clients = pd.DataFrame(data_clients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ada393",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    We want to easily determine which customer has reserved the boats of the boats DataFrame. To do this, we can simply merge the DataFrames.\n",
    "\n",
    "    (b) Rename the 'reservation_number' column from boats to 'reservation_id' using the rename method.\n",
    "\n",
    "    (c) In a DataFrame named boats_clients, perform the left join between boats (left) and clients (right).\n",
    "\n",
    "    (d) Set the column 'boat_name' as index of the boats_clients DataFrame.\n",
    "\n",
    "    (e) Using the loc method, find who reserved the boats 'Julia' and 'Siren'.\n",
    "\n",
    "    (f) Using the isna method applied to the client_name column, determine the boats that have not been reserved.\n",
    "\n",
    "    (g) The number of times a boat has been reserved so far is indicated by the column 'n_reservations'. Using the sort_values method, determine the name of the customer who reserved the blue boat with the most reservations to date.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326c5532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>reservation_id</th>\n",
       "      <th>n_reservations</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boat_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hercules</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Marie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julia</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>154.0</td>\n",
       "      <td>Anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sea Sons</th>\n",
       "      <td>red</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minerva</th>\n",
       "      <td>green</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Yassine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cesar</th>\n",
       "      <td>yellow</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Siren</th>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Yann</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            color  reservation_id  n_reservations  client_id client_name\n",
       "boat_name                                                               \n",
       "Hercules     blue               1              41       91.0       Marie\n",
       "Julia        blue               2              34      154.0        Anna\n",
       "Sea Sons      red               6              20        NaN         NaN\n",
       "Minerva     green               5              16       22.0     Yassine\n",
       "Cesar      yellow               4              12        NaN         NaN\n",
       "Siren       green               3              10      124.0        Yann"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "#b)\n",
    "boats.rename(columns = {'reservation_number' :'reservation_id' }, inplace=True)\n",
    "\n",
    "#c)\n",
    "boats_clients = boats.merge(clients, how='left', on='reservation_id')\n",
    "boats_clients\n",
    "#d)\n",
    "boats_clients = boats_clients.set_index('boat_name')\n",
    "boats_clients\n",
    "#e)\n",
    "#boats_clients.loc[boats_clients.index.isin(['Julia', 'Siren'])]\n",
    "boats_clients.loc[['Julia', 'Siren']]\n",
    "\n",
    "#f)\n",
    "#boats_clients.client_name.fillna('not_reserved', inplace=True)\n",
    "boats_clients[boats_clients.client_name.isna()].index\n",
    "\n",
    "#g)\n",
    "boats_clients.sort_values('n_reservations', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba305bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The client who reserved 'Julia' is: Anna\n",
      "The client who reserved 'Siren' is: Yann\n",
      "\n",
      "\n",
      "The boats which have not been reserved are: ['Sea Sons', 'Cesar']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>reservation_id</th>\n",
       "      <th>n_reservations</th>\n",
       "      <th>client_id</th>\n",
       "      <th>client_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boat_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hercules</th>\n",
       "      <td>blue</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Marie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Julia</th>\n",
       "      <td>blue</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>154.0</td>\n",
       "      <td>Anna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sea Sons</th>\n",
       "      <td>red</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minerva</th>\n",
       "      <td>green</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Yassine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cesar</th>\n",
       "      <td>yellow</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Siren</th>\n",
       "      <td>green</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Yann</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            color  reservation_id  n_reservations  client_id client_name\n",
       "boat_name                                                               \n",
       "Hercules     blue               1              41       91.0       Marie\n",
       "Julia        blue               2              34      154.0        Anna\n",
       "Sea Sons      red               6              20        NaN         NaN\n",
       "Minerva     green               5              16       22.0     Yassine\n",
       "Cesar      yellow               4              12        NaN         NaN\n",
       "Siren       green               3              10      124.0        Yann"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original Cozum\n",
    "# We rename the column 'number_reservation'\n",
    "boats = boats.rename(columns = {'reservation_number': 'reservation_id'})\n",
    "\n",
    "# We perform the left join between boats and clients\n",
    "boats_clients = boats.merge(clients, on = 'reservation_id', how = 'left')\n",
    "\n",
    "# We set the column 'boat_name' as the index of boats_clients\n",
    "boats_clients = boats_clients.set_index(\"boat_name\")\n",
    "\n",
    "# Who reserved 'Julia' and 'Siren'?\n",
    "print(\"The client who reserved 'Julia' is:\", boats_clients.loc['Julia', 'client_name'])\n",
    "print(\"The client who reserved 'Siren' is:\", boats_clients.loc['Siren', 'client_name'])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Which boats have not been reserved?\n",
    "boats_not_reserved = boats_clients[boats_clients['client_name'].isna()]\n",
    "print(\"The boats which have not been reserved are:\", [boat for boat in boats_not_reserved.index])\n",
    "\n",
    "# Which client reserved the BLUE boat with the MOST reservations to date?\n",
    "\n",
    "boats_clients.sort_values(by = 'n_reservations', ascending = False)\n",
    "# Marie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3066453",
   "metadata": {},
   "source": [
    "## 4. Grouping the elements of a DataFrame: groupby, agg and crosstab methods.\n",
    "\n",
    "    The groupby method allows you to group the rows of a DataFrame which share a common value on a given column.\n",
    "\n",
    "    This method does not return a DataFrame. The object returned by the groupby method is an object of the DataFrameGroupBy class.\n",
    "\n",
    "    This class is used to perform operations such as calculating statistics (sum, average, maximum, etc.) for each modality of the column on which the rows are grouped.\n",
    "\n",
    "    The general structure of a groupby operation is as follows:\n",
    "\n",
    "            Split the data.\n",
    "            Apply a function.\n",
    "            Combine the results.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    It is assumed that the boats in the boats DataFrame are all identical and have the same age. We want to determine if the color of a boat has an influence on its number of reservations. For this, we will calculate for each color the average number of reservations per boat.\n",
    "\n",
    "    It is therefore necessary to:\n",
    "\n",
    "            Split the boats by color.\n",
    "            Apply the mean function to compute the average number of reservations.\n",
    "            Combine the results in a DataFrame to easily compare them.\n",
    "\n",
    "    Therefore, we can use the groupby method followed by the mean method to get the result:\n",
    "\n",
    "<img src=\"Photos\\pd_groupby_en.png\" width=\"900\" height=\"500\">\n",
    "\n",
    "\n",
    "    All the usual statistical methods (count,mean, max, etc.) can be used as a suffix of the groupby method. These will only be applied on columns of compatible type.\n",
    "\n",
    "    It is possible to specify for each column which function must be used in the Apply step of a groupby operation. For that, we use the agg method of the DataFrameGroupBy class by giving it a dictionary where each key is the name of a column and the value is the function to apply.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Let us go back to the transactions DataFrame:\n",
    "    transaction_id \tcust_id \ttran_date \tprod_subcat_code \tprod_cat_code \tqty \trate \ttax \ttotal_amt \tstore_type\n",
    "    80712190438 \t270351 \t28-02-2014 \t1 \t1 \t-5 \t-772 \t405.3 \t-4265.3 \te-Shop\n",
    "    29258453508 \t270384 \t27-02-2014 \t5 \t3 \t-5 \t-1497 \t785.925 \t-8270.92 \te-Shop\n",
    "    51750724947 \t273420 \t24-02-2014 \t6 \t5 \t-2 \t-791 \t166.11 \t-1748.11 \tTeleShop\n",
    "    93274880719 \t271509 \t24-02-2014 \t11 \t6 \t-3 \t-1363 \t429.345 \t-4518.35 \te-Shop\n",
    "    51750724947 \t273420 \t23-02-2014 \t6 \t5 \t-2 \t-791 \t166.11 \t-1748.11 \tTeleShop\n",
    "\n",
    "    We want to determine, for each customer (cust_id), the minimum, maximum and the total amount spent from the total_amt column. We also want to know how many types of stores the customer has made a transaction in (store_type column).\n",
    "\n",
    "    We can perform these calculations using a groupby operation:\n",
    "\n",
    "            Split the transactions by the customer identifier.\n",
    "            For the total_amt column, calculate the minimum (min), maximum (max) and the sum (sum). For the store_type column, count the number of unique modalities taken.\n",
    "            Combine the results in a DataFrame.\n",
    "\n",
    "    To find the number of unique modalities taken by the store_type column, we will use the following lambda function:\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    n_modalities = lambda store_type: len(np.unique(store_type))\n",
    "\n",
    "            The lambda function must take as argument a column and return a number.\n",
    "            The np.unique function determines the unique modalities that appear in a sequence.\n",
    "            The len function counts the number of elements in a sequence, i.e. its length.\n",
    "\n",
    "    Thus, this function will allow us to determine the number of unique modalities for the store_type column.\n",
    "\n",
    "    To apply these functions in the groupby operation, we'll use a dictionary whose keys are the columns to process and the values the functions to use.\n",
    "\n",
    "    functions_to_apply = {\n",
    "    # Classic statistical methods can be entered with\n",
    "    # strings\n",
    "    'total_amt': ['min', 'max', 'sum'],\n",
    "    'store_type': n_modalities\n",
    "    }\n",
    "\n",
    "    This dictionary can now be fed into the agg method to perform the groupby operation:\n",
    "\n",
    "    transactions.groupby('cust_id').agg(functions_to_apply)\n",
    "\n",
    "    Which produces the following DataFrame:\n",
    "\n",
    "\n",
    "                total_amt                               store_type\n",
    "\n",
    "                 min               max          sum \t   <lambda>\n",
    "\n",
    "    cust_id\n",
    "    266783 \t-5838.82 \t5838.82 \t3113.89 \t2\n",
    "    266784 \t442 \t4279.66 \t5694.07 \t3\n",
    "    266785 \t-6828.9 \t6911.77 \t21613.8 \t3\n",
    "    266788 \t1312.74 \t1927.12 \t6092.97 \t3\n",
    "    266794 \t-135,915 \t4610.06 \t27981.9 \t4\n",
    "\n",
    "    (a) Using a groupby operation, determine for each customer from the quantity of items purchased in a transaction (qty column):\n",
    "\n",
    "            The maximum quantity.\n",
    "            The minimum quantity\n",
    "            The median quantity.\n",
    "\n",
    "        You will have to filter the transactions whose quantity is negative. For this, you can use conditional indexing (qty[qty > 0]) over the column in a lambda function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "func = {'qty' : ['max', 'min', 'median']}\n",
    "\n",
    "transactions.loc[transactions.qty > 0].groupby('cust_id').agg(func).head()\n",
    "\n",
    "# Original Cozum\n",
    "# Maximal Quantity\n",
    "max_qty = lambda qty: qty[qty > 0].max()\n",
    "\n",
    "# Minimal Quantity\n",
    "min_qty = lambda qty: qty[qty > 0].min()\n",
    "\n",
    "# Median Quantity\n",
    "median_qty = lambda qty : qty[qty > 0].median()\n",
    "\n",
    "# Definition of the dictionnary of functions to apply\n",
    "functions_to_apply = {\n",
    "    'qty' : [max_qty, min_qty, median_qty]\n",
    "}\n",
    "\n",
    "# Groupby Operation\n",
    "qty_groupby = transactions.groupby('cust_id').agg(functions_to_apply)\n",
    "\n",
    "# For a better display, we can rename the columns produced by the groupby operation\n",
    "qty_groupby.columns.set_levels(['max_qty', 'min_qty', 'median_qty'], level=1, inplace = True)\n",
    "\n",
    "# Display of the first rows of the DataFrame produced by the groupby operation\n",
    "qty_groupby.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1d94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    Another way of grouping and summarizing data is to use the crosstab function of pandas which, as its name suggests, is used to crosstab the data in the columns of a DataFrame.\n",
    "\n",
    "    A crosstab allows us to visualize the appearance frequency of pairs of modalities in a DataFrame.\n",
    "\n",
    "    Example :\n",
    "\n",
    "    In the transactions DataFrame, we want to know which are the most frequent category and subcategory pairs (prod_cat_code and prod_subcat_code columns)\n",
    "\n",
    "    The crosstab function of pandas gives us this result:\n",
    "\n",
    "    column1 = transactions['prod_cat_code']\n",
    "    column2 = transactions['prod_subcat_code']\n",
    "    pd.crosstab(column1, column2)\n",
    "\n",
    "    This instruction produces the following DataFrame:\n",
    "    prod_subcat_code\n",
    "\n",
    "    prod_cat_code \t-1 \t1 \t2 \t3 \t4 \t5 \t6 \t7 \t8 \t9 \t10 \t11 \t12\n",
    "    1 \t4 \t1001 \t0 \t981 \t958 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "    2 \t4 \t934 \t0 \t1040 \t1005 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "    3 \t11 \t0 \t0 \t0 \t1020 \t950 \t0 \t0 \t966 \t976 \t945 \t0 \t0\n",
    "    4 \t5 \t993 \t0 \t0 \t988 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t0\n",
    "    5 \t3 \t0 \t0 \t1023 \t0 \t0 \t984 \t1037 \t0 \t0 \t998 \t1029 \t962\n",
    "    6 \t5 \t0 \t1002 \t0 \t0 \t0 \t0 \t0 \t0 \t0 \t1025 \t1013 \t1057\n",
    "\n",
    "    The (i, j) cell of the resulting DataFrame contains the number of rows of the DataFrame having the modality i for column 1 and the modality j for column 2.\n",
    "\n",
    "    Thus, it is easy to determine, for example, that the dominant subcategories of the category 4 are 1 and 4.\n",
    "\n",
    "    The normalize argument of crosstab allows to display frequencies as a percentage.\n",
    "\n",
    "    Thus, the argument normalize = 1 normalizes the table over the axis 1 of the crosstab, i.e. its columns:\n",
    "\n",
    "    We recover the year of the transaction.\n",
    "    column1 = transactions['tran_date'].apply(lambda x: x.split('-')[2]).astype(int)\n",
    "\n",
    "    column2 = transactions[store_type]\n",
    "\n",
    "    pd.crosstab(column1,\n",
    "                column2,\n",
    "                normalize = 1)\n",
    "\n",
    "    This produces the following DataFrame:\n",
    "\n",
    "\n",
    "    store_type\n",
    "\n",
    "    tran_date \tFlagship store \tMBR \tTeleShop \te-Shop\n",
    "    2011 \t0.291942 \t0.323173 \t0.283699 \t0.306947\n",
    "    2012 \t0.331792 \t0.322093 \t0.336767 \t0.322886\n",
    "    2013 \t0.335975 \t0.3115 \t0.332512 \t0.320194\n",
    "    2014 \t0.0402906 \t0.0432339 \t0.0470219 \t0.0499731\n",
    "\n",
    "    This DataFrame allows us to say that 33.5975% of the transactions made in a 'Flagship store' took place in 2013.\n",
    "\n",
    "    Conversely, by entering the argument normalize = 0, the crosstab is normalized over each row:\n",
    "\n",
    "\n",
    "    store_type\n",
    "\n",
    "    tran_date \tFlagship store \tMBR \tTeleShop \te-Shop\n",
    "    2011 \t0.191121 \t0.21548 \t0.182617 \t0.410781\n",
    "    2012 \t0.20096 \t0.198693 \t0.20056 \t0.399787\n",
    "    2013 \t0.205522 \t0.194074 \t0.2 \t0.400404\n",
    "    2014 \t0.173132 \t0.189215 \t0.198675 \t0.438978\n",
    "\n",
    "    Normalizing over the rows allows us to deduce that the transactions made in an 'e-Shop' account for 41.0781% of the transactions of the year 2011.\n",
    "\n",
    "    In the covid_tests.csv file, we have a dataset of 200 COVID-19 tests. The columns of this dataset are as follows:\n",
    "\n",
    "            'patient_id': ID of the patient tested.\n",
    "            'test_result': Result of the test. Equals 1 if the patient is tested positive and 0 otherwise.\n",
    "            'infected': Equals 1 if the patient was actually infected and 0 otherwise.\n",
    "\n",
    "    (b) Load the dataset contained in the covid_tests.csv file. The values are separated by the character ';'.\n",
    "\n",
    "    (c) Use the pd.crosstab function to determine the number of False Negatives produced by this test. (A false negative occurs when the test determines that the patient is not infected when they actually are.)\n",
    "\n",
    "    (d) What is the false positive rate of the test? The false positive rate is the proportion of false positives in relation to the number of people that are not infected. (A false positive occurs when the test determines the patient is infected when they are not.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af77e5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "#b)\n",
    "df = pd.read_csv('covid_tests.csv', sep=';')\n",
    "df\n",
    "\n",
    "#c)\n",
    "col1 = df.test_result\n",
    "col2 = df.infected\n",
    "\n",
    "print(pd.crosstab(col1, col2))\n",
    "print(30*'-', 'normalize = 1   3/3+71 ')\n",
    "#d) normalize = 0\n",
    "\n",
    "print(pd.crosstab(col1, col2, normalize=1))\n",
    "\n",
    "# normalize = 1\n",
    "print(30*'-', 'normalize = 0    3/3+119' )\n",
    "print(pd.crosstab(col1, col2, normalize=0))\n",
    "\n",
    "\n",
    "#Original Cozum\n",
    "# Loading the dataset in 'covid_tests.csv'\n",
    "covid_df = pd.read_csv(\"covid_tests.csv\", sep = ';', index_col = 'patient_id')\n",
    "covid_df.head()\n",
    "\n",
    "\n",
    "# Crosstab of the test results with reality\n",
    "pd.crosstab(covid_df['test_result'], \n",
    "            covid_df['infected'])\n",
    "\n",
    "# There are 3 false negatives\n",
    "\n",
    "\n",
    "pd.crosstab(covid_df['test_result'], \n",
    "            covid_df['infected'],\n",
    "            normalize = 1)\n",
    "\n",
    "# The false positive rate is about 5,6%\n",
    "# 94,4% of healthy people are true negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conclusion and recap\n",
    "\n",
    "    In this notebook you have learned to:\n",
    "\n",
    "            Filter the rows of a DataFrame with multiple conditions using the binary operators &, | and -:\n",
    "\n",
    "        # Year equal to 1979 and surface area greater than 60\n",
    "        df[(df['year'] == 1979) & (df['surface'] > 60)]\n",
    "\n",
    "        Year greater than 1900 or neighborhood equal to 'Père-Lachaise'.\n",
    "        df[(df['year'] > 1900) | (df['neighborhood'] == 'Père-Lachaise')]\n",
    "\n",
    "            Merge DataFrames using the concat function and the merge method.\n",
    "\n",
    "        # Vertical concatenation\n",
    "        pd.concat([df1, df2], axis = 0)\n",
    "\n",
    "        # Horizontal concatenation\n",
    "        pd.concat([df1, df2], axis = 1)\n",
    "\n",
    "        # Different types of joins\n",
    "        df1.merge(right = df2, on = 'column', how = 'inner')\n",
    "        df1.merge(right = df2, on = 'column', how = 'outer')\n",
    "        df1.merge(right = df2, on = 'column', how = 'left')\n",
    "        df1.merge(right = df2, on = 'column', how = 'right')\n",
    "\n",
    "            Sort and order the values of a DataFrame with the sort_values and sort_index methods.\n",
    "\n",
    "        # Sorting a DataFrame by 'column' in ascending order\n",
    "        df.sort_values(by = 'column', ascending = True)\n",
    "\n",
    "            Perform a complex groupby operation using lambda functions and the groupby and agg methods.\n",
    "\n",
    "        functions_to_apply = {\n",
    "        'column1': ['min', 'max'],\n",
    "        'column2' : [np.mean, np.std],\n",
    "        'column3' : lambda x: x.max() - x.min()\n",
    "        }\n",
    "\n",
    "        df.groupby('column_to_group_by').agg(functions_to_apply)\n",
    "\n",
    "    In this introductory module to Python for Data Science, you have learned how to create, clean and manipulate a dataset with Python using the numpy and pandas modules.\n",
    "\n",
    "    You now have all the tools to approach more advanced Data Science notions such as Machine Learning or Data Visualization :)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scpraing_portfolio_deneme",
   "language": "python",
   "name": "web_scpraing_portfolio_deneme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

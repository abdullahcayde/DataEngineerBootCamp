{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7524d50b",
   "metadata": {},
   "source": [
    "''' Pyspark '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a32d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992e82ee",
   "metadata": {},
   "source": [
    "'''Pyspark Deneme'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cd0ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/04 09:52:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The PySpark 3.4.0 version is running...\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\") \\\n",
    "                    .appName('BigData-ETL.com') \\\n",
    "                    .getOrCreate()\n",
    "\n",
    "print(f'The PySpark {spark.version} version is running...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36218c24",
   "metadata": {},
   "source": [
    "# Pysaprk DataScientest Ders01 - Big data processing with Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c8c42-21bc-452e-845f-fd60081bce86",
   "metadata": {},
   "source": [
    "## Introduction to PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa23a27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/04 10:15:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing SparkContext from the pyspark module\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Defining a SparkContext locally\n",
    "sc = SparkContext('local')\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d81e2bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2057.0</td>\n",
       "      <td>2052</td>\n",
       "      <td>2312.0</td>\n",
       "      <td>2258</td>\n",
       "      <td>AS</td>\n",
       "      <td>324</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>703.0</td>\n",
       "      <td>715</td>\n",
       "      <td>958.0</td>\n",
       "      <td>951</td>\n",
       "      <td>AS</td>\n",
       "      <td>572</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1846</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>2145</td>\n",
       "      <td>AS</td>\n",
       "      <td>511</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2301.0</td>\n",
       "      <td>2300</td>\n",
       "      <td>2354.0</td>\n",
       "      <td>2359</td>\n",
       "      <td>AS</td>\n",
       "      <td>376</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>1221</td>\n",
       "      <td>1422.0</td>\n",
       "      <td>1438</td>\n",
       "      <td>AS</td>\n",
       "      <td>729</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1   2   3       4     5       6     7   8    9   ...   19    20  21   \n",
       "0  2008   1   1   2  2057.0  2052  2312.0  2258  AS  324  ...  7.0  16.0   0  \\\n",
       "1  2008   1   1   2   703.0   715   958.0   951  AS  572  ...  6.0  25.0   0   \n",
       "2  2008   1   1   2  2011.0  1846  2248.0  2145  AS  511  ...  7.0  14.0   0   \n",
       "3  2008   1   1   2  2301.0  2300  2354.0  2359  AS  376  ...  5.0  13.0   0   \n",
       "4  2008   1   1   2  1221.0  1221  1422.0  1438  AS  729  ...  6.0  11.0   0   \n",
       "\n",
       "    22  23   24   25   26   27    28  \n",
       "0  NaN   0  NaN  NaN  NaN  NaN   NaN  \n",
       "1  NaN   0  NaN  NaN  NaN  NaN   NaN  \n",
       "2  NaN   0  0.0  0.0  0.0  0.0  63.0  \n",
       "3  NaN   0  NaN  NaN  NaN  NaN   NaN  \n",
       "4  NaN   0  NaN  NaN  NaN  NaN   NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/macbook/Desktop/IBM/DataScientest_Datalar\"\n",
    "\n",
    "df = pd.read_csv(f\"{path}/2008.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60180baf-7ecd-41ca-ad2a-1539bb2e9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.784 seconds\n"
     ]
    }
   ],
   "source": [
    "# Import the time library and calculation of time at the beginning of the execution (t0)\n",
    "path = \"/Users/macbook/Desktop/IBM/DataScientest_Datalar\"\n",
    "\n",
    "from time import time\n",
    "t0 = time()\n",
    "\n",
    "#Reading the file \"2008_raw.csv\"\n",
    "raw_rdd = sc.textFile(f\"file:///{path}/2008.csv\")\n",
    "#raw_rdd = sc.textFile(f\"/{path}/2008.csv\") ==> Hata veriyor file:/// eklemezsen \n",
    "\n",
    "# Calculation of file reading time\n",
    "t1 = time() - t0\n",
    "print(\"Done in {} seconds\".format(round(t1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83dfbc49-b47d-43d5-82ba-f96650cbf569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 2.192 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2008,1,1,2,2057,2052,2312,2258,AS,324,N306AS,135,126,112,14,5,SEA,SJC,697,7,16,0,,0,NA,NA,NA,NA,NA',\n",
       " '2008,1,1,2,703,715,958,951,AS,572,N302AS,175,156,144,7,-12,SEA,PSP,987,6,25,0,,0,NA,NA,NA,NA,NA',\n",
       " '2008,1,1,2,2011,1846,2248,2145,AS,511,N564AS,157,179,136,63,85,SAN,SEA,1050,7,14,0,,0,0,0,0,0,63',\n",
       " '2008,1,1,2,2301,2300,2354,2359,AS,376,N309AS,53,59,35,-5,1,SEA,GEG,224,5,13,0,,0,NA,NA,NA,NA,NA',\n",
       " '2008,1,1,2,1221,1221,1422,1438,AS,729,N317AS,181,197,164,-16,0,TUS,SEA,1216,6,11,0,,0,NA,NA,NA,NA,NA']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation of time at the beginning of execution (t0)\n",
    "t0 = time()\n",
    "\n",
    "### Insert your code here\n",
    "raw_rdd.take(5)\n",
    "\n",
    "### Do not change the code below\n",
    "# Calculation of the time of display of the 5 elements\n",
    "t1 = time() - t0\n",
    "print(\"Done in {} seconds\".format(round(t1,3)))\n",
    "raw_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5507e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151102"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculation of the number of lines \n",
    "count = raw_rdd.count()\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "660ca23b-cb54-46c7-9888-fb97e338fb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2008',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '2057',\n",
       "  '2052',\n",
       "  '2312',\n",
       "  '2258',\n",
       "  'AS',\n",
       "  '324',\n",
       "  'N306AS',\n",
       "  '135',\n",
       "  '126',\n",
       "  '112',\n",
       "  '14',\n",
       "  '5',\n",
       "  'SEA',\n",
       "  'SJC',\n",
       "  '697',\n",
       "  '7',\n",
       "  '16',\n",
       "  '0',\n",
       "  '',\n",
       "  '0',\n",
       "  'NA',\n",
       "  'NA',\n",
       "  'NA',\n",
       "  'NA',\n",
       "  'NA']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an rdd whose lines are a list of raw_rdd elements \n",
    "airplane_rdd = raw_rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Display of the first line of the rdd\n",
    "airplane_rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b31e0e-1c54-4f89-992e-6d2a6a3a90f6",
   "metadata": {},
   "source": [
    "## Map, reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a38cd73-103c-4a9b-a66c-6842e3f32729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2258', 89), ('951', 156), ('2145', 314), ('2359', 223), ('1438', 106)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new rdd by summarizing the lines by the departure airport\n",
    "hist_rdd = airplane_rdd.map(lambda x: (x[7], 1)).reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# Display of the first 5 lines \n",
    "hist_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d06eb1-0f24-4f82-b809-8de7690e1590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2008,1,1,2,2057,2052,2312,2258,AS,324,N306AS,135,126,112,14,5,SEA,SJC,697,7,16,0,,0,NA,NA,NA,NA,NA']\n"
     ]
    }
   ],
   "source": [
    "# Step 02\n",
    "print(raw_rdd.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27f7e906-c679-4f2b-a098-4523887ae33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hist_rdd =  [('2258', 1), ('951', 1), ('2145', 1)]\n",
      "hist_raw_rdd =  [('2008,1,1,2', 1), ('2008,1,1,2', 1), ('2008,1,1,2', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Step 03\n",
    "hist_rdd = airplane_rdd.map(lambda line: (line[7], 1))\n",
    "hist_raw_rdd = raw_rdd.map(lambda line_string: (line_string[0:10], 1))\n",
    "print(\"hist_rdd = \", hist_rdd.take(3))\n",
    "print(\"hist_raw_rdd = \", hist_raw_rdd.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db5ad375-3070-4283-b76a-2c7591996e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008,', '2008,', '2008,', '2008,', '2008,']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 04\n",
    "sil = raw_rdd.map(lambda line: (line[0:5]))\n",
    "sil.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980a8444-ffbb-4c16-8f3a-ddd313a3bbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60de459c-4401-479f-b6cc-e01bd7b3b7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('2258', 1), ('951', 1), ('2145', 1), ('2359', 1), ('1438', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "hist_rdd.collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f1f7c-7290-4aa1-a576-67e2f4a28a41",
   "metadata": {},
   "source": [
    "## sorted ,reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f333acd3-e0e6-4dde-a90e-0e30a253af76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2258', 1), ('951', 1), ('2145', 1), ('2359', 1), ('1438', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('951', 1),\n",
       " ('844', 1),\n",
       " ('523', 1),\n",
       " ('2359', 1),\n",
       " ('2330', 1),\n",
       " ('2258', 1),\n",
       " ('2145', 1),\n",
       " ('2125', 1),\n",
       " ('1956', 1),\n",
       " ('1438', 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorting data in decreasing order\n",
    "# Creating a list from an rdd\n",
    "hist = hist_rdd.collect()\n",
    "\n",
    "# display of the entire list\n",
    "print(hist[:5])\n",
    "\n",
    "sorted(hist[:10], key= lambda x: x[0], reverse= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048927e3-9bbd-47c0-864b-b3701f01e689",
   "metadata": {},
   "source": [
    "## filter, map, reduceByKey, collect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75adc1a3-a0fb-4905-b7e3-809686ac85eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating an rdd whose lines are a list of raw_rdd elements \n",
    "airplane_rdd = raw_rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Calculation and display of the number of cancelled flights by city of origin\n",
    "airplane_rdd \\\n",
    "    .filter(lambda x: x[10] == \"1\") \\\n",
    "    .map(lambda x: (x[8], 1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b84f003-8424-49ff-be2e-7346047908b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airplane_rdd \\\n",
    "    .filter(lambda x: x[10] == \"1\") \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16bfe01c-c761-4b97-93fe-616486f7da2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2008',\n",
       "  '1',\n",
       "  '1',\n",
       "  '2',\n",
       "  '2057',\n",
       "  '2052',\n",
       "  '2312',\n",
       "  '2258',\n",
       "  'AS',\n",
       "  '324',\n",
       "  'N306AS',\n",
       "  '135',\n",
       "  '126',\n",
       "  '112',\n",
       "  '14',\n",
       "  '5',\n",
       "  'SEA',\n",
       "  'SJC',\n",
       "  '697',\n",
       "  '7',\n",
       "  '16',\n",
       "  '0',\n",
       "  '',\n",
       "  '0',\n",
       "  'NA',\n",
       "  'NA',\n",
       "  'NA',\n",
       "  'NA',\n",
       "  'NA']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airplane_rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c8481-b2b0-46f7-ad22-615f0835f469",
   "metadata": {},
   "source": [
    "# DERS 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "234cfaf7-827a-4b6e-a8d5-7a14ebeeada5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'LES MISÉRABLES',\",\n",
       " \" 'VOLUME I.-FANTINE.',\",\n",
       " \" 'PREFACE',\",\n",
       " \" 'So long as there shall exist, by virtue of law and custom, decrees of damnation pronounced by society, artificially creating hells amid the civilization of earth, and adding the element of human fate to divine destiny ; so long as the three great problems of the century-the degradation of man through pauperism, the corruption of woman through hunger, the crippling of children through lack of light-are unsolved ; so long as social asphyxia is possible in any part of the world ;-in other words, and with a still wider significance, so long as ignorance and poverty exist on earth, books of the nature of Les Misérables cannot fail to be of use.',\",\n",
       " \" 'HAUTEVILLE HOUSE, 1862.',\"]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miserables = sc.textFile(f\"file:///{path}/miserable_full.txt\")\n",
    "miserables.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7e014-53c8-42cf-8e1d-73fffcf48565",
   "metadata": {},
   "source": [
    "## replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "972654a6-b3d7-49ae-984c-5a17a1e93963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' les misérables  ',\n",
       " '  volume i  fantine   ',\n",
       " '  preface  ',\n",
       " '  so long as there shall exist  by virtue of law and custom  decrees of damnation pronounced by society  artificially creating hells amid the civilization of earth  and adding the element of human fate to divine destiny ; so long as the three great problems of the century the degradation of man through pauperism  the corruption of woman through hunger  the crippling of children through lack of light are unsolved ; so long as social asphyxia is possible in any part of the world ; in other words  and with a still wider significance  so long as ignorance and poverty exist on earth  books of the nature of les misérables cannot fail to be of use   ',\n",
       " '  hauteville house  1862   ']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "miserables_clean = miserables.map(lambda x : x.lower().replace(',', ' ')\\\n",
    "                                  .replace('.', ' ')\\\n",
    "                                  .replace('-', ' ')\\\n",
    "                                  .replace('\\'', ' '))\n",
    "miserables_clean.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87128c-474c-40c7-b24b-18b63091cdd8",
   "metadata": {},
   "source": [
    "## flatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15efc2c8-82d0-433c-8553-25dba95073d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miserables_flat count =  54702\n",
      "miserables count = 1001\n"
     ]
    }
   ],
   "source": [
    "miserables_flat = miserables_clean.flatMap(lambda line: line.split(\" \"))\n",
    "print(\"miserables_flat count = \", miserables_flat.count())\n",
    "print(\"miserables count =\", miserables.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3af2bccc-0cab-47d9-8cb4-df0bee3fa6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 10405), ('the', 3015), ('of', 1564), ('a', 1136), ('and', 1097)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = miserables_flat.map(lambda x : (x, 1)) \\\n",
    "                        .reduceByKey(lambda x,y : x+y) \\\n",
    "                        .collect()\n",
    "\n",
    "sorted(words, key=lambda x: x[1], reverse=1)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d048bb90-3b3a-42fa-a444-54bb35a4353f",
   "metadata": {},
   "source": [
    "## all func. in one code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "30f3ad3c-89c1-41d7-8712-f72e086f0da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 10405), ('the', 3015), ('of', 1564), ('a', 1136), ('and', 1097)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Direct creation of a list containing the words\n",
    "words_sorted_3 =  sc.textFile(f\"file:///{path}/miserable_full.txt\") \\\n",
    "                    .map(lambda x : x.lower().replace(',', ' ').replace('.', ' ').replace('-', ' ').replace('\\'', ' ').replace('\\\\', ' ')) \\\n",
    "                    .flatMap(lambda line : line.split(\" \")) \\\n",
    "                    .map(lambda x : (x,1)) \\\n",
    "                    .reduceByKey(lambda x,y : x+y) \\\n",
    "                    .sortBy(lambda couple: couple[1], ascending = False) \\\n",
    "\n",
    "words_sorted_3.collect()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9678bbd5-ca90-439d-8f1e-72b74feeeeb9",
   "metadata": {},
   "source": [
    "# DERS 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4df201-e619-4d62-9b66-c8565efb4bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/06/04 20:35:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8b0528c280>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing Spark Session and SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Definition of a SparkContext\n",
    "SparkContext.getOrCreate() \n",
    "\n",
    "# Definition of a SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Introduction to DataFrame\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a665e2f1-39f4-462c-ac46-1edffeb60b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://macbook-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=pyspark-shell>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a shortcut to the SparkContext already created\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e528f9-f99a-416d-8bb5-d7dfaff402de",
   "metadata": {},
   "source": [
    "## Import Row, create DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1211f720-893d-499c-9832-fce0da2fca56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/04 20:39:02 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 1 (TID 1): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+---------+\n",
      "|year|month|day|flightNum|\n",
      "+----+-----+---+---------+\n",
      "|2008|    1|  1|     2052|\n",
      "|2008|    1|  1|      715|\n",
      "|2008|    1|  1|     1846|\n",
      "|2008|    1|  1|     2300|\n",
      "|2008|    1|  1|     1221|\n",
      "+----+-----+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Import the Row structure from the module pyspark.sql\n",
    "Import the database 2008_raw.csv\n",
    "Create a rdd from this database\n",
    "Create a rdd_row using the map method, applying on each line the structure Row with the explanatory variables year, month, day and flightNum\n",
    "Create a DataFrame df from rdd_row\n",
    "'''\n",
    "\n",
    "path = \"/Users/macbook/Desktop/IBM/DataScientest_Datalar\"\n",
    "\n",
    "# Importing Row from the pyspark.sql package\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Loading the file '2008_raw.csv'\n",
    "rdd = sc.textFile(f'file:///{path}/2008.csv').map(lambda line: line.split(\",\"))\n",
    "\n",
    "# Creating a new rdd by selecting the explanatory variables\n",
    "rdd_row = rdd.map(lambda line: Row(year = line[0],\n",
    "                                   month = line[1],\n",
    "                                   day = line[2],\n",
    "                                   flightNum = line[5]))\n",
    "\n",
    "# Creating a data frame from an rdd\n",
    "df = spark.createDataFrame(rdd_row)\n",
    "\n",
    "\n",
    "# Display of the first 5 lines\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045ad93-c5c0-432d-aecc-40d2c3a537a4",
   "metadata": {},
   "source": [
    "## Reading csv file, printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d29354cb-deb7-4e7c-9ec4-237b10e2ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: string (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      " |-- _c10: string (nullable = true)\n",
      " |-- _c11: string (nullable = true)\n",
      " |-- _c12: string (nullable = true)\n",
      " |-- _c13: string (nullable = true)\n",
      " |-- _c14: string (nullable = true)\n",
      " |-- _c15: string (nullable = true)\n",
      " |-- _c16: string (nullable = true)\n",
      " |-- _c17: string (nullable = true)\n",
      " |-- _c18: string (nullable = true)\n",
      " |-- _c19: string (nullable = true)\n",
      " |-- _c20: string (nullable = true)\n",
      " |-- _c21: string (nullable = true)\n",
      " |-- _c22: string (nullable = true)\n",
      " |-- _c23: string (nullable = true)\n",
      " |-- _c24: string (nullable = true)\n",
      " |-- _c25: string (nullable = true)\n",
      " |-- _c26: string (nullable = true)\n",
      " |-- _c27: string (nullable = true)\n",
      " |-- _c28: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading the file '2008.csv'\n",
    "raw_df = spark.read.csv(f'file:///{path}/2008.csv', header=False)\n",
    "\n",
    "# Display of the variables' schema\n",
    "raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdcb95e7-6099-48f8-b50e-6d261fe0883b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+---+----+----+----+----+---+---+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "| _c0|_c1|_c2|_c3| _c4| _c5| _c6| _c7|_c8|_c9|  _c10|_c11|_c12|_c13|_c14|_c15|_c16|_c17|_c18|_c19|_c20|_c21|_c22|_c23|_c24|_c25|_c26|_c27|_c28|\n",
      "+----+---+---+---+----+----+----+----+---+---+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|2008|  1|  1|  2|2057|2052|2312|2258| AS|324|N306AS| 135| 126| 112|  14|   5| SEA| SJC| 697|   7|  16|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2| 703| 715| 958| 951| AS|572|N302AS| 175| 156| 144|   7| -12| SEA| PSP| 987|   6|  25|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2|2011|1846|2248|2145| AS|511|N564AS| 157| 179| 136|  63|  85| SAN| SEA|1050|   7|  14|   0|null|   0|   0|   0|   0|   0|  63|\n",
      "|2008|  1|  1|  2|2301|2300|2354|2359| AS|376|N309AS|  53|  59|  35|  -5|   1| SEA| GEG| 224|   5|  13|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2|1221|1221|1422|1438| AS|729|N317AS| 181| 197| 164| -16|   0| TUS| SEA|1216|   6|  11|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2|1843|1840|2110|2125| AS|283|N318AS| 147| 165| 124| -15|   3| LAX| SEA| 954|   7|  16|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2|2045|2045|2314|2330| AS|211|N305AS| 149| 165| 126| -16|   0| LAX| SEA| 954|   6|  17|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2|  49|  50| 547| 523| AS|100|N315AS| 238| 213| 222|  24|  -1| ANC| PDX|1542|   2|  14|   0|null|   0|   0|   0|  24|   0|   0|\n",
      "|2008|  1|  1|  2|1719|1715|1939|1956| AS|665|N302AS| 140| 161| 118| -17|   4| LAS| SEA| 866|   8|  14|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2| 613| 630| 815| 844| AS|531|N755AS| 122| 134|  96| -29| -17| SJC| SEA| 697|   7|  19|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2| 753| 720|1125|1103| AS|571|N320AS| 152| 163| 124|  22|  33| SEA| DEN|1024|   5|  23|   0|null|   0|  22|   0|   0|   0|   0|\n",
      "|2008|  1|  1|  2|null| 205|null| 620| AS|154|N309AS|null| 195|null|null|null| ANC| SEA|1449|null|null|   1|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2| 741| 740|1128|1139| AS|728|N317AS| 167| 179| 150| -11|   1| SEA| TUS|1216|   4|  13|   0|null|   0|null|null|null|null|null|\n",
      "|2008|  1|  1|  2|1702|1530|1941|1804| AS|518|N564AS| 159| 154| 142|  97|  92| SEA| SAN|1050|   2|  15|   0|null|   0|  92|   0|   5|   0|   0|\n",
      "|2008|  1|  1|  2|1306|1245|1551|1525| AS|580|N307AS| 165| 160| 142|  26|  21| SEA| SAN|1050|   2|  21|   0|null|   0|  21|   0|   5|   0|   0|\n",
      "+----+---+---+---+----+----+----+----+---+---+------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_df.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d16aeea5-ad59-4fcf-bba5-4b1355e6ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|year|month|day|hour|flightNum|tailNum|origin|dest|dist|canceled|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|2008|    1|  1|2057|      324| N306AS|   SEA| SJC| 697|       0|\n",
      "|2008|    1|  1| 703|      572| N302AS|   SEA| PSP| 987|       0|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/04 21:09:51 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 40 (TID 42): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Creating a new rdd by selecting the explanatory variables\n",
    "rdd_row = rdd.map(lambda line: Row(year = line[0],\n",
    "                                   month = line[1],\n",
    "                                   day = line[2],\n",
    "                                   hour = line[4],\n",
    "                                   flightNum = line[9],\n",
    "                                   tailNum = line[10],\n",
    "                                   origin = line[16],\n",
    "                                   dest = line[17],\n",
    "                                   dist = line[18],\n",
    "                                   canceled = line[21]\n",
    "                                ))\n",
    "\n",
    "rdd_row.take(2)\n",
    "\n",
    "df = spark.createDataFrame(rdd_row)\n",
    "\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07dfacf9-fcee-4e93-be71-db32fe49ac52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- flightNum: string (nullable = true)\n",
      " |-- tailNum: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- dist: string (nullable = true)\n",
      " |-- canceled: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276173d-40d8-42c9-8bbd-1e0d7e695979",
   "metadata": {},
   "source": [
    "## change col type 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4f737f5-b9d0-4c9a-a91f-a940ff2122ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: string (nullable = true)\n",
      " |-- flightNum: integer (nullable = true)\n",
      " |-- tailNum: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- dist: integer (nullable = true)\n",
      " |-- canceled: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "integerColumns = integerList = ['year', 'month', 'day', 'flightNum', 'dist', 'canceled' ]\n",
    "\n",
    "stringColumns = ['tailNum','origin', 'dest']\n",
    "\n",
    "# integerColumns listesindeki sütunları integer tipine dönüştürmek\n",
    "for col_name in integerColumns:\n",
    "    df = df.withColumn(col_name, col(col_name).cast(\"int\"))\n",
    "\n",
    "# stringColumns tuple'ındaki sütunları string tipine dönüştürmek\n",
    "for col_name in stringColumns:\n",
    "    df = df.withColumn(col_name, col(col_name).cast(\"string\"))\n",
    "    \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f6f97-b3e7-4032-a983-7b38ea48f620",
   "metadata": {},
   "source": [
    "## change col type 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c17478-e78b-4c25-9113-53c6b40d3ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a data frame by specifying the type of columns\n",
    "flights = raw_df.select(raw_df.year.cast(\"int\"),\n",
    "                        raw_df.month.cast(\"int\"),\n",
    "                        raw_df.day.cast(\"int\"),\n",
    "                        raw_df.flightNum.cast(\"int\"),\n",
    "                        raw_df.origin.cast(\"string\"),\n",
    "                        raw_df.dest.cast(\"string\"),\n",
    "                        raw_df.distance.cast(\"int\"),\n",
    "                        raw_df.canceled.cast(\"boolean\"),\n",
    "                        raw_df.cancellationCode.cast(\"string\"),\n",
    "                        raw_df.carrierDelay.cast(\"int\"))\n",
    "\n",
    "# Display of 20 first lines\n",
    "flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aaadaf-7a37-4c85-a170-2e98d1e37c23",
   "metadata": {},
   "source": [
    "## describe , toPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2134c172-771a-460c-abe6-fe629b77b03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+---------+-------+------+------+--------+--------+\n",
      "|summary|    year|   month|     day|    hour|flightNum|tailNum|origin|  dest|    dist|canceled|\n",
      "+-------+--------+--------+--------+--------+---------+-------+------+------+--------+--------+\n",
      "|  count|  151102|  151102|  151102|  151102|   151102| 151102|151102|151102|  151102|  151102|\n",
      "|   mean|  2008.0|6.414...|15.70...|1333....| 336.7...|   null|  null|  null|957.9...|0.014...|\n",
      "| stddev|1.136...|3.372...|8.794...|511.2...| 235.5...|   null|  null|  null|598.6...|0.118...|\n",
      "|    min|    2008|       1|       1|       1|        1| N302AS|   ADK|   ADK|      31|       0|\n",
      "|    max|    2008|      12|      31|      NA|      997| N982AS|   YAK|   YAK|    2846|       1|\n",
      "+-------+--------+--------+--------+--------+---------+-------+------+------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>flightNum</th>\n",
       "      <th>tailNum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dist</th>\n",
       "      <th>canceled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "      <td>151102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mean</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>6.414633823509947</td>\n",
       "      <td>15.70080475440431</td>\n",
       "      <td>1333.6065953390969</td>\n",
       "      <td>336.75316011700704</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>957.9093526227317</td>\n",
       "      <td>0.014156000582388056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stddev</td>\n",
       "      <td>1.1368673191536325E-13</td>\n",
       "      <td>3.372586753808719</td>\n",
       "      <td>8.79497003328945</td>\n",
       "      <td>511.2859647572262</td>\n",
       "      <td>235.5397135668841</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>598.6289977832145</td>\n",
       "      <td>0.11813424816440472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>min</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>N302AS</td>\n",
       "      <td>ADK</td>\n",
       "      <td>ADK</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>max</td>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>NA</td>\n",
       "      <td>997</td>\n",
       "      <td>N982AS</td>\n",
       "      <td>YAK</td>\n",
       "      <td>YAK</td>\n",
       "      <td>2846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  summary                    year              month                day   \n",
       "0   count                  151102             151102             151102  \\\n",
       "1    mean                  2008.0  6.414633823509947  15.70080475440431   \n",
       "2  stddev  1.1368673191536325E-13  3.372586753808719   8.79497003328945   \n",
       "3     min                    2008                  1                  1   \n",
       "4     max                    2008                 12                 31   \n",
       "\n",
       "                 hour           flightNum tailNum  origin    dest   \n",
       "0              151102              151102  151102  151102  151102  \\\n",
       "1  1333.6065953390969  336.75316011700704    None    None    None   \n",
       "2   511.2859647572262   235.5397135668841    None    None    None   \n",
       "3                   1                   1  N302AS     ADK     ADK   \n",
       "4                  NA                 997  N982AS     YAK     YAK   \n",
       "\n",
       "                dist              canceled  \n",
       "0             151102                151102  \n",
       "1  957.9093526227317  0.014156000582388056  \n",
       "2  598.6289977832145   0.11813424816440472  \n",
       "3                 31                     0  \n",
       "4               2846                     1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying a summary using the truncate option of the show method\n",
    "df.describe().show(truncate = 8)\n",
    "\n",
    "### Second method\n",
    "# Displaying a summary using the method toPandas\n",
    "df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda5cde4-e6b3-428a-839b-722aa3d8fcca",
   "metadata": {},
   "source": [
    "## distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "daa68bed-2bab-4a69-9c69-4c07daf4ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "681"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation of the number of flights with separate flight numbers\n",
    "df.select('flightNum').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7b01b7-e47e-4b4f-86fb-6140714acbcc",
   "metadata": {},
   "source": [
    "## groupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95fb5728-cb46-409e-9854-2c288b3601cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 47:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|canceled| count|\n",
      "+--------+------+\n",
      "|       1|  2139|\n",
      "|       0|148963|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display of the summary of the category variable \"cancellationCode\".\n",
    "\n",
    "df.groupBy('canceled').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19203cff-36ba-4f76-b265-559fbdcaf777",
   "metadata": {},
   "source": [
    "## filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "801c1f69-7cf1-4fab-82fc-79e923e06bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|year|month|day|hour|flightNum|tailNum|origin|dest|dist|canceled|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|2008|    1|  1|  NA|      154| N309AS|   ANC| SEA|1449|       1|\n",
      "|2008|    1|  1|  NA|      327| N792AS|   SNA| PDX| 859|       1|\n",
      "|2008|    1|  1|  NA|      488| N792AS|   PDX| SNA| 859|       1|\n",
      "|2008|    1|  1|  NA|      464| N960AS|   SEA| ONT| 956|       1|\n",
      "|2008|    1|  1|  NA|      631| N962AS|   LAS| SEA| 866|       1|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/04 21:13:47 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 55 (TID 57): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(df.canceled == 1).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8245c5-c186-47cc-96e3-9bc98085d830",
   "metadata": {},
   "source": [
    "## filter, groupBy, count, orderBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab455968-d8b8-4234-9833-4669a4de7789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 62:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|month|count|\n",
      "+-----+-----+\n",
      "|   11|   65|\n",
      "|    9|   67|\n",
      "|    3|   85|\n",
      "|   10|   93|\n",
      "|    7|   98|\n",
      "|    6|  104|\n",
      "|    5|  127|\n",
      "|    8|  154|\n",
      "|    4|  158|\n",
      "|    2|  206|\n",
      "|    1|  355|\n",
      "|   12|  627|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(df.canceled == 1).groupBy('month').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02a4e6-14b3-4cbd-96b6-0d263b873f65",
   "metadata": {},
   "source": [
    "## withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "df402e76-3b39-435b-9f28-342c1abea511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 73:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------+----+----+--------+------------+\n",
      "|year|month|day|hour|flightNum|tailNum|origin|dest|dist|canceled|isLongFlight|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+------------+\n",
      "|2008|    1|  1|2057|      324| N306AS|   SEA| SJC| 697|       0|       false|\n",
      "|2008|    1|  1| 703|      572| N302AS|   SEA| PSP| 987|       0|       false|\n",
      "|2008|    1|  1|2011|      511| N564AS|   SAN| SEA|1050|       0|        true|\n",
      "|2008|    1|  1|2301|      376| N309AS|   SEA| GEG| 224|       0|       false|\n",
      "|2008|    1|  1|1221|      729| N317AS|   TUS| SEA|1216|       0|        true|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/05 03:58:06 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 73 (TID 75): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Creation of a new variable \"isLongFlight\" and display of the first 10 lines\n",
    "\n",
    "df.withColumn('isLongFlight', df.dist > 1000).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79c2c041-e2d1-4f0a-a681-b8148c939706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "151102"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "779dd1a3-3d15-46c5-b04f-f72695e03168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46574"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter( df.dist > 1000).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8619c539-21bf-49a2-b560-7b07c0df44d0",
   "metadata": {},
   "source": [
    "## fillna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e960de6-7d34-4977-b0ef-115ddab9af28",
   "metadata": {},
   "source": [
    "df.fillna( newValue, 'columnName') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37aabde3-80c8-4f8e-b56d-9eb8c730ef74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|year|month|day|hour|flightNum|tailNum|origin|dest|dist|canceled|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.filter(df.hour.isNull()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b3f303e-d9fc-4ec6-9b17-402c563b5cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|year|month|day|hour|flightNum|tailNum|origin|dest|dist|canceled|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|2008|    1|  1|null|      154| N309AS|   ANC| SEA|1449|       1|\n",
      "|2008|    1|  1|null|      327| N792AS|   SNA| PDX| 859|       1|\n",
      "|2008|    1|  1|null|      488| N792AS|   PDX| SNA| 859|       1|\n",
      "|2008|    1|  1|null|      464| N960AS|   SEA| ONT| 956|       1|\n",
      "|2008|    1|  1|null|      631| N962AS|   LAS| SEA| 866|       1|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/05 04:09:55 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 87 (TID 89): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Convert 'NA' values to NULL in the 'hour' column\n",
    "df = df.withColumn('hour', when(col('hour') == 'NA', None).otherwise(col('hour').cast('integer')))\n",
    "\n",
    "# Filter rows where 'hour' is NULL and show the first 5 rows\n",
    "df.filter(df.hour.isNull()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd9a7ca-29c5-49cc-ba53-3bf7efc2f411",
   "metadata": {},
   "source": [
    "## replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563bbcb4-c199-4ed9-a6d8-0ca19f324b86",
   "metadata": {},
   "source": [
    "df.replace(oldValue, newValue)\n",
    "replaces on the whole database\n",
    "\n",
    "df.replace(oldValue, newValue, 'columnName')\n",
    "replaces only on the specified columns\n",
    "\n",
    "df.replace([oldValue1, oldValue2], [newValue1, newValue2], 'columnName')\n",
    "if several values to be replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfd4299-27d2-4636-b136-ae44ad6a8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace, in order, the cancellation codes 'A','B','C' with '1', '2', '3'\n",
    "\n",
    "df.replace(['A', 'B', 'C'], [1, 2, 3], ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac5339-a144-4b00-8d2b-c56c8eaa9b59",
   "metadata": {},
   "source": [
    "## order by"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fb49bc-148f-458c-82b1-d9d2a35f5265",
   "metadata": {},
   "source": [
    "df.orderBy(df.age)\n",
    "ordered by the variable 'age'\n",
    "\n",
    "df.orderBy(df.age.desc())\n",
    "order in decreasing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "39aea550-3cf8-4951-a0ca-f5f71dfbcac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|year|month|day|hour|flightNum|tailNum|origin|dest|dist|canceled|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "|2008|    8| 29|1255|      997| N708AS|   SEA| ANC|1449|       0|\n",
      "|2008|    6|  7|2057|      996| N562AS|   SEA| GEG| 224|       0|\n",
      "|2008|    8| 25| 800|      991| N570AS|   DEN| SEA|1024|       0|\n",
      "|2008|    7| 31| 805|      991| N562AS|   DEN| SEA|1024|       0|\n",
      "|2008|    4| 27| 736|      989| N557AS|   SFO| SEA| 679|       0|\n",
      "+----+-----+---+----+---------+-------+------+----+----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Display the first lines of the database ordered in decreasing order by flight number\n",
    "\n",
    "df.orderBy(df.flightNum.desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915c1cb-c75e-4ecb-bcbf-29b6ddc53f0a",
   "metadata": {},
   "source": [
    "## SQL Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0afde-1f5c-49db-bccf-58bf2f0c5ddc",
   "metadata": {},
   "source": [
    "df.createOrReplaceTempView(\"people\")\n",
    "sqlDF = spark.sql(\"SELECT * FROM people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87710c63-4b34-45ff-b8a4-335d03f1fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|origin|\n",
      "+------+\n",
      "|   SEA|\n",
      "|   SEA|\n",
      "|   SAN|\n",
      "|   SEA|\n",
      "|   TUS|\n",
      "|   LAX|\n",
      "|   LAX|\n",
      "|   ANC|\n",
      "|   LAS|\n",
      "|   SJC|\n",
      "+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/06/05 04:28:01 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 90 (TID 94): Attempting to kill Python Worker\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Creating an SQL view\n",
    "df.createOrReplaceTempView(\"flightsView\")\n",
    "\n",
    "# Creating a data frame containing only the variable \"carrierDelay\"\n",
    "sqlDF = spark.sql(\"SELECT origin FROM flightsView\")\n",
    "\n",
    "# Display of the first 10 lines\n",
    "sqlDF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a98c6c-9ee1-496d-a34a-1df485168c73",
   "metadata": {
    "tags": []
   },
   "source": [
    "## sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86636081-7e31-4db1-af6e-5dc8e6b313b6",
   "metadata": {},
   "source": [
    "withRemplacement : a Boolean to specify False if you don't want to overwrite the DataFrame\n",
    "fraction : the fraction of data to be kept\n",
    "seed : an integer that allows the results to be reproduced: for the same seed, a function, although random, will always give the same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f2ae27ed-631b-472c-872a-31015fac7a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>flightNum</th>\n",
       "      <th>tailNum</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>dist</th>\n",
       "      <th>canceled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2028</td>\n",
       "      <td>310</td>\n",
       "      <td>N706AS</td>\n",
       "      <td>PDX</td>\n",
       "      <td>SFO</td>\n",
       "      <td>550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>191</td>\n",
       "      <td>N772AS</td>\n",
       "      <td>ANC</td>\n",
       "      <td>FAI</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>818</td>\n",
       "      <td>31</td>\n",
       "      <td>N784AS</td>\n",
       "      <td>ADQ</td>\n",
       "      <td>ANC</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>1339</td>\n",
       "      <td>6</td>\n",
       "      <td>N590AS</td>\n",
       "      <td>LAX</td>\n",
       "      <td>DCA</td>\n",
       "      <td>2311</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2130</td>\n",
       "      <td>313</td>\n",
       "      <td>N564AS</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SEA</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2008</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1034</td>\n",
       "      <td>184</td>\n",
       "      <td>N648AS</td>\n",
       "      <td>FAI</td>\n",
       "      <td>ANC</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2008</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1351</td>\n",
       "      <td>62</td>\n",
       "      <td>N783AS</td>\n",
       "      <td>KTN</td>\n",
       "      <td>SEA</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>2220</td>\n",
       "      <td>70</td>\n",
       "      <td>N613AS</td>\n",
       "      <td>JNU</td>\n",
       "      <td>SIT</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>22</td>\n",
       "      <td>2013</td>\n",
       "      <td>614</td>\n",
       "      <td>N317AS</td>\n",
       "      <td>SEA</td>\n",
       "      <td>LAS</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2008</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>1819</td>\n",
       "      <td>19</td>\n",
       "      <td>N558AS</td>\n",
       "      <td>MCO</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2008</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>628</td>\n",
       "      <td>335</td>\n",
       "      <td>N778AS</td>\n",
       "      <td>SJC</td>\n",
       "      <td>SEA</td>\n",
       "      <td>697</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year  month  day  hour  flightNum tailNum origin dest  dist  canceled\n",
       "0   2008      1   30  2028        310  N706AS    PDX  SFO   550         0\n",
       "1   2008      2    1    16        191  N772AS    ANC  FAI   261         0\n",
       "2   2008      3   24   818         31  N784AS    ADQ  ANC   252         0\n",
       "3   2008      3   28  1339          6  N590AS    LAX  DCA  2311         0\n",
       "4   2008      6   15  2130        313  N564AS    SFO  SEA   679         0\n",
       "5   2008      6   22  1034        184  N648AS    FAI  ANC   261         0\n",
       "6   2008      7   15  1351         62  N783AS    KTN  SEA   680         0\n",
       "7   2008      9   30  2220         70  N613AS    JNU  SIT    95         0\n",
       "8   2008     10   22  2013        614  N317AS    SEA  LAS   866         0\n",
       "9   2008     10   25  1819         19  N558AS    MCO  SEA  2553         0\n",
       "10  2008     12    6   628        335  N778AS    SJC  SEA   697         0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display of about ten lines of the database\n",
    "df.sample(False, .00006, seed = 222).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d17718-d132-40eb-a737-f1f1dc6691e7",
   "metadata": {},
   "source": [
    "## sc.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a29e67-a3a2-4eae-b661-1ae13a1335db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing SparkContextb\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d139ed-3311-4d03-8263-09344a2bcefd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b8777f-e122-4556-86ed-a3f806f59ef9",
   "metadata": {},
   "source": [
    "# RECAP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa75aada-2cba-432b-8216-d957bd3a8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECAP \n",
    "\n",
    "# Importing SparkContext from the pyspark module\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# Defining a SparkContext locally\n",
    "sc = SparkContext('local')\n",
    "sc\n",
    "\n",
    "\n",
    "#Reading the file \"2008_raw.csv\"\n",
    "raw_rdd = sc.textFile(f\"file:///{path}/2008.csv\")\n",
    "\n",
    "\n",
    "# take 5 rows\n",
    "raw_rdd.take(5)\n",
    "\n",
    "\n",
    "# collect all\n",
    "raw_rdd.collect()\n",
    "\n",
    "\n",
    "# count\n",
    "# calculation of the number of lines \n",
    "count = raw_rdd.count()\n",
    "\n",
    "\n",
    "# map func\n",
    "hist_rdd = airplane_rdd.map(lambda line: (line[7], 1))\n",
    "hist_raw_rdd = raw_rdd.map(lambda line_string: (line_string[0:10], 1))\n",
    "print(\"hist_rdd = \", hist_rdd.take(3))\n",
    "print(\"hist_raw_rdd = \", hist_raw_rdd.take(3))\n",
    "\n",
    "\n",
    "# collect (create list)\n",
    "# Creating a list from an rdd\n",
    "hist = hist_rdd.collect()\n",
    "\n",
    "\n",
    "# sorted\n",
    "# ASC increasing≈ (reverse = 0) # DESC decreasing (reverse = 1) \n",
    "hist_sorted  = sorted(hist, key= lambda x: x[0], reverse= 1)\n",
    "print(hist_rdd[:5])\n",
    "\n",
    "\n",
    "# sortBY\n",
    "hist_sorted_2 = hist.sortBy(lambda couple: couple[1], ascending = True) \\\n",
    "                    .collect()\n",
    "\n",
    "\n",
    "# split \n",
    "# Creating an rdd whose lines are a list of raw_rdd elements \n",
    "airplane_rdd = raw_rdd.map(lambda line: line.split(\",\"))\n",
    "\n",
    "\n",
    "# Calculation and display of the number of cancelled flights by city of origin\n",
    "airplane_rdd \\\n",
    "    .filter(lambda x: x[10] == \"1\") \\\n",
    "    .map(lambda x: (x[8], 1)) \\\n",
    "    .reduceByKey(lambda x,y: x+y) \\\n",
    "    .collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255f36b2-c277-4566-a228-0a58b48384bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 (Visual Studio)",
   "language": "python",
   "name": "visualstudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

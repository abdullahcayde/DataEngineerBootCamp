{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    The exercise is composed of several questions, follow the order and be careful to respect the names of the variables. Do not hesitate to contact the DataScientest team if you face any issue help@datascientest.com\n",
    "    Exploring the dataset\n",
    "\n",
    "    This evaluation focuses on the heart_disease.csv dataset. This dataset contains information and medical results for just over 300 patients. The variable target indicates whether a patient has (1) or not (0) heart disease.\n",
    "    The main objective of the exam is to use data processing methods and a classification algorithm to predict whether a patient has heart disease or not.\n",
    "\n",
    "    (a) Read the file heart_disease.csv in a DataFrame called df specifying that the first column contains the indices\n",
    "\n",
    "    (b) Display an overview and a first description of the variables in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012</td>\n",
       "      <td>63</td>\n",
       "      <td>Male</td>\n",
       "      <td>3</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1264</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1217</td>\n",
       "      <td>41</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1300</td>\n",
       "      <td>56</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1049</td>\n",
       "      <td>57</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  age     sex  cp  trestbps   chol  fbs  restecg  thalach  exang  \\\n",
       "0  1012   63    Male   3     145.0  233.0    1        0    150.0    0.0   \n",
       "1  1264   37    Male   2     130.0  250.0    0        1    187.0    0.0   \n",
       "2  1217   41  Female   1     130.0  204.0    0        0      NaN    0.0   \n",
       "3  1300   56    Male   1     120.0  236.0    0        1    178.0    0.0   \n",
       "4  1049   57  Female   0     120.0  354.0    0        1    163.0    1.0   \n",
       "\n",
       "   oldpeak  slope   ca  thal  target  \n",
       "0      2.3      0  0.0     1     1.0  \n",
       "1      3.5      0  0.0     2     1.0  \n",
       "2      1.4      2  0.0     2     1.0  \n",
       "3      0.8      2  0.0     2     1.0  \n",
       "4      0.6      2  0.0     2     1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert your code here\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('heart_disease.csv', sep=';')\n",
    "df = pd.read_csv('Data\\test2.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    (c) Display the information about the oldest patient. Is he or she sick?\n",
    "\n",
    "    (d) What about the youngest patient?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "age_max = df['age'].max()\n",
    "age_min = df['age'].min()\n",
    "\n",
    "print('Oldest patient, she is not sick\\n', df.loc[df.age == age_max])\n",
    "print('\\nYoungest patient, she is sick\\n', df.loc[df.age == age_min])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Compare the proportions of sick and non-sick between male and female patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df_male = df.loc[(df.sex == 'Male')]\n",
    "df_female = df.loc[(df.sex == 'Female')]\n",
    "\n",
    "male_sick = df_male.loc[df_male.target == 1].shape[0]\n",
    "male_nonsick = df_male.loc[df_male.target == 0].shape[0]\n",
    "male_total = male_sick + male_nonsick\n",
    "\n",
    "female_sick = df_female.loc[df_female.target == 1].shape[0]\n",
    "female_nonsick = df_female.loc[df_female.target == 0].shape[0]\n",
    "female_total = female_sick + female_nonsick\n",
    "\n",
    "print('Male sick : %', male_sick/male_total)\n",
    "print('Male non-sick : %', male_nonsick/male_total)\n",
    "\n",
    "print('Female sick : %', female_sick/male_total)\n",
    "print('Female non-sick : %', female_nonsick/male_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing\n",
    "\n",
    "    The data preparation phase includes the activities related to the construction of the precise set of data to be analyzed, based on the raw data.\n",
    "\n",
    "    It includes the classification of the data according to chosen criteria, the cleaning of the data, and especially their recoding to make them compatible with the algorithms that will be used.\n",
    "\n",
    "    (f) Replace the modalities \"Male\" and \"Female\" of the variable \"sex\" with 0 and 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df.replace(('Male', 'Female'), (0,1), inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    The thalach variable is the maximum heart rate of the patient.\n",
    "    The maximum heart rate is usually between 50 and 250 beats per minute. Sometimes some values are outside the expected values of a variable, due to human error (a misplaced comma for example), they are called outliers.\n",
    "\n",
    "    (g) Display the distribution of the variable `thalach', find the outliers (i.e., outside the [50,250] range) and replace them with a plausible value if there are any.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df.thalach.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.thalach < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_outlier = df.loc[df.thalach > 250].index\n",
    "df.loc[index_outlier, 'thalach'] = 250\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Display the number of missing values for each column of df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(i) Delete the lines in the data frame df that are not labeled. In other words, the lines for which the value of the target attribute is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df.dropna(axis=0, how='all', subset=['target'], inplace = True)\n",
    "df.target.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    Some variables like ca or exang are numerical, but qualitative variables. Indeed, they contain a finite number of modalities (four for the first, two for the second). In this case, it is possible to replace the missing values in these columns with the most frequent element. In statistics, this value is called the mode, and the method of the same name allows you to return this value within a pandas Series.\n",
    "\n",
    "    (j) Replace the missing values for the variables ca and exang with their respective modes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "df.ca.fillna(df.ca.mode()[0], inplace=True)\n",
    "df.exang.fillna(df.exang.mode()[0], inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    (k) Replace the missing values in the other columns with their respective averages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.thalach.fillna(df.thalach.mean(), inplace=True)\n",
    "\n",
    "df.trestbps.fillna(df.trestbps.mean(), inplace=True)\n",
    "\n",
    "df.chol.fillna(df.chol.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    (l) Split the explanatory variables in a dataframe X and the target variable in y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "X = df.drop(['ID','target'], axis=1)\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    The 13 explanatory variables available have different scales, which can be problematic for some classification algorithms. For example, the variable oldpeak contains values between 0 and 6.2, while the variable trestbps is in the range [94,200].\n",
    "\n",
    "    To transform these variables so that they are all within the fixed interval [0,1], Min-Max normalization can be applied.\n",
    "\n",
    "    The Min-Max normalization is done using the following formula:\n",
    "\n",
    "    Xnew=X−XminXmax−Xmin\n",
    "    Xnew=X−XminXmax−Xmin\n",
    "\n",
    "    With:\n",
    "    XminXmin : the smallest observed value for variable XX\n",
    "    XmaxXmax : the largest observed value for variable XX\n",
    "    XX : the value of the variable we are trying to normalize\n",
    "\n",
    "    (m) Apply this transformation to each column of X in a new data frame called X_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Training data\n",
    "\n",
    "    Modeling is the most interesting step in data science. It includes the selection, parameterization and test of different algorithms as well as their chaining, which constitutes a model.\n",
    "\n",
    "    This process is first descriptive to generate knowledge, by explaining why things happened. It then becomes predictive by explaining what will happen, and then prescriptive by allowing the optimization of a future situation.\n",
    "\n",
    "    In order to evaluate the performance of the classification model, it is necessary to \"set aside\" some data that will attest to the quality of the model once trained. To do this, the data must be systematically divided into a training set (X_train and y_train) and a test set (X_test and y_test). The variables X_train, X_test contain the features and y_train, y_test contain the labels.\n",
    "\n",
    "    (n) Divide the data (X_norm, y) into a training set and a test set. The samples will be randomly distributed between the training set and the test set, and the size of the test set should be 30% of the total amount of available data.\n",
    "\n",
    "    (o) Train a classification algorithm of your choice on the training set (X_train and y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- KNN\n",
    "# Instantiation of the model\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# Training the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of the target variable for the TEST dataset\n",
    "y_pred_test_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the classification model\n",
    "\n",
    "    The purpose of the evaluation is to verify the model or the knowledge obtained to ensure that it meets the objectives formulated at the beginning of the process. It also contributes to the decision to deploy the model or, if necessary, to improve it. At this stage, the robustness and accuracy of the models obtained are tested.\n",
    "\n",
    "    (p) Display the rate of true predictions on the test sample, as well as the confusion matrix obtained from the predictions on this sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "# Computation of the accuracy, precision and recall\n",
    "(TN, FP), (FN, TP) = confusion_matrix(y_test, y_pred_test_knn)\n",
    "n = len(y_test)\n",
    "\n",
    "print(\"\\nKNN Accuracy:\", (TP + TN) / n)\n",
    "\n",
    "# Computation and display of the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test_knn)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    (q) On the test sample, how many sick patients were not detected by the model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here\n",
    "\n",
    "# This means False Negative FN\n",
    "\n",
    "print(f'{FN} sick patients were not detected by the model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
